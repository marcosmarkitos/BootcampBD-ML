{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesado\n",
    "\n",
    "A veces tenemos que ajustar nuestros datos de entrada para que encajen con lo que espera el algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escalado de caracterísicas\n",
    "\n",
    "Muchas veces los datos de diferentes orígenes, columnas, dimensiones, vienen en distintas escalas. \n",
    "\n",
    "\n",
    "Muy importante para:\n",
    "\n",
    "* Algoritmos que utilicen medidas de distancia: kmeans, knearest neighbors\n",
    "\n",
    "Puede ser interesante para:\n",
    "\n",
    "* Regresiones/Redes neuronales para acelerar la convergencia\n",
    "\n",
    "No es necesario para:\n",
    "\n",
    "* Algoritmos basados en árboles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Por qué es necesario?\n",
    "\n",
    "Cuando estamos trabajando con dataframes con múltiples variables, cada una generalmente se mueve en un rango diferente.\n",
    "\n",
    "Ejemplo a veces tenemos datos en diferents métricas: distancia, superficie, temperatura energía, etc.. o aunque se trata de las mismas métricas se mueven en rangos diferentes. \n",
    "\n",
    "Para que los datos de las diferentes dimensiones sean comparables recurrimos al reescalado de dichas variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estandarización\n",
    "\n",
    "El resultado consiste en dejar nuestros datos con media 0 y varianza 1:\n",
    "\\\\[\n",
    "X_n=\\frac{X-\\mu}{\\sigma}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización\n",
    "\n",
    "\n",
    "Las dos **normalizaciones más comunes** son:\n",
    "\n",
    "Podemos maximizar para dejar todos nuestros datos en el rango [0,1]:\n",
    "\\\\[\n",
    "X_n=\\frac{X- min\\{X\\} }{max\\{X\\}-min\\{X\\}}\n",
    "\\\\]\n",
    "A veces existen variaciones de esta normalización. El máximo y el mínimo puede ser peligroso si tenemos outliers, es posible que primero tengamos que eliminarlos. También podemos utilizar percentiles.\n",
    "\n",
    "Existen infinidad de formas diferentes de normalizar los datos. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo proteinas\n",
    "\n",
    "Dataset extraido de: https://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression\n",
    "\n",
    "El conjunto de datos consiste en los niveles de expresión de 77 proteínas / modificaciones de proteínas que produjeron señales detectables en la fracción nuclear del cortex. Hay 38 ratones de control y 34 ratones trisómicos (síndrome de Down), para un total de 72 ratones. En los experimentos, se registraron 15 mediciones de cada proteína por muestra / ratón. Por lo tanto, para ratones de control, hay 38x15, o 570 mediciones, y para ratones trisómicos, hay 34x15, o 510 mediciones. El conjunto de datos contiene un total de 1080 mediciones por proteína. Cada medida puede considerarse como una muestra / ratón independiente.\n",
    "\n",
    "Las ocho clases de ratones se describen en función de características como el genotipo, el comportamiento y el tratamiento. Según el genotipo, los ratones pueden ser de control o trisómicos. Según el comportamiento, algunos ratones han sido estimulados para aprender (shock de contexto) y otros no (contexto de shock) y para evaluar el efecto del medicamento memantina en la recuperación de la capacidad de aprender en ratones trisómicos, algunos ratones han sido inyectado con la droga y otros no.\n",
    "\n",
    "Clases\n",
    "* c-CS-s: ratones de control, estimulados para aprender, inyectados con solución salina (9 ratones)\n",
    "* c-CS-m: ratones de control, estimulados para aprender, inyectados con memantina (10 ratones)\n",
    "* c-SC-s: ratones de control, no estimulados para aprender, inyectados con solución salina (9 ratones)\n",
    "* c-SC-m: ratones de control, no estimulados para aprender, inyectados con memantina (10 ratones)\n",
    "\n",
    "* t-CS-s: ratones con trisomía, estimulados para aprender, inyectados con solución salina (7 ratones)\n",
    "* t-CS-m: ratones con trisomía, estimulados para aprender, inyectados con memantina (9 ratones)\n",
    "* t-SC-s: ratones con trisomía, no estimulados para aprender, inyectados con solución salina (9 ratones)\n",
    "* t-SC-m: ratones con trisomía, no estimulados para aprender, inyectados con memantina (9 ratones)\n",
    "\n",
    "Los niveles absolutos de expresión de un gen no son comprarables con los de otro. Para hacerlo comparables es necesario que todos los niveles de expresión se muevan en los mismos rangos.\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/1/14/Extended_Central_Dogma_with_Enzymes_gl.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse<-read.csv(\"data/Data_Cortex_Nuclear.csv\")\n",
    "#mouse_data<-mouse[,c(2:78,79)]\n",
    "mouse_data<-mouse[,c(2:78,82)]\n",
    "head(mouse_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que los margenes en los que se mueve el nivel de expresión de cada gen es muy diferente y los hace dificilmente comparables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(mouse_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "options(repr.plot.height=4,repr.plot.width=6)\n",
    "\n",
    "ggplot(mouse_data,aes(x=DYRK1A_N,y=pCAMKII_N,color=class))+geom_point(size=0.1)+ coord_fixed() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras aplicar una normalización podemos comparar su nivel de expresión con mayor claridad y ver que influye en cada clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(pracma)\n",
    "mouse_data_noclass<-mouse_data\n",
    "mouse_data_noclass$class<-NULL\n",
    "gem_m<-colMeans(mouse_data_noclass,na.rm = T)\n",
    "gem_sd<-sapply(mouse_data_noclass, sd,na.rm=T)\n",
    "mnCols<-repmat(gem_m,n = nrow(mouse_data_noclass),m=1)\n",
    "sdCols<-repmat(gem_sd,n = nrow(mouse_data_noclass),m=1)\n",
    "mouse_data_norm<-(mouse_data_noclass-mnCols)/sdCols\n",
    "mouse_data_norm$class<-mouse_data$class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra forma de hacer lo mismo utilizando funciones de R\n",
    "mouse_data_noclass<-mouse_data\n",
    "mouse_data_noclass$class<-NULL\n",
    "\n",
    "mouse_data_norm<-as.data.frame(apply(mouse_data_noclass,2,scale,center=TRUE,scale=TRUE))\n",
    "mouse_data_norm$class<-mouse_data$class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(mouse_data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(mouse_data_norm,aes(x=DYRK1A_N,y=pCAMKII_N,color=class))+geom_point(size=0.1)+ coord_fixed() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo\n",
    "\n",
    "Recuperemos el ejemplo de la predicción de la potencia de generación de una central de ciclo combinado\n",
    "\n",
    "El conjunto de datos contiene 9568 puntos de datos recopilados de una Central de Ciclo Combinado durante 6 años (2006-2011), cuando la planta de energía se puso a funcionar con carga completa. Las características consisten en variables ambientales promedio por hora, Temperatura (T), Presión ambiente (AP), Humedad relativa (HR) y Vacío de escape (V) para predecir la producción neta de energía eléctrica por hora (EP) de la planta.\n",
    "\n",
    "Las características consisten en variables ambientales promedio por hora\n",
    "- Temperatura (AT) en el rango de 1.81 ° C y 37.11 ° C,\n",
    "- Presión ambiental (AP) en el rango de 992.89-1033.30 milibares,\n",
    "- Humedad relativa (HR) en el rango de 25.56% a 100.16%\n",
    "- Vacío de escape (V) en el rango de 25.36-81.56 cm Hg\n",
    "- Producción neta de energía eléctrica por hora (EP) 420.26-495.76 MW\n",
    "\n",
    "Los promedios se toman de varios sensores ubicados alrededor de la planta que registran las variables ambientales cada segundo. Las variables se dan sin normalización.\n",
    "\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant\n",
    "\n",
    "\n",
    "Cada columna, cada variable viene uno un rango de funcionamiento diferente y es dificil comparalro entre ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerplant<-read.csv(\"data/powerplant.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx<-sample(1:nrow(powerplant),nrow(powerplant)*0.7)\n",
    "powerplant.train<-powerplant[idx,]\n",
    "powerplant.test <-powerplant[-idx,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(GGally)\n",
    "options(repr.plot.height=4,repr.plot.width=6)\n",
    "ggpairs(powerplant.train, \n",
    "        lower = list(continuous = wrap(\"density\", alpha = 0.8,size=0.2,color='blue'))\n",
    "       #lower = list(continuous = wrap(\"points\", alpha = 0.3,size=0.1,color='blue'))\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1234)\n",
    "\n",
    "model_powerplant<-lm(PE~.,data=powerplant.train)\n",
    "summary(model_powerplant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerplant.test$pe_est<-predict(model_powerplant,powerplant.test)\n",
    "paste(\"Error cuadrático medio\",sqrt(mean((powerplant.test$PE-powerplant.test$pe_est)^2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos escalar nuestros datos para que todos esten en el mismo rango. \n",
    "\n",
    "Habría que hacerlo solo con los elementos de train, porque se supone que los datos de test no los hemos visto nunca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gem_m<-colMeans(powerplant.train)\n",
    "gem_sd<-sapply(powerplant.train, sd,na.rm=T)\n",
    "mnCols<-repmat(gem_m,n = nrow(powerplant.train),m=1)\n",
    "sdCols<-repmat(gem_sd,n = nrow(powerplant.train),m=1)\n",
    "\n",
    "powerplant_norm.train<- (powerplant.train-mnCols)/sdCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerplant.train_noPE<-powerplant.train\n",
    "powerplant.train_noPE$PE<-NULL\n",
    "gem_m<-colMeans(powerplant.train_noPE)\n",
    "gem_sd<-sapply(powerplant.train_noPE, sd,na.rm=T)\n",
    "mnCols<-repmat(gem_m,n = nrow(powerplant.train_noPE),m=1)\n",
    "sdCols<-repmat(gem_sd,n = nrow(powerplant.train_noPE),m=1)\n",
    "\n",
    "powerplant_norm.train<- (powerplant.train_noPE-mnCols)/sdCols\n",
    "powerplant_norm.train$PE<-powerplant.train$PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggpairs(powerplant_norm.train, \n",
    "        lower = list(continuous = wrap(\"density\", alpha = 0.8,size=0.2,color='blue'))\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_powerplant_norm<-lm(PE~.,data=powerplant_norm.train)\n",
    "summary(model_powerplant_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerplant_norm.train$pe_est<-predict(model_powerplant_norm,powerplant_norm.train)\n",
    "paste(\"Error cuadrático medio\",sqrt(mean((powerplant_norm.train$PE-powerplant_norm.train$pe_est)^2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerplant.test_noPE<-powerplant.test\n",
    "powerplant.test_noPE$PE<-NULL\n",
    "\n",
    "mnCols<-repmat(gem_m,n = nrow(powerplant.test_noPE),m=1)\n",
    "sdCols<-repmat(gem_sd,n = nrow(powerplant.test_noPE),m=1)\n",
    "powerplant_norm.test <- (powerplant.test_noPE-mnCols)/sdCols\n",
    "powerplant_norm.test$PE<-powerplant.test$PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerplant_norm.test$pe_est<-predict(model_powerplant_norm,powerplant_norm.test)\n",
    "paste(\"Error cuadrático medio\",sqrt(mean((powerplant_norm.test$PE-powerplant_norm.test$pe_est)^2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(microbenchmark)\n",
    "set.seed(50)\n",
    "mb<-microbenchmark(lm(PE~.,data=powerplant.train),times=1000)\n",
    "print(mb)\n",
    "set.seed(50)\n",
    "mb<-microbenchmark(lm(PE~.,data=powerplant_norm.train),times=1000)\n",
    "print(mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?microbenchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(50)\n",
    "mb<-microbenchmark(glm(PE~.,data=powerplant.train),times=1000)\n",
    "print(mb)\n",
    "set.seed(50)\n",
    "mb<-microbenchmark(glm(PE~.,data=powerplant_norm.train),times=1000)\n",
    "print(mb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformación de variable\n",
    "\n",
    "A veces se transforma la variable para conseguir que su distribución siga una normal y/o varianza constante. Una de las tecnicas consiste en buscar el parámetro $\\lambda$ que maximiza el estimador de máxima verosimilitud:\n",
    "\n",
    "\\\\[\n",
    "f(y,\\lambda)\\left\\{\\begin{matrix}\n",
    "\\frac{y^\\lambda-1}{\\lambda} ~~ si~~ \\lambda \\neq 0\\\\ \n",
    "log(y) ~~ si~~ \\lambda = 0\\\\ \n",
    "\\end{matrix}\\right.\n",
    "\\\\]\n",
    "Esta transformaxión se suele conocer como la transformación box-cox. Funciona para valores estrictamente positivos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "bx<-boxcox(model_powerplant,lambda=seq(-5,1,length.out = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l<-bx$x[which.max(bx$y)]\n",
    "my_transform<-function(y,l){\n",
    "    (y^l-1)/l\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerplant_transformed.train<-powerplant.train\n",
    "powerplant_transformed.train$PE_tr<-my_transform(powerplant.train$PE,l)\n",
    "model_powerplant_tr<-lm(PE_tr~AT+V+AP+RH,data=powerplant_transformed.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow = c(1,2))\n",
    "qqnorm(y=model_powerplant$residuals,cex=0.1)\n",
    "qqnorm(y=model_powerplant_tr$residuals,cex=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valores no disponibles / Missing Values\n",
    "\n",
    "Son valores para los cuales no tenemos ninguna medida, se representan con un NA.\n",
    "\n",
    "Pertenecen a valores perdidos que no se han podido recuperar, errores de medida, perdidas de datos, etc..\n",
    "\n",
    "En R los detectamos con:\n",
    "\n",
    "is.na(x)\n",
    "y podemos reemplazar su valor con la media, moda, mediana, etc...\n",
    "\n",
    "o simplemente eliminarlos: na.omit(x)\n",
    "\n",
    "Si estamos trabajando con series temporales es posible que queramos hacer una interpolación de los valores perdidos:\n",
    "\n",
    "zoo::na.approx(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data<-c(1,3,NA,6)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is.na(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse<-read.csv(\"data/Data_Cortex_Nuclear.csv\")\n",
    "#mouse_data<-mouse[,c(2:78,79)]\n",
    "summary(mouse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sapply(mouse,function(x) sum(is.na(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which(is.na(mouse$pMTOR_N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_no_na<-na.omit(mouse)\n",
    "nrow(mouse_no_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Los índices que NO ha eliminado son:\n",
    "length(na.action(na.omit(mouse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow(mouse)\n",
    "nrow(na.omit(mouse))\n",
    "nrow(mouse)-nrow(na.omit(mouse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reemplazar su valor por la media de esa columna.\n",
    "\n",
    "Vamos a ver tres formas diferentes de hacer lo mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_data<-mouse[,2:77]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i in 1:ncol(mouse_data)){\n",
    "    mouse_data[,i]<-replace(mouse_data[,i],is.na(mouse_data[,i]),mean(mouse_data[,i],na.rm=T))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_data=as.data.frame(sapply(mouse_data,function(mcol) replace(mcol, is.na(mcol), mean(mcol, na.rm = TRUE))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(zoo)\n",
    "mouse_data=na.aggregate(mouse_data,FUN=mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "\n",
    "Un outlier es una obervación que se encuentra a una distancia **anormal** de otros valores de la muestra.\n",
    "\n",
    "La definición está abierta, todo depende de que datos se quieran descartar (reemplazar por NA). \n",
    "\n",
    "Los podemos identificar mediate diagramas de dispersión o diagramas de cajas.\n",
    "\n",
    "\n",
    "\n",
    "Una forma podría ser considerar outlier todo lo que esté fuera del rango:\n",
    "\\\\[\n",
    "{\\big [}Q_{1}-k(Q_{3}-Q_{1}),Q_{3}+k(Q_{3}-Q_{1}){\\big ]}\n",
    "\\\\]\n",
    "Donde un valor típico de $k$ es 1.5\n",
    " \n",
    "Lo podemos reemplazar por un valor extremo, por la media, moda, etc...o descartarlo al igual que los NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo\n",
    "\n",
    "Datos de tejido mamario con cancer.\n",
    "Las características se calculan a partir de una imagen digitalizada de aspiración con aguja fina (PAAF) de una masa mamaria. Describen las características de los núcleos celulares presentes en la imagen.\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "* 1) ID number \n",
    "* 2) Diagnosis (M = malignant, B = benign) \n",
    "* 3-32) \n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus: \n",
    "\n",
    "* a) radius (mean of distances from center to points on the perimeter) \n",
    "* b) texture (standard deviation of gray-scale values) \n",
    "* c) perimeter \n",
    "* d) area \n",
    "* e) smoothness (local variation in radius lengths) \n",
    "* f) compactness (perimeter^2 / area - 1.0) \n",
    "* g) concavity (severity of concave portions of the contour) \n",
    "* h) concave points (number of concave portions of the contour) \n",
    "* i) symmetry \n",
    "* j) fractal dimension (\"coastline approximation\" - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1234)\n",
    "wdbc<-read.csv(\"data/wdbc.data\",col.names=c(\"id\",\"diagnosis\",paste0(\"c\",1:30)))\n",
    "diagnosis<-wdbc$diagnosis\n",
    "wdbc<-wdbc[,3:ncol(wdbc)]\n",
    "length(wdbc)\n",
    "N<-30\n",
    "#Vamos a añadir outliers:\n",
    "for (i in 1:ncol(wdbc)){\n",
    "    idx_row<-unique(round(runif(N,min = 1,max = nrow(wdbc))))\n",
    "    wdbc[idx_row,i]<-runif(length(idx_row),min=1000,max=10000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot(wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(pracma)\n",
    "mnCols<-repmat(colMeans(wdbc),n = nrow(wdbc),m=1)\n",
    "sdCols<-repmat(sapply(wdbc, sd,na.rm=T),n = nrow(wdbc),m=1)\n",
    "wdbc_norm<-(wdbc-mnCols)/sdCols\n",
    "wdbc_norm$diagnosis<-diagnosis\n",
    "\n",
    "#summary(wdbc)\n",
    "idx<-sample(1:nrow(wdbc),round(nrow(wdbc)*0.7))\n",
    "wdbc.train_norm<-wdbc_norm[idx,]\n",
    "wdbc.test_norm<-wdbc_norm[-idx,]\n",
    "\n",
    "\n",
    "model_wdbc<-glm(data=wdbc.train_norm,formula=diagnosis~.,family=binomial(link='logit'))   \n",
    "y_predict<-predict(model_wdbc,wdbc.test_norm)\n",
    "y_factor<-as.factor(ifelse(y_predict<0,\"B\",\"M\"))\n",
    "\n",
    "table(y_factor,wdbc.test_norm$diagnosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for (i in 1:ncol(wdbc)){\n",
    "    x <- wdbc[,i]\n",
    "    qnt  <- quantile(x, probs=c(.25, .75), na.rm = T)\n",
    "    caps <- quantile(x, probs=c(.1, .90), na.rm = T)    \n",
    "    H <- 10 * IQR(x, na.rm = T)\n",
    "    x[x < (qnt[1] - H)] <- caps[1]\n",
    "    x[x > (qnt[2] + H)] <- caps[2]\n",
    "    wdbc[,i]<-x\n",
    "}\n",
    "\n",
    "mnCols<-repmat(colMeans(wdbc),n = nrow(wdbc),m=1)\n",
    "sdCols<-repmat(sapply(wdbc, sd,na.rm=T),n = nrow(wdbc),m=1)\n",
    "wdbc_norm<-(wdbc-mnCols)/sdCols\n",
    "wdbc_norm$diagnosis<-diagnosis\n",
    "\n",
    "idx<-sample(1:nrow(wdbc),round(nrow(wdbc)*0.7))\n",
    "wdbc.train_norm <- wdbc_norm[ idx,]\n",
    "wdbc.test_norm  <- wdbc_norm[-idx,]\n",
    "\n",
    "model_wdbc<-glm(data=wdbc.train_norm,formula=diagnosis~.,family=binomial(link='logit'))   \n",
    "\n",
    "y_predict<-predict(model_wdbc,wdbc.test_norm)\n",
    "y_factor<-as.factor(ifelse(y_predict<0,\"B\",\"M\"))\n",
    "\n",
    "table(y_factor,wdbc.test_norm$diagnosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
