{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_path = '../datasets'\n",
    "neil_degrasse_csv = 'datasets_241_800048_NeildeGrasseTysonTweets.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(tweets_path, neil_degrasse_csv))\n",
    "df.dropna(subset=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "for t in df['text']:\n",
    "    text += ' ' + t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Moon’s shadow landfalls Oregon, crosses USA at 1800mph, exits SCarolina. Behold ‘Muuurica’s Eclipse.pic.twitter.com/fIMCnEyyQy @huggy_panda  Oink, oink.   : - ) Future headlines from the Multiverse: Nov 9, 2016: “Trump: How I Got Hillary Elected while Dismantling the Republican Party.” Awww. That’s the nicest thing anybody has said to me in a long while.https://twitter.com/ayeshatron/status/784441432652320769\\xa0… If ComicCon people ruled the world, international conflicts would be resolved entirely by plastic  light saber fights in bars On Pluto, with its 248-year orbit around the Sun, birthdays are incompatible with human physiology. @ivychat Maybe I‘m floating in an atmospheric balloon in Saturn’s atmosphere. The urge to want some bit of information to be true often clouds our ability to assess why that information may be false. Evidence that internet Cats are rapidly achieving cosmic consciousness, soon to become our Overlords:https://www.youtube.com/watch?v=LJSH6Ru1xRk&feature=share'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación del train y test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(list(set(text)))\n",
    "n_to_char = {n:char for n, char in enumerate(characters)}\n",
    "char_to_n = {char:n for n, char in enumerate(characters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "length = len(text)\n",
    "seq_length = 100\n",
    "for i in range(0, length-seq_length, 1):\n",
    "    sequence = text[i:i + seq_length]\n",
    "    label =text[i + seq_length]\n",
    "    X.append([char_to_n[char] for char in sequence])\n",
    "    Y.append(char_to_n[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formateo de los datos para la entrada en la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
    "X_modified = X_modified / float(len(characters))\n",
    "Y_modified = np_utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de un modelo sencillo durante 1 época"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 106)               10706     \n",
      "=================================================================\n",
      "Total params: 131,906\n",
      "Trainable params: 131,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 267682 samples, validate on 14089 samples\n",
      "Epoch 1/1\n",
      "267682/267682 [==============================] - 683s 3ms/step - loss: 3.2434 - acc: 0.1723 - val_loss: 3.0771 - val_acc: 0.1927\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_modified, Y_modified, validation_split=0.05, batch_size=128, epochs=1, shuffle=True).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save('../models/simple_model_1e.h5')\n",
    "pickle.dump(history, open('../models/simple_model_1e_history.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de un modelo sencillo durante 10 épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 106)               10706     \n",
      "=================================================================\n",
      "Total params: 131,906\n",
      "Trainable params: 131,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 267682 samples, validate on 14089 samples\n",
      "Epoch 1/10\n",
      "267682/267682 [==============================] - 654s 2ms/step - loss: 3.2185 - acc: 0.1753 - val_loss: 3.0725 - val_acc: 0.1923\n",
      "Epoch 2/10\n",
      "267682/267682 [==============================] - 665s 2ms/step - loss: 3.0647 - acc: 0.1924 - val_loss: 3.0095 - val_acc: 0.2081\n",
      "Epoch 3/10\n",
      "267682/267682 [==============================] - 635s 2ms/step - loss: 3.0064 - acc: 0.2032 - val_loss: 2.9680 - val_acc: 0.2138\n",
      "Epoch 4/10\n",
      "267682/267682 [==============================] - 633s 2ms/step - loss: 2.9510 - acc: 0.2139 - val_loss: 2.9309 - val_acc: 0.2148\n",
      "Epoch 5/10\n",
      "267682/267682 [==============================] - 635s 2ms/step - loss: 2.9090 - acc: 0.2209 - val_loss: 2.9043 - val_acc: 0.2210\n",
      "Epoch 6/10\n",
      "267682/267682 [==============================] - 635s 2ms/step - loss: 2.8783 - acc: 0.2267 - val_loss: 2.8864 - val_acc: 0.2222\n",
      "Epoch 7/10\n",
      "267682/267682 [==============================] - 639s 2ms/step - loss: 2.8532 - acc: 0.2318 - val_loss: 2.8652 - val_acc: 0.2304\n",
      "Epoch 8/10\n",
      "267682/267682 [==============================] - 638s 2ms/step - loss: 2.8329 - acc: 0.2360 - val_loss: 2.8508 - val_acc: 0.2339\n",
      "Epoch 9/10\n",
      "267682/267682 [==============================] - 691s 3ms/step - loss: 2.8102 - acc: 0.2410 - val_loss: 2.8367 - val_acc: 0.2328\n",
      "Epoch 10/10\n",
      "267682/267682 [==============================] - 687s 3ms/step - loss: 2.7893 - acc: 0.2448 - val_loss: 2.8237 - val_acc: 0.2366\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_modified, Y_modified, validation_split=0.05, batch_size=128, epochs=10, shuffle=True).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/simple_model_10e.h5')\n",
    "pickle.dump(history, open('../models/simple_model_10e_history.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    " def generate_text(model, string_id):\n",
    "    string_mapped = deepcopy(string_id)\n",
    "    full_string = [n_to_char[value] for value in string_mapped]\n",
    "    \n",
    "    # Generating characters\n",
    "    for i in range(400):\n",
    "        x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
    "        x = x / float(len(characters))\n",
    "\n",
    "        pred_index = np.argmax(model.predict(x, verbose=0))\n",
    "        seq = [n_to_char[value] for value in string_mapped]\n",
    "        full_string.append(n_to_char[pred_index])\n",
    "\n",
    "        string_mapped.append(pred_index)\n",
    "        string_mapped = string_mapped[1:len(string_mapped)]\n",
    "        \n",
    "    text = \"\"\n",
    "    for char in full_string:\n",
    "        text = text + char\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_1e = load_model('../models/simple_model_1e.h5')\n",
    "model_10e = load_model('../models/simple_model_10e.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alls Oregon, crosses USA at 1800mph, exits SCarolina. Behold ‘Muuurica’s Eclipse.pic.twitter.com/fIM     00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "model_1e_results = generate_text(model_1e, X[20])\n",
    "print(model_1e_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alls Oregon, crosses USA at 1800mph, exits SCarolina. Behold ‘Muuurica’s Eclipse.pic.twitter.com/fIMmmmm Co the aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe the wou aoe \n"
     ]
    }
   ],
   "source": [
    "model_10e_results = generate_text(model_10e, X[20])\n",
    "print(model_10e_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "\n",
    "El presente ejercicio tenía como objetivo el del entenar de primera mano redes neuronales y, más que conseguir un modelo perfecto, enfrentarse a los retos que se presentan ante resultados como los anteriormente presentados.\n",
    "\n",
    "También, otro objetivo era el de presentar una representación del texto distinta a la vista en los problemas de clasificación tradicionales (spam, sentiment, ...) a la hora de trabajar con textos y redes neuronales.\n",
    "\n",
    "Dada una arquitectura de red, a mayor número de épocas el modelo aprende poco a poco la estructura del lenguaje. Modelos más complejos serán capaces, teóricamente, de aprender mayor número de estructuras en el lenguaje y de mayor complejidad. De hecho, está probado como modelos basados en Deep Learning son capaces de aprender reglas morfológicas, reglas sintácticas, o la semántica de un corpus. Está probado también que distintas partes de la red (capas) aprenden diferentes partes (por ejemplo, las primeras capas extraerían información morfológica y capas más profundas serían capaces de aprender la semántica).\n",
    "\n",
    "Este tipo de modelos, cuando se presentan en demos como las múltiples que existen de GPT-2, son verdaderamente complejos de entrenar. Entre otros, algunas limitaciones claras son (se espera que el alumno las haya podido intuir durante la realización del ejercicio):\n",
    "- Disponibilidad de datos\n",
    "- Formato de los datos\n",
    "- ¿Con qué datos / chunks entrenamos? ¿Predecimos un carácter? ¿Varios? ¿La longitud importa?\n",
    "- Diferencia entre entrenar un modelo de NLG para Twitter que para otro caso de uso (un teclado predictivo, un generador de resúmenes, etc.)\n",
    "- La complejidad en la validación\n",
    "- Necesidad de GPUs (o incluso TPUs) para entrenar de manera eficiente estos modelos\n",
    "- Una vez se tiene un modelo con un alto performance, ¿es realmente un buen modelo o un loro que repite todo lo que ha aprendido?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
