{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importamos las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargamos un modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2v_sg = Word2Vec.load('../../data/w2v_sg_d300_mc5_w5.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_sg.wv.most_similar('comer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos _clusters_ de palabras con las más similares a unas dadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['comida', 'comer', 'agua', 'elecciones', 'brexit']\n",
    "\n",
    "embedding_clusters = []\n",
    "word_clusters = []\n",
    "for word in keys:\n",
    "    embeddings = []\n",
    "    words = []\n",
    "    for similar_word, _ in w2v_sg.wv.most_similar(word, topn=5):\n",
    "        words.append(similar_word)\n",
    "        embeddings.append(w2v_sg.wv[similar_word])\n",
    "    embedding_clusters.append(embeddings)\n",
    "    word_clusters.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embedding_clusters[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducimos dimensionalidad a 2D para poder representar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_model_2d = TSNE(perplexity=15, n_components=2, init='pca', n_iter=3500, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_clusters = np.array(embedding_clusters)\n",
    "n, m, k = embedding_clusters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_2d = np.array(tsne_model_2d.fit_transform(embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def tsne_plot_similar_words(labels, embedding_clusters, word_clusters, a=0.7):\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(labels)))\n",
    "    for label, embeddings, words, color in zip(labels, embedding_clusters, word_clusters, colors):\n",
    "        x = embeddings[:,0]\n",
    "        y = embeddings[:,1]\n",
    "        plt.scatter(x, y, c=[color], alpha=a, label=label)\n",
    "        for i, word in enumerate(words):\n",
    "            plt.annotate(word, alpha=0.5, xy=(x[i], y[i]), xytext=(5, 2), \n",
    "                         textcoords='offset points', ha='right', va='bottom', size=8)\n",
    "    plt.legend(loc=4)\n",
    "    plt.grid(True)\n",
    "    plt.title('Representación en 2D de los embeddings de algunos clusters de palabras')\n",
    "    # plt.savefig(\"f/г.png\", format='png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "tsne_plot_similar_words(keys, embeddings_2d, word_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding projector online\n",
    "\n",
    "Permite cargar un fichero TSV con los word embeddings pre-calculados y representarlos en una representación interactiva en 3D. \n",
    "\n",
    "La reducción de dimensionalidad puede realizarse mediante UMAP, t-SNE o PCA.\n",
    "\n",
    "Además, permite cargar los vectores con metadata como, por ejemplo, variables categóricas, que permitirán visualizar los topics / clusters en el espacio de 3D.\n",
    "\n",
    "https://projector.tensorflow.org\n",
    "\n",
    "<img src=https://i.ytimg.com/vi/y2rEqxzqOkM/maxresdefault.jpg>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
