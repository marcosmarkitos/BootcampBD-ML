{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from utils import load_cinema_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path al directorio donde tenemos los datasets con las reviews\n",
    "# ¡Descomprimir antes!\n",
    "datasets_path = '../../datasets'\n",
    "corpus_cine_folder = 'corpusCine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_dict = load_cinema_reviews(datasets_path, corpus_cine_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(reviews_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reviews_dict.get(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase String\n",
    "\n",
    "Clase nativa de Python que íncorpora utilidades para procesado de texto.\n",
    "\n",
    "Enlace a los distintos métodos: [link](https://www.w3schools.com/python/python_ref_string.asp). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = reviews_dict.get(10).get('review_text')\n",
    "print(review[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences = review.split('.')\n",
    "print(sentences[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = sentences[2]\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, word in enumerate(sentence.split(' ')):\n",
    "    print('Palabra {0:5}{1:5}'.format(str(idx), word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convertir a minúsculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convertir a mayúsculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminar espacios al inicio y al final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solo minúsculas y números\n",
    "import re\n",
    "re.sub(r'[^a-z0-9]+', ' ', sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solo números\n",
    "# Quedarse solo con números\n",
    "import re\n",
    "re.sub('[^0-9]+', ' ', sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminar puntuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "' '.join([word.translate(table) for word in sentence.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminar acentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_with_accents = 'Téxtô Ácěntuado ñ'\n",
    "unicodedata.normalize('NFKD', text_with_accents).encode('ascii', 'ignore').decode('utf-8', 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convertir números a texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from num2words import num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num2words(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num2words(2, lang='es', ordinal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num2words(2, lang='es', ordinal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[word if not word.isdigit() else num2words(word, lang='es', ordinal=False) for word in 'Hoy es 29 de junio de 2020'.split(' ')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Palabras con - a priori - ningún significado o que aportan muy poca información. Suelen ser palabras muy comunes como, por ejemplo, preposiciones.\n",
    "\n",
    "En NLP se suele trabajar con vocabularios enormes (en _Don Quijote de la Mancha_ aparecen en torno a **23.000 palabras distintas**) por lo que interesa filtras aquellas que menos información aporten.\n",
    "\n",
    "Debate: ¿qué significa que _aporten información_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sw_list = get_stop_words('es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_no_sw = ' '.join([word for word in sentence.split() if word not in sw_list])\n",
    "\n",
    "print('Frase completa:\\n{}\\n'.format(sentence))\n",
    "print('Frase sin stopwords:\\n{}'.format(sentence_no_sw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Técnica de normalización de textos que busca reducir las palabras a su raíz (lemma).\n",
    "\n",
    "Muy utilizado para reducir la cardinalidad del vocabulario asociando para diferentes formas flexionadas un único token ('entreno', 'entrenarás', 'entrenaría' -> 'entrenar').\n",
    "\n",
    "Aunque muy utilizados en motores de búsqueda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../data'\n",
    "lemmas_dict_file = 'lemmatization-es.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemmas_dict():\n",
    "    lemmas_dict = {}\n",
    "    with open(os.path.join(data_path, lemmas_dict_file), 'r') as f:\n",
    "        for line in f:\n",
    "            (key, val) = line.split()\n",
    "            lemmas_dict[str(val)] = key\n",
    "    return lemmas_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_dict = get_lemmas_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_dict.get('comieron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_dict.get('mama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_dict.get('cinco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentence_lemmatized = ' '.join([lemmas_dict.get(word, word) for word in sentence.split()])\n",
    "\n",
    "print('{0:15}{1:10}'.format('Token' ,'Lemma'))\n",
    "for word in sentence.split():\n",
    "    print('{0:15}{1:10}'.format(word, lemmas_dict.get(word, word)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Palabras más frecuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "freq_text = 'Palabras con - a priori - ningún significado o que aportan muy poca' + \\\n",
    "            'información. Suelen ser palabras muy comunes como, por ejemplo,' + \\\n",
    "            ' preposiciones. En NLP se suele trabajar con vocabularios enormes' + \\\n",
    "            '(en Don Quijote de la Mancha aparecen en torno a 23.000 palabras distintas)' + \\\n",
    "            'por lo que interesa filtras aquellas que menos información aporten.' + \\\n",
    "            'Debate: ¿qué significa que aporten información?'\n",
    "\n",
    "word_freqs = Counter(freq_text.lower().split())\n",
    "word_freqs.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
