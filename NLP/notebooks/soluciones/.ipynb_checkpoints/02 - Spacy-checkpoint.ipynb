{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy\n",
    "\n",
    "spaCy es otra librería open source en Python para NLP.\n",
    "\n",
    "La diferencia fundamental entre NLTK y spaCy es que el primero es muy cómodo para aprender e iniciarse mientras que el segundo está pensado para productizar.\n",
    "\n",
    "Gensim, otra librería, la veremos más adelante cuando estudiemos Topic Modeling y Word Embeddings.\n",
    "\n",
    "Documentación de spaCy: https://spacy.io/\n",
    "\n",
    "La filosofía de trabajo en spaCy es que si existen una serie de algoritmos que solucionan un problema, dar la solución al problema con un único. Además, su funcionamiento se basa en la construcción de pipelines.\n",
    "\n",
    "\n",
    "<img src=https://i.imgur.com/nD7ut2U.jpg>\n",
    "\n",
    "¿Qué capacidades (modelos) linguísticas nos ofrece spaCy?\n",
    "\n",
    "<img src=https://i.imgur.com/lGcL6lx.jpg>\n",
    "\n",
    "Es decir, de spaCy podremos sacar siempre que queramos tokens, pos tags, árboles de dependencia, o entidades nombradas. Incluye también modelos de word embeddings (que veremos con más detalle en sesiones posteriores)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://spacy.io/architecture-bcdfffe5c0b9f221a2f6607f96ca0e4a.svg width=550px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de spaCy\n",
    "\n",
    "Modelos pre-entrenados para diferentes idiomas y con diferentes corpus. Pueden ser descargados de diferentes maneras, tanto descarga directa, como con pip.\n",
    "\n",
    "Link: https://spacy.io/usage/models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download es_core_news_sm\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz --no-deps\n",
    "# pip install https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.3.0/es_core_news_sm-2.3.0.tar.gz#egg=es_core_news_sm==2.3.0 --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U spacy download es_core_news_sm\n",
    "# !pip install -U spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# import es_core_news_sm\n",
    "# import en_core_web_sm\n",
    "\n",
    "# nlp_es = es_core_news_sm.load()\n",
    "# nlp_en = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Modelo \"pequeño\" entrenado con noticias en castellano\n",
    "# https://spacy.io/models/es\n",
    "nlp_es = spacy.load('es_core_news_sm')\n",
    "\n",
    "# Modelo \"pequeño\" entrenado con página\n",
    "# https://spacy.io/models/en\n",
    "nlp_en = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x12329ae90>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x10efd0f30>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x120db24b0>)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline del modelo por defecto\n",
    "nlp_es.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelines en spaCy:\n",
    "https://spacy.io/usage/processing-pipelines\n",
    "\n",
    "<img src=https://d33wubrfki0l68.cloudfront.net/16b2ccafeefd6d547171afa23f9ac62f159e353d/48b91/pipeline-7a14d4edd18f3edfee8f34393bff2992.svg width=700px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Mi nombre es Carlos y vivo en Madrid. Hoy es lunes 29 de junio'\n",
    "doc = nlp_es(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mi nombre es Carlos y vivo en Madrid. Hoy es lunes 29 de junio"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mi nombre es Carlos y vivo en Madrid. Hoy es lunes 29 de junio\n"
     ]
    }
   ],
   "source": [
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase 0    Mi nombre es Carlos y vivo en Madrid.\n",
      "Frase 1    Hoy es lunes 29 de junio\n"
     ]
    }
   ],
   "source": [
    "for idx, sent in enumerate(doc.sents):\n",
    "    print('Frase {0:5}{1:5}'.format(str(idx), sent.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token 0    Mi   \n",
      "Token 1    nombre\n",
      "Token 2    es   \n",
      "Token 3    Carlos\n",
      "Token 4    y    \n",
      "Token 5    vivo \n",
      "Token 6    en   \n",
      "Token 7    Madrid\n",
      "Token 8    .    \n",
      "Token 9    Hoy  \n",
      "Token 10   es   \n",
      "Token 11   lunes\n",
      "Token 12   29   \n",
      "Token 13   de   \n",
      "Token 14   junio\n"
     ]
    }
   ],
   "source": [
    "for idx, token in enumerate(doc):\n",
    "    print('Token {0:5}{1:5}'.format(str(idx), token.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token     Shape     is_alpha\n",
      "Mi        Xx        True \n",
      "nombre    xxxx      True \n",
      "es        xx        True \n",
      "Carlos    Xxxxx     True \n",
      "y         x         True \n",
      "vivo      xxxx      True \n",
      "en        xx        True \n",
      "Madrid    Xxxxx     True \n",
      ".         .         False\n",
      "Hoy       Xxx       True \n",
      "es        xx        True \n",
      "lunes     xxxx      True \n",
      "29        dd        False\n",
      "de        xx        True \n",
      "junio     xxxx      True \n"
     ]
    }
   ],
   "source": [
    "print('{0:10}{1:10}{2:5}'.format('Token', 'Shape', 'is_alpha'))\n",
    "for token in doc:\n",
    "    print('{0:10}{1:10}{2:5}'.format(token.text, token.shape_, str(token.is_alpha)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalización de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '  Mi   nombre es Carlos y vivo en Madrid. Hoy es lunes 29 de junio  '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " 'Mi',\n",
       " '',\n",
       " '',\n",
       " 'nombre',\n",
       " 'es',\n",
       " 'Carlos',\n",
       " 'y',\n",
       " 'vivo',\n",
       " 'en',\n",
       " 'Madrid.',\n",
       " 'Hoy',\n",
       " 'es',\n",
       " 'lunes',\n",
       " '29',\n",
       " 'de',\n",
       " 'junio',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separar por espacios\n",
    "text.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quiénes', 'están', 'cosas', 'informó', 'solamente', 'allí', 'encima', 'embargo', 'pero', 'antes', 'usa', 'su', 'existe', 'ahi', 'muchos', 'hacer', 'podrán', 'muy', 'trabajamos', 'vuestros']\n"
     ]
    }
   ],
   "source": [
    "# Eliminar stop words\n",
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "\n",
    "print(list(STOP_WORDS)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['frase', 'a', 'eliminar', 'stopwords']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_text_1 = 'Soy una frase de ejemplo de la cual vamos a eliminar los stopwords'\n",
    "[word for word in ex_text_1.lower().split() if word not in STOP_WORDS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debate: ¿Pensáis que, en general, se deben filtrar los stopwords?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gusta', 'canción']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_text_2 = 'No me gusta esta canción'\n",
    "[word for word in ex_text_2.lower().split() if word not in STOP_WORDS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech tagging\n",
    "\n",
    "El PoS Tagging es una técnica **fundamental** en NLP que consiste en etiquetar cada palabra de un documento en su correspondiente categría gramatical.\n",
    "\n",
    "<img src=https://blog.aaronccwong.com/assets/images/bigram-hmm/pos-title.jpg width=650px>\n",
    "\n",
    "¿Utilidad? Muchísima:\n",
    "\n",
    "- Posibilidad de encontrar los adjetivos / sustantivos /adverbios más comunes\n",
    "- _Ayuda_ a Lemmatizers al desambiguar entre palabras\n",
    "- Grafos en los que los nodos son entidades y verbos. Posibilidad de analizar relaciones entre entidades -> Pintar ejemplo\n",
    "- Posibles features (la distribución de categorías no siempre es homogénea en función del contexto)\n",
    "\n",
    "Podríamos hacer un algoritmo que mirara verbos entre otras entidades, como nombres o adjetivos, y que fuera el verbo quien decidiera que relación tienen esas entidades. Eso se suele hacer para crear bases de datos de grafos, donde cada nodo es una entidad, y entre entidades hay relaciones.\n",
    "\n",
    "Veamos algún ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atributos (https://spacy.io/api/token#attributes):\n",
    "- pos_: tipo de palabra (sustantivo, verbo, adjetivo, etc)\n",
    "- tag_: tipo de palabra especificando más atributos\n",
    "- dep_: relación de dependencia sintáctica\n",
    "\n",
    "Explicación de los términos:\n",
    "https://github.com/explosion/spaCy/blob/master/spacy/glossary.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token     pos       \n",
      "Mi        DET       \n",
      "nombre    NOUN      \n",
      "es        AUX       \n",
      "Carlos    PROPN     \n",
      "y         CONJ      \n",
      "vivo      ADJ       \n",
      "en        ADP       \n",
      "Madrid    PROPN     \n",
      ".         PUNCT     \n",
      "Hoy       ADV       \n",
      "es        AUX       \n",
      "lunes     NOUN      \n",
      "29        NUM       \n",
      "de        ADP       \n",
      "junio     NOUN      \n"
     ]
    }
   ],
   "source": [
    "print('{0:10}{1:10}'.format('Token', 'pos'))\n",
    "for idx, token in enumerate(doc):\n",
    "    print('{0:10}{1:10}'.format(token.text, token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token     tag       \n",
      "Mi        DET__Number=Sing|Number[psor]=Sing|Person=1|Poss=Yes|PronType=Prs\n",
      "nombre    NOUN__Gender=Masc|Number=Sing\n",
      "es        AUX__Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "Carlos    PROPN___  \n",
      "y         CCONJ___  \n",
      "vivo      ADJ__Gender=Masc|Number=Sing\n",
      "en        ADP__AdpType=Prep\n",
      "Madrid    PROPN___  \n",
      ".         PUNCT__PunctType=Peri\n",
      "Hoy       ADV___    \n",
      "es        AUX__Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "lunes     NOUN___   \n",
      "29        NUM__NumForm=Digit|NumType=Card\n",
      "de        ADP__AdpType=Prep\n",
      "junio     NOUN___   \n"
     ]
    }
   ],
   "source": [
    "print('{0:10}{1:10}'.format('Token', 'tag'))\n",
    "for idx, token in enumerate(doc):\n",
    "    print('{0:10}{1:10}'.format(token.text, token.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token     dep       Meaning   \n",
      "Mi        det       determiner\n",
      "nombre    nsubj     nominal subject\n",
      "es        cop       copula    \n",
      "Carlos    ROOT      None      \n",
      "y         cc        coordinating conjunction\n",
      "vivo      conj      conjunct  \n",
      "en        case      None      \n",
      "Madrid    nmod      modifier of nominal\n",
      ".         punct     punctuation\n",
      "Hoy       advmod    adverbial modifier\n",
      "es        cop       copula    \n",
      "lunes     ROOT      None      \n",
      "29        compound  None      \n",
      "de        case      None      \n",
      "junio     compound  None      \n"
     ]
    }
   ],
   "source": [
    "print('{0:10}{1:10}{2:10}'.format('Token', 'dep', 'Meaning'))\n",
    "for idx, token in enumerate(doc):\n",
    "    print('{0:10}{1:10}{2:10}'.format(token.text, token.dep_, str(spacy.explain(token.dep_))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencia sintáctica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"es\" id=\"092f91242ce243518784802b019c66a7-0\" class=\"displacy\" width=\"1450\" height=\"237.0\" direction=\"ltr\" style=\"max-width: none; height: 237.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Mi</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">nombre</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">es</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">Carlos</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">y</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">CONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">vivo</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">en</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Madrid.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">Hoy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">es</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1050\">lunes</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1050\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">29</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">de</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1350\">junio</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1350\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-092f91242ce243518784802b019c66a7-0-0\" stroke-width=\"2px\" d=\"M70,102.0 C70,52.0 145.0,52.0 145.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-092f91242ce243518784802b019c66a7-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,104.0 L62,92.0 78,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-092f91242ce243518784802b019c66a7-0-1\" stroke-width=\"2px\" d=\"M170,102.0 C170,2.0 350.0,2.0 350.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-092f91242ce243518784802b019c66a7-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M170,104.0 L162,92.0 178,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-092f91242ce243518784802b019c66a7-0-2\" stroke-width=\"2px\" d=\"M270,102.0 C270,52.0 345.0,52.0 345.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-092f91242ce243518784802b019c66a7-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cop</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M270,104.0 L262,92.0 278,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-092f91242ce243518784802b019c66a7-0-3\" stroke-width=\"2px\" d=\"M470,102.0 C470,52.0 545.0,52.0 545.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-092f91242ce243518784802b019c66a7-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M470,104.0 L462,92.0 478,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-092f91242ce243518784802b019c66a7-0-4\" stroke-width=\"2px\" d=\"M370,102.0 C370,2.0 550.0,2.0 550.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-092f91242ce243518784802b019c66a7-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M550.0,104.0 L558.0,92.0 542.0,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-092f91242ce243518784802b019c66a7-0-5\" stroke-width=\"2px\" d=\"M670,102.0 C670,52.0 745.0,52.0 745.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-092f91242ce243518784802b019c66a7-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M670,104.0 L662,92.0 678,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-092f91242ce243518784802b019c66a7-0-6\" stroke-width=\"2px\" d=\"M570,102.0 C570,2.0 750.0,2.0 750.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-092f91242ce243518784802b019c66a7-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,104.0 L758.0,92.0 742.0,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-092f91242ce243518784802b019c66a7-0-7\" stroke-width=\"2px\" d=\"M870,102.0 C870,2.0 1050.0,2.0 1050.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-092f91242ce243518784802b019c66a7-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M870,104.0 L862,92.0 878,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-092f91242ce243518784802b019c66a7-0-8\" stroke-width=\"2px\" d=\"M970,102.0 C970,52.0 1045.0,52.0 1045.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-092f91242ce243518784802b019c66a7-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cop</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M970,104.0 L962,92.0 978,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-092f91242ce243518784802b019c66a7-0-9\" stroke-width=\"2px\" d=\"M1070,102.0 C1070,52.0 1145.0,52.0 1145.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-092f91242ce243518784802b019c66a7-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1145.0,104.0 L1153.0,92.0 1137.0,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-092f91242ce243518784802b019c66a7-0-10\" stroke-width=\"2px\" d=\"M1270,102.0 C1270,52.0 1345.0,52.0 1345.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-092f91242ce243518784802b019c66a7-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270,104.0 L1262,92.0 1278,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-092f91242ce243518784802b019c66a7-0-11\" stroke-width=\"2px\" d=\"M1170,102.0 C1170,2.0 1350.0,2.0 1350.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-092f91242ce243518784802b019c66a7-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1350.0,104.0 L1358.0,92.0 1342.0,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de entidades nombradas (NER)\n",
    "\n",
    "El reconocimiento de entidades nombradas (Named Entity Recognition, NER, por sus siglas en inglés) trata de detectar posibles entidades nombradas y, posteriormente, clasificarlas entre un conjunto de categorías predefinidas.\n",
    "\n",
    "Ejemplos de entidades nombradas: nombres de personas, lugares, cantidades, empresas...\n",
    "\n",
    "Pero, ¿qué es exactamente una _entidad nombrada_? Según definió Saul Kripke * (filósofo y lógico) son - o deberían ser - todas aquellas entidades para las cuales existe uno - o más de uno - designador rígido. Es decir, dicha palabra / expresión se refiere a la misma cosa / entidad con independencia del contexto.\n",
    "\n",
    "<img src=https://hyscore.io/wp-content/uploads/2019/03/illustration_named_entity_recognition-1024x486-1.jpg width=700px>\n",
    "\n",
    "El rendimiento de los NER varía mucho en función del idioma en el que han sido entrenados. El rendimiento que se comienza a obtener (debido principalmente al uso de modelos de embeddings contextuales) supera al de un ser humano.\n",
    "\n",
    "Un enlace intersante: https://primer.ai/blog/a-new-state-of-the-art-for-named-entity-recognition/\n",
    "\n",
    "* _El nombrar y la necesidad_ (Saul Kripke), 1980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Jim\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " compró 300 acciones de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Acme Corp\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ". en 20</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_ner_1 = nlp_es('Jim compró 300 acciones de Acme Corp. en 2006')\n",
    "displacy.render(doc_ner_1, style='ent', jupyter=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Peter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " bought \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    300\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " shares of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Acme Corp.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    2006\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_ner_2 = nlp_en('Peter bought 300 shares of Acme Corp. in 2006')\n",
    "displacy.render(doc_ner_2, style='ent', jupyter=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I heard that \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Paris Hilton\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " stayed at the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Hilton\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Paris\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_ner_2 = nlp_en('I heard that Paris Hilton stayed at the Hilton in Paris')\n",
    "displacy.render(doc_ner_2, style='ent', jupyter=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token     Entity Label\n",
      "Jim       PER       \n",
      "Acme Corp PER       \n"
     ]
    }
   ],
   "source": [
    "print('{0:10}{1:10}'.format('Token', 'Entity Label'))\n",
    "for entity in doc_ner_1.ents:\n",
    "    print('{0:10}{1:10}'.format(entity.text, entity.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token     Entity Label\n",
      "Paris HiltonORG       \n",
      "Hilton    ORG       \n",
      "Paris     GPE       \n"
     ]
    }
   ],
   "source": [
    "print('{0:10}{1:10}'.format('Token', 'Entity Label'))\n",
    "for entity in doc_ner_2.ents:\n",
    "    print('{0:10}{1:10}'.format(entity.text, entity.label_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "\n",
    "Técnica de normalización de textos que busca reducir las palabras a su raíz (lemma).\n",
    "\n",
    "Muy utilizado para reducir la cardinalidad del vocabulario asociando para diferentes formas flexionadas un único token ('entreno', 'entrenarás', 'entrenaría' -> 'entrenar').\n",
    "\n",
    "Aunque muy utilizados en motores de búsqueda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token     Lemma     PoS Tag   \n",
      "Mi        Mi        DET       \n",
      "nombre    nombrar   NOUN      \n",
      "es        ser       AUX       \n",
      "Carlos    Carlos    PROPN     \n",
      "y         y         CONJ      \n",
      "vivo      vivir     ADJ       \n",
      "en        en        ADP       \n",
      "Madrid    Madrid    PROPN     \n",
      ".         .         PUNCT     \n",
      "Hoy       Hoy       ADV       \n",
      "es        ser       AUX       \n",
      "lunes     lunes     NOUN      \n",
      "29        29        NUM       \n",
      "de        de        ADP       \n",
      "junio     junio     NOUN      \n"
     ]
    }
   ],
   "source": [
    "print('{0:10}{1:10}{2:10}'.format('Token', 'Lemma', 'PoS Tag'))\n",
    "for idx, token in enumerate(doc):\n",
    "    print('{0:10}{1:10}{2:10}'.format(token.text, token.lemma_, token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 2\n",
      "Token     Lemma     PoS Tag   \n",
      "comer     comer     AUX       \n",
      "comiendo  comer     VERB      \n",
      "comieron  comer     VERB      \n",
      "comedor   comedor   ADJ       \n",
      "comeré    comer     VERB      \n",
      "comerá    comer     VERB      \n",
      "comerás   comer     NOUN      \n",
      "\n",
      "Text 3\n",
      "Token     Lemma     PoS Tag   \n",
      "comerás   comer     VERB      \n"
     ]
    }
   ],
   "source": [
    "text_2 = 'comer comiendo comieron comedor comeré comerá comerás'\n",
    "text_3 = 'comerás'\n",
    "doc_2 = nlp_es(text_2)\n",
    "doc_3 = nlp_es(text_3)\n",
    "\n",
    "\n",
    "print('Text 2')\n",
    "print('{0:10}{1:10}{2:10}'.format('Token', 'Lemma', 'PoS Tag'))\n",
    "for idx, token in enumerate(doc_2):\n",
    "    print('{0:10}{1:10}{2:10}'.format(token.text, token.lemma_, token.pos_))\n",
    "\n",
    "print('\\nText 3')\n",
    "print('{0:10}{1:10}{2:10}'.format('Token', 'Lemma', 'PoS Tag'))\n",
    "for idx, token in enumerate(doc_3):\n",
    "    print('{0:10}{1:10}{2:10}'.format(token.text, token.lemma_, token.pos_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization vs Stemming\n",
    "\n",
    "Ambas tienen como objetivo reducir las palabras a su raíz léxica.\n",
    "\n",
    "- **Lemmatization**:\n",
    "\n",
    "    Tiene en consideración el análisis morfológico de las palabras. Son necesarios diccionarios completos de formas flexionadas y raíces (lemmas).\n",
    "    \n",
    "    A veces es necesario desambiguar. P. ej.: \"planta\" (planta vs plantar)\n",
    "\n",
    "<img src=https://blog.bitext.com/hs-fs/hubfs/lemma_v2.png width=500px>\n",
    "\n",
    "- **Stemming**:\n",
    "    \n",
    "    Algoritmos que mediante heurísticos / reglas tratan de reducir las palabras a una posible raíz (stem) mediante la eliminación de algunos prefijos y sufijos. Más sencillo que un lemmatizer\n",
    "    \n",
    "    No hay garantía de que el resultado sea una palabra real.\n",
    "    \n",
    "    El algoritmo más utilizado en Inglés es el de Porter que consiste en 5 fases de reducción de la palabra aplicadas de manera secuencial.\n",
    "    <img src=https://blog.bitext.com/hs-fs/hubfs/stemming_v2.png width=250px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similitud\n",
    "\n",
    "Si trabajamos con los _small models_ (SM) en lugar de los _large models_ (LM), en lugar de trabajar con _word vectors_ estaremos trabajando con _context-sensitive tensors_.\n",
    "\n",
    "No os preocupéis, los modelos de _word embeddings_ los estudiaremos con mucho más detalle en próximas sesiones :D\n",
    "\n",
    "Como adelanto, en el caso de trabajar con los primeros (word vectors) siempre tendremos el mismo vector para el mismo token. Si trabajamos con los segundos (context-sensitive tensors) el vector del token estará determinado por su contexto (el resto de tokens que le rodean).\n",
    "\n",
    "Aunque el concepto de similitud lo veremos más adelante, como adelanto, conocer que con spaCy es posible calcular lo _parecidos_ o _distintos_ que son dos tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip3 install https://github.com/explosion/spacy-models/releases/download/es_core_news_md-2.3.0/es_core_news_md-2.3.0.tar.gz#egg=es_core_news_md==2.3.0 --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !python3 -m spacy download es_core_news_md\n",
    "import spacy\n",
    "nlp_es_md = spacy.load('es_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between word 1 and word 2: 0.911342\n",
      "Similarity between word 1 and word 3: 0.552898\n",
      "Similarity between word 2 and word 3: 0.602600\n"
     ]
    }
   ],
   "source": [
    "word_1 = nlp_es_md('verde')\n",
    "word_2 = nlp_es_md('azul')\n",
    "word_3 = nlp_es_md('mariposa')\n",
    "\n",
    "print('Similarity between word {} and word {}: {:0.6f}'.format(1, 2, word_1.similarity(word_2)))\n",
    "print('Similarity between word {} and word {}: {:0.6f}'.format(1, 3, word_1.similarity(word_3)))\n",
    "print('Similarity between word {} and word {}: {:0.6f}'.format(2, 3, word_2.similarity(word_3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between sent 1 and sent 2: 0.981271\n",
      "Similarity between sent 1 and sent 3: 0.922150\n",
      "Similarity between sent 2 and sent 3: 0.951995\n"
     ]
    }
   ],
   "source": [
    "sent_1 = nlp_es_md('me gusta el color verde')\n",
    "sent_2 = nlp_es_md('me gusta el azul')\n",
    "sent_3 = nlp_es_md('me gusta la mariposa')\n",
    "\n",
    "print('Similarity between sent {} and sent {}: {:0.6f}'.format(1, 2, sent_1.similarity(sent_2)))\n",
    "print('Similarity between sent {} and sent {}: {:0.6f}'.format(1, 3, sent_1.similarity(sent_3)))\n",
    "print('Similarity between sent {} and sent {}: {:0.6f}'.format(2, 3, sent_2.similarity(sent_3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El Universo de spaCy\n",
    "\n",
    "Diferentes recursos (paquetes, plugins, extensiones, etc) desarrollados por o para spaCy.\n",
    "\n",
    "https://spacy.io/universe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
