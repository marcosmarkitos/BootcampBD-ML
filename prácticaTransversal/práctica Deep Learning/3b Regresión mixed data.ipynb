{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Regresión mixed data.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1gaMHFzFfxPdZDCS3_sxqZAOqcwxG1fFU","authorship_tag":"ABX9TyNHxem05F1cT9mLmnBWBcTc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"CF3PrvWJ6X8t","colab_type":"text"},"source":["**REGRESIÓN PARTIENDO DE IMÁGENES Y DATOS NUMÉRICOS Y CATEGÓRICOS**\n","\n","En este notebook vamos a tratar de hacer una regresión para estimar el precio de un apartamento de alquiler. Dicha predicción se va a hacer a partir de dos fuentes de datos distintas: por un lado las imágenes que tenemos en el dataset de airbnb que venimos usando en las prácticas de este Bootcamp y por otro los datos numéricos y categóricos de dicho dataset.\n","\n","En primer lugar nos descargamos el fichero de internet y lo copiamos en un directorio local de My Drive donde tenemos recogido todo el entorno de esta práctica.\n","A continuación hacemos lo mismo con las imágenes de cada una de las entradas. Usamos la vista en miniatura que sacamos de la URL de dicho fichero.\n","\n","También montamos el google collab con My Drive para tenerlo vinculado.\n","\n","Estos pasos solo hay que realizarlos la primera vez, una vez que tenemos los ficheros en My Drive se pueden saltar y pasamos a cargar los datos directamente desde dicho directorio."]},{"cell_type":"code","metadata":{"id":"yGAWhUGP6nRG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":343},"executionInfo":{"status":"ok","timestamp":1593064923489,"user_tz":-120,"elapsed":62620,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}},"outputId":"a49fee41-1611-48e3-9bd8-5cb4329ec326"},"source":["# nos descargamos el dataset de OpenDataSoft\n","!wget -O \"airbnb-listings.csv\" \"https://public.opendatasoft.com/explore/dataset/airbnb-listings/download/?format=csv&disjunctive.host_verifications=true&disjunctive.amenities=true&disjunctive.features=true&refine.country=Spain&q=Madrid&timezone=Europe/London&use_labels_for_header=true&csv_separator=%3B\"\n","\n","!ls -lah"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-06-25 06:01:03--  https://public.opendatasoft.com/explore/dataset/airbnb-listings/download/?format=csv&disjunctive.host_verifications=true&disjunctive.amenities=true&disjunctive.features=true&refine.country=Spain&q=Madrid&timezone=Europe/London&use_labels_for_header=true&csv_separator=%3B\n","Resolving public.opendatasoft.com (public.opendatasoft.com)... 34.249.199.226, 34.248.20.69\n","Connecting to public.opendatasoft.com (public.opendatasoft.com)|34.249.199.226|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [application/csv]\n","Saving to: ‘airbnb-listings.csv’\n","\n","airbnb-listings.csv     [  <=>               ]  54.19M  2.77MB/s    in 50s     \n","\n","2020-06-25 06:02:01 (1.09 MB/s) - ‘airbnb-listings.csv’ saved [56826824]\n","\n","total 55M\n","drwxr-xr-x 1 root root 4.0K Jun 25 06:01 .\n","drwxr-xr-x 1 root root 4.0K Jun 25 05:59 ..\n","-rw-r--r-- 1 root root  55M Jun 25 06:02 airbnb-listings.csv\n","drwxr-xr-x 1 root root 4.0K Jun 19 16:15 .config\n","drwx------ 4 root root 4.0K Jun 25 06:00 drive\n","drwxr-xr-x 1 root root 4.0K Jun 17 16:18 sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-4dDxIX4wNAb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1593148776645,"user_tz":-120,"elapsed":8497,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}},"outputId":"d123b864-a9b6-4071-b32b-17b8a663be88"},"source":["!ls -lah"],"execution_count":null,"outputs":[{"output_type":"stream","text":["total 16K\n","drwxr-xr-x 1 root root 4.0K Jun 17 16:18 .\n","drwxr-xr-x 1 root root 4.0K Jun 26 05:15 ..\n","drwxr-xr-x 1 root root 4.0K Jun 19 16:15 .config\n","drwxr-xr-x 1 root root 4.0K Jun 17 16:18 sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YLSxaq6U32t_","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"27R_6DOoEpEF","colab_type":"code","colab":{}},"source":["!cp airbnb-listings.csv \"drive/My Drive/BootcampBD&ML/práctica/prácticaDeepLearning\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LyUGFt37FHVK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1593149243426,"user_tz":-120,"elapsed":875,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}},"outputId":"49df4fd7-e4e7-4e33-e62f-2b9c7e4ff32f"},"source":["# aquí creamos nuestra estructura de datos, que va a consistir en la url de la\n","# imagen y un índice para saber donde insertarla en nuestro array\n","images_paths = [[i, img_url] for i, img_url in enumerate(full_df['Thumbnail Url'])]\n","images_paths[:5]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[0,\n","  'https://a0.muscache.com/im/pictures/cffe393a-0d84-4fd5-ab4c-a62e067c1b0d.jpg?aki_policy=small'],\n"," [1,\n","  'https://a0.muscache.com/im/pictures/ea919e56-aa99-4d5d-a129-1edf0d117d6a.jpg?aki_policy=small'],\n"," [2,\n","  'https://a0.muscache.com/im/pictures/57011236/eea5c213_original.jpg?aki_policy=small'],\n"," [3,\n","  'https://a0.muscache.com/im/pictures/974f0245-55c2-4e8c-b9bf-14c1c975c798.jpg?aki_policy=small'],\n"," [4,\n","  'https://a0.muscache.com/im/pictures/c2dde263-20dd-43af-8c6b-be636c2c0ce1.jpg?aki_policy=small']]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"My93mt1qMtcv","colab_type":"code","colab":{}},"source":["import imageio as io\n","import cv2\n","\n","# esta es la función que se descargará la imagen y devolverá la imagen y el \n","# índice indicando la posición donde se incrustará la imagen en nuestro array\n","def get_image(data_url, target_size=(224, 224)):\n","    idx, url = data_url\n","    try:\n","        img = io.imread(url)\n","        # hay alguna imagen en blanco y negro y daría error al incluirla en \n","        # nuestro array de imagenes que tiene 3 canales, así que convertimos\n","        # todas las imágenes que tengan menos de 3 dimensiones a color\n","        if img.ndim < 3:\n","            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n","        img = cv2.resize(img, dsize=target_size)\n","        return img, idx\n","    except IOError as err:\n","        return (None, idx)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WldeZWd2NAbm","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","# en este array iremos incrustando las imágenes conforme las vayamos obteniendo\n","loaded_images = np.zeros((len(images_paths), 224, 224, 3), dtype=np.uint8)\n","\n","# y en este array llevaremos un control de cuales se han cargado correctamente\n","# y cuales no\n","was_loaded = np.zeros(len(images_paths))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j4PSNB_hNVLC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593151722336,"user_tz":-120,"elapsed":498858,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}},"outputId":"e1f758ce-a160-4e1e-8b4b-0e7fdf5ac77e"},"source":["import concurrent\n","from tqdm import tqdm\n","\n","# creamos un pool de procesos que se irán descargando las imágenes\n","# por defecto, se crearán tantos como CPUs tenga vuestra máquina\n","with concurrent.futures.ProcessPoolExecutor() as executor:\n","    # procesamos la lista de urls de imágenes paralelizandola con el pool de procesos\n","    for (img, idx) in tqdm(executor.map(get_image, images_paths), total=len(images_paths)):\n","        # metemos la imagen en nuestro array\n","        if img is not None:\n","            loaded_images[idx] = img\n","            was_loaded[idx] = 1\n","        else:\n","            was_loaded[idx] = 0\n","\n","print('Terminado!')\n","print(f'Total de imágenes recuperadas correctamente: {sum(was_loaded)}/{len(images_paths)}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 14001/14001 [08:14<00:00, 28.29it/s]"],"name":"stderr"},{"output_type":"stream","text":["Terminado!\n","Total de imágenes recuperadas correctamente: 11271.0/14001\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"INHNB-WhNsvG","colab_type":"code","colab":{}},"source":["# guardamos las imágenes (y yo os recomiendo que os lo guardéis en GDrive para evitar tener que repetir esto)\n","np.save('images.npy', loaded_images)\n","np.save('was_loaded.npy', was_loaded)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f4-TANTHNsWk","colab_type":"code","colab":{}},"source":["# almacenamos las imagenes en nuestro drive\n","!cp images.npy \"drive/My Drive/BootcampBD&ML/práctica/prácticaDeepLearning\"\n","!cp was_loaded.npy \"drive/My Drive/BootcampBD&ML/práctica/prácticaDeepLearning\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hJu_2Fcm8qNz","colab_type":"text"},"source":["Esta parte de descarga, montado y copiado solo hace falta ejecutarla la primera vez. Una vez que lo tenemos almacenado en My Drive solo necesitamos cargarlo directamente.\n","\n","A partir de aquí empieza nuestro ejercicio de regresión.\n","\n","Como hábito de buena costumbre, para no incurrir en errores involuntarios, en primer lugar se va a dividir el dataset original en train, validation y test.\n","\n","Se trabaja únicamente con el de train con el objetivo de elegir un modelo. Eso se verifica con el conjunto de validation y finalmente se aplica ese \"entrenamiento\" al bloque de test."]},{"cell_type":"code","metadata":{"id":"E63PIJHrVKuF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593340976459,"user_tz":-120,"elapsed":899,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}},"outputId":"20c40af0-36fd-406c-a4e1-5caa008d815f"},"source":["%tensorflow_version 1.x"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GQK8_P3qVKOb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1593340984734,"user_tz":-120,"elapsed":7292,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}},"outputId":"aa8196d0-ea0c-4122-fd6a-be1b7eaf7ff1"},"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","%matplotlib inline\n","cm = plt.cm.RdBu\n","cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error\n","\n","\n","#hacemos la divisón en train, val y test\n","full_df = pd.read_csv('drive/My Drive/BootcampBD&ML/práctica/prácticaDeepLearning/airbnb-listings.csv', sep=';', decimal='.')\n","full_train, test = train_test_split(full_df, test_size=0.2, shuffle=True, random_state=0)\n","train, val = train_test_split(full_train, test_size=0.2, shuffle=True, random_state=0)\n","\n","print(f'Dimensiones del dataset de training: {train.shape}')\n","print(f'Dimensiones del dataset de validación: {val.shape}')\n","print(f'Dimensiones del dataset de test: {test.shape}')\n","\n","# Guardamos\n","train.to_csv('./train.csv', sep=';', decimal='.', index=True)\n","val.to_csv('./val.csv', sep=';', decimal='.', index=True)\n","test.to_csv('./test.csv', sep=';', decimal='.', index=True)\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Dimensiones del dataset de training: (8960, 89)\n","Dimensiones del dataset de validación: (2240, 89)\n","Dimensiones del dataset de test: (2801, 89)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"snh4Brs5SLwN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":118},"executionInfo":{"status":"ok","timestamp":1593341025054,"user_tz":-120,"elapsed":45696,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}},"outputId":"d0c9e7da-2c18-4048-c548-ca4072d0c2e4"},"source":["#cargamos las imágenes desde el directorio de My Drive (ya las habíamos descargado previamente)\n","images  = np.load('drive/My Drive/BootcampBD&ML/práctica/prácticaDeepLearning/images.npy')\n","was_loaded  = np.load('drive/My Drive/BootcampBD&ML/práctica/prácticaDeepLearning/was_loaded.npy')\n","\n","#cargamos los datos ya divididos en train, val y test\n","df_train = pd.read_csv('./train.csv', sep=';', decimal='.')\n","df_val = pd.read_csv('./val.csv', sep=';', decimal='.')\n","df_test = pd.read_csv('./test.csv', sep=';', decimal='.')\n","\n","#usando el índice de la división anterior obtenemos los conjuntos de test, val y test en las imágenes\n","train_imgs = images[df_train['Unnamed: 0']]\n","val_imgs = images[df_val['Unnamed: 0']]\n","test_imgs = images[df_test['Unnamed: 0']]\n","\n","train_was_loaded = was_loaded[df_train['Unnamed: 0']]\n","val_was_loaded = was_loaded[df_val['Unnamed: 0']]\n","test_was_loaded = was_loaded[df_test['Unnamed: 0']]\n","\n","print(f'Dimensiones del dataset de training: {train_imgs.shape}')\n","print(f'Dimensiones del dataset de validación: {val_imgs.shape}')\n","print(f'Dimensiones del dataset de test: {test_imgs.shape}')\n","\n","print(f'Dimensiones del dataset de training: {train_was_loaded.shape}')\n","print(f'Dimensiones del dataset de validación: {val_was_loaded.shape}')\n","print(f'Dimensiones del dataset de test: {test_was_loaded.shape}')\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Dimensiones del dataset de training: (8960, 224, 224, 3)\n","Dimensiones del dataset de validación: (2240, 224, 224, 3)\n","Dimensiones del dataset de test: (2801, 224, 224, 3)\n","Dimensiones del dataset de training: (8960,)\n","Dimensiones del dataset de validación: (2240,)\n","Dimensiones del dataset de test: (2801,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oveWlY0PQu8G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":118},"executionInfo":{"status":"ok","timestamp":1593341026493,"user_tz":-120,"elapsed":45959,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}},"outputId":"24b7a3c2-9fe7-4966-baf1-5e5d431c4f22"},"source":["# nos quedamos con los datos e imágenes para los que hemos podido encontrar imágenes\n","train_imgs_loaded = train_imgs[train_was_loaded == 1]\n","val_imgs_loaded = val_imgs[val_was_loaded == 1]\n","test_imgs_loaded = test_imgs[test_was_loaded == 1]\n","\n","train_with_imgs = df_train[train_was_loaded == 1]\n","val_with_imgs = df_val[val_was_loaded == 1]\n","test_with_imgs = df_test[test_was_loaded == 1]\n","\n","print(f'Dimensiones del dataset de training: {train_imgs_loaded.shape}')\n","print(f'Dimensiones del dataset de validación: {val_imgs_loaded.shape}')\n","print(f'Dimensiones del dataset de test: {test_imgs_loaded.shape}')\n","\n","print(f'Dimensiones del dataset de training: {train_with_imgs.shape}')\n","print(f'Dimensiones del dataset de validación: {val_with_imgs.shape}')\n","print(f'Dimensiones del dataset de test: {test_with_imgs.shape}')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Dimensiones del dataset de training: (7204, 224, 224, 3)\n","Dimensiones del dataset de validación: (1790, 224, 224, 3)\n","Dimensiones del dataset de test: (2277, 224, 224, 3)\n","Dimensiones del dataset de training: (7204, 90)\n","Dimensiones del dataset de validación: (1790, 90)\n","Dimensiones del dataset de test: (2277, 90)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R7ZiZcPXNRVG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593341026839,"user_tz":-120,"elapsed":44971,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}}},"source":["#definimos la función de procesado de datos categóricos y numéricos\n","def preprocesado(train, val, test):\n","  \n","  #eliminamos las columnas que no aportan\n","  train.drop(['ID','Scrape ID','Last Scraped','Host ID','Calendar last Scraped','Listing Url','Thumbnail Url',\n","         'Medium Url','Picture Url','XL Picture Url','Host URL','Host Thumbnail Url','Host Picture Url',\n","        'Name','Summary','Space','Description','Neighborhood Overview','Notes','Transit','Access',\n","         'Interaction','House Rules','Host Name','Host About','Street','Host Location','State','Market',\n","         'Smart Location','Country Code','Country','Geolocation','Weekly Price','Monthly Price',\n","         'Host Acceptance Rate','Experiences Offered','Has Availability','License','Jurisdiction Names','Square Feet','City'], \n","        axis=1, inplace=True)\n","  val.drop(['ID','Scrape ID','Last Scraped','Host ID','Calendar last Scraped','Listing Url','Thumbnail Url',\n","         'Medium Url','Picture Url','XL Picture Url','Host URL','Host Thumbnail Url','Host Picture Url',\n","        'Name','Summary','Space','Description','Neighborhood Overview','Notes','Transit','Access',\n","         'Interaction','House Rules','Host Name','Host About','Street','Host Location','State','Market',\n","         'Smart Location','Country Code','Country','Geolocation','Weekly Price','Monthly Price',\n","         'Host Acceptance Rate','Experiences Offered','Has Availability','License','Jurisdiction Names','Square Feet','City'], \n","        axis=1, inplace=True)\n","  test.drop(['ID','Scrape ID','Last Scraped','Host ID','Calendar last Scraped','Listing Url','Thumbnail Url',\n","         'Medium Url','Picture Url','XL Picture Url','Host URL','Host Thumbnail Url','Host Picture Url',\n","        'Name','Summary','Space','Description','Neighborhood Overview','Notes','Transit','Access',\n","         'Interaction','House Rules','Host Name','Host About','Street','Host Location','State','Market',\n","         'Smart Location','Country Code','Country','Geolocation','Weekly Price','Monthly Price',\n","         'Host Acceptance Rate','Experiences Offered','Has Availability','License','Jurisdiction Names','Square Feet','City'], \n","        axis=1, inplace=True)\n","  \n","  #PRICE\n","  #imputamos valores vacíos con la media de train\n","  MeanPriceTrain = train['Price'].mean()\n","  train['Price'].fillna(MeanPriceTrain, inplace=True)\n","  val['Price'].fillna(MeanPriceTrain, inplace=True)\n","  test['Price'].fillna(MeanPriceTrain, inplace=True)\n","  #transformamos variable Price a gausiana\n","  train['Price'] = train['Price'].apply(lambda x: np.log10(x))\n","  val['Price'] = val['Price'].apply(lambda x: np.log10(x))\n","  test['Price'] = test['Price'].apply(lambda x: np.log10(x))\n","    \n","  \n","  #FECHAS\n","  train['Host Since'] = pd.to_datetime(train['Host Since'], format=\"%Y-%m-%d\")\n","  train['First Review'] = pd.to_datetime(train['First Review'], format=\"%Y-%m-%d\")\n","  train['Last Review'] = pd.to_datetime(train['Last Review'], format=\"%Y-%m-%d\")\n","  train['Host Since'] = train['Host Since'].apply(lambda x: 2017 - x.year)\n","  train['First Review'] = train['First Review'].apply(lambda x: 2017 - x.year)\n","  train['Last Review'] = train['Last Review'].apply(lambda x: 2017 - x.year)\n","\n","  val['Host Since'] = pd.to_datetime(val['Host Since'], format=\"%Y-%m-%d\")\n","  val['First Review'] = pd.to_datetime(val['First Review'], format=\"%Y-%m-%d\")\n","  val['Last Review'] = pd.to_datetime(val['Last Review'], format=\"%Y-%m-%d\")\n","  val['Host Since'] = val['Host Since'].apply(lambda x: 2017 - x.year)\n","  val['First Review'] = val['First Review'].apply(lambda x: 2017 - x.year)\n","  val['Last Review'] = val['Last Review'].apply(lambda x: 2017 - x.year)\n","\n","  test['Host Since'] = pd.to_datetime(test['Host Since'], format=\"%Y-%m-%d\")\n","  test['First Review'] = pd.to_datetime(test['First Review'], format=\"%Y-%m-%d\")\n","  test['Last Review'] = pd.to_datetime(test['Last Review'], format=\"%Y-%m-%d\")\n","  test['Host Since'] = test['Host Since'].apply(lambda x: 2017 - x.year)\n","  test['First Review'] = test['First Review'].apply(lambda x: 2017 - x.year)\n","  test['Last Review'] = test['Last Review'].apply(lambda x: 2017 - x.year)\n","\n","  #Imputamos valores en variables categóricas donde tomamos la moda para los valores que faltan.\n","  #Lo extraemos en una variable disinta para cada columna con la intención de aplicar el mismo valor en val y test\n","  ModeHSTrain = train['Host Since'].mode()[0]\n","  ModeHLCTrain = train['Host Listings Count'].mode()[0]\n","  ModeHTLCTrain = train['Host Total Listings Count'].mode()[0]\n","  ModeBathroomsTrain = train['Bathrooms'].mode()[0]\n","  ModeBedroomsTrain = train['Bedrooms'].mode()[0]\n","  ModeBedsTrain = train['Beds'].mode()[0]\n","\n","  train['Host Since'].fillna(ModeHSTrain, inplace=True)\n","  train['Host Listings Count'].fillna(ModeHLCTrain, inplace=True)\n","  train['Host Total Listings Count'].fillna(ModeHTLCTrain, inplace=True)\n","  train['Bathrooms'].fillna(ModeBathroomsTrain, inplace=True)\n","  train['Bedrooms'].fillna(ModeBedroomsTrain, inplace=True)\n","  train['Beds'].fillna(ModeBedsTrain, inplace=True)\n","\n","  val['Host Since'].fillna(ModeHSTrain, inplace=True)\n","  val['Host Listings Count'].fillna(ModeHLCTrain, inplace=True)\n","  val['Host Total Listings Count'].fillna(ModeHTLCTrain, inplace=True)\n","  val['Bathrooms'].fillna(ModeBathroomsTrain, inplace=True)\n","  val['Bedrooms'].fillna(ModeBedroomsTrain, inplace=True)\n","  val['Beds'].fillna(ModeBedsTrain, inplace=True)\n","  test['Host Since'].fillna(ModeHSTrain, inplace=True)\n","  test['Host Listings Count'].fillna(ModeHLCTrain, inplace=True)\n","  test['Host Total Listings Count'].fillna(ModeHTLCTrain, inplace=True)\n","  test['Bathrooms'].fillna(ModeBathroomsTrain, inplace=True)\n","  test['Bedrooms'].fillna(ModeBedroomsTrain, inplace=True)\n","  test['Beds'].fillna(ModeBedsTrain, inplace=True)\n","\n","  #Imputamos valores en variables lineales donde tomamos la media para los valores que faltan\n","  #Lo extraemos en una variable disinta para cada columna con la intención de aplicar el mismo valor en val y test\n","  MeanRSRatingTrain = train['Review Scores Rating'].mean()\n","  MeanRSAccuracyTrain = train['Review Scores Accuracy'].mean()\n","  MeanRSCleanlinessTrain = train['Review Scores Cleanliness'].mean()\n","  MeanRSCheckinTrain = train['Review Scores Checkin'].mean()\n","  MeanRSCommunicationTrain = train['Review Scores Communication'].mean()\n","  MeanRSLocationTrain = train['Review Scores Location'].mean()\n","  MeanRSValueTrain = train['Review Scores Value'].mean()\n","\n","  train['Review Scores Rating'].fillna(MeanRSRatingTrain, inplace=True)\n","  train['Review Scores Accuracy'].fillna(MeanRSAccuracyTrain, inplace=True)\n","  train['Review Scores Cleanliness'].fillna(MeanRSCleanlinessTrain, inplace=True)\n","  train['Review Scores Checkin'].fillna(MeanRSCheckinTrain, inplace=True)\n","  train['Review Scores Communication'].fillna(MeanRSCommunicationTrain, inplace=True)\n","  train['Review Scores Location'].fillna(MeanRSLocationTrain, inplace=True)\n","  train['Review Scores Value'].fillna(MeanRSValueTrain, inplace=True)\n","  val['Review Scores Rating'].fillna(MeanRSRatingTrain, inplace=True)\n","  val['Review Scores Accuracy'].fillna(MeanRSAccuracyTrain, inplace=True)\n","  val['Review Scores Cleanliness'].fillna(MeanRSCleanlinessTrain, inplace=True)\n","  val['Review Scores Checkin'].fillna(MeanRSCheckinTrain, inplace=True)\n","  val['Review Scores Communication'].fillna(MeanRSCommunicationTrain, inplace=True)\n","  val['Review Scores Location'].fillna(MeanRSLocationTrain, inplace=True)\n","  val['Review Scores Value'].fillna(MeanRSValueTrain, inplace=True)\n","  test['Review Scores Rating'].fillna(MeanRSRatingTrain, inplace=True)\n","  test['Review Scores Accuracy'].fillna(MeanRSAccuracyTrain, inplace=True)\n","  test['Review Scores Cleanliness'].fillna(MeanRSCleanlinessTrain, inplace=True)\n","  test['Review Scores Checkin'].fillna(MeanRSCheckinTrain, inplace=True)\n","  test['Review Scores Communication'].fillna(MeanRSCommunicationTrain, inplace=True)\n","  test['Review Scores Location'].fillna(MeanRSLocationTrain, inplace=True)\n","  test['Review Scores Value'].fillna(MeanRSValueTrain, inplace=True)\n","\n","  #los vacíos los consideramos como desconocidos\n","  train['Host Neighbourhood'].fillna('Unknown', inplace=True)\n","  train['Host Verifications'].fillna('Unknown', inplace=True)\n","  train['Neighbourhood'].fillna('Unknown', inplace=True)\n","  train['Zipcode'].fillna('Unknown', inplace=True)\n","  train['Amenities'].fillna('Unknown', inplace=True)\n","  train['First Review'].fillna('Unknown', inplace=True)\n","  train['Last Review'].fillna('Unknown', inplace=True)\n","  val['Host Neighbourhood'].fillna('Unknown', inplace=True)\n","  val['Host Verifications'].fillna('Unknown', inplace=True)\n","  val['Neighbourhood'].fillna('Unknown', inplace=True)\n","  val['Zipcode'].fillna('Unknown', inplace=True)\n","  val['Amenities'].fillna('Unknown', inplace=True)\n","  val['First Review'].fillna('Unknown', inplace=True)\n","  val['Last Review'].fillna('Unknown', inplace=True)\n","  test['Host Neighbourhood'].fillna('Unknown', inplace=True)\n","  test['Host Verifications'].fillna('Unknown', inplace=True)\n","  test['Neighbourhood'].fillna('Unknown', inplace=True)\n","  test['Zipcode'].fillna('Unknown', inplace=True)\n","  test['Amenities'].fillna('Unknown', inplace=True)\n","  test['First Review'].fillna('Unknown', inplace=True)\n","  test['Last Review'].fillna('Unknown', inplace=True)\n","\n","  #consideramos que donde falta un valor es porque no existe, es decir, no hay respuesta o la tasa es 0€\n","  train['Host Response Time'].fillna('No response', inplace=True)\n","  train['Host Response Rate'].fillna(0, inplace=True)\n","  train['Security Deposit'].fillna(0, inplace=True)\n","  train['Cleaning Fee'].fillna(0, inplace=True)\n","  train['Reviews per Month'].fillna(0, inplace=True)\n","  val['Host Response Time'].fillna('No response', inplace=True)\n","  val['Host Response Rate'].fillna(0, inplace=True)\n","  val['Security Deposit'].fillna(0, inplace=True)\n","  val['Cleaning Fee'].fillna(0, inplace=True)\n","  val['Reviews per Month'].fillna(0, inplace=True)\n","  test['Host Response Time'].fillna('No response', inplace=True)\n","  test['Host Response Rate'].fillna(0, inplace=True)\n","  test['Security Deposit'].fillna(0, inplace=True)\n","  test['Cleaning Fee'].fillna(0, inplace=True)\n","  test['Reviews per Month'].fillna(0, inplace=True)\n","\n","  #transformaciones contando palabras. es algo muy sencillo, queda pendiente mejorarlo con técnicas NLP en el futuro\n","  train['Amenities'] = train['Amenities'].apply(lambda x: len(str(x).split(',')))\n","  train['Host Verifications'] = train['Host Verifications'].apply(lambda x: len(str(x).split(',')))\n","  train['Features'] = train['Features'].apply(lambda x: len(str(x).split(',')))\n","  val['Amenities'] = val['Amenities'].apply(lambda x: len(str(x).split(',')))\n","  val['Host Verifications'] = val['Host Verifications'].apply(lambda x: len(str(x).split(',')))\n","  val['Features'] = val['Features'].apply(lambda x: len(str(x).split(',')))\n","  test['Amenities'] = test['Amenities'].apply(lambda x: len(str(x).split(',')))\n","  test['Host Verifications'] = test['Host Verifications'].apply(lambda x: len(str(x).split(',')))\n","  test['Features'] = test['Features'].apply(lambda x: len(str(x).split(',')))\n","\n","  #MeanEncoder\n","  categorical = ['Host Response Time', 'Host Neighbourhood', 'Neighbourhood','Neighbourhood Cleansed',\n","               'Neighbourhood Group Cleansed','Zipcode','Property Type','Room Type','Bed Type',\n","               'Calendar Updated','First Review','Last Review','Cancellation Policy']\n","  # En train creamos un dict para usarlo después en val y test\n","  mean_map = {}\n","  for c in categorical:\n","      mean = train.groupby(c)['Price'].mean()\n","      train[c] = train[c].map(mean)    \n","      mean_map[c] = mean\n","  for c in categorical:\n","    val[c] = val[c].map(mean_map[c])\n","  for c in categorical:\n","    test[c] = test[c].map(mean_map[c])\n"," #los valores vacíos de val y test los completo con la moda de train\n","  for c in categorical:\n","    val[c].fillna(train[c].mode()[0], inplace=True)\n","  for c in categorical:\n","    test[c].fillna(train[c].mode()[0], inplace=True)\n","\n","  #extraemos la variable objetivo\n","  Ytrain = train['Price']\n","  Yval = val['Price']\n","  Ytest = test['Price']\n","  #eliminamos la variable Price\n","  train.drop(['Price'],axis=1, inplace=True)\n","  val.drop(['Price'],axis=1, inplace=True)\n","  test.drop(['Price'],axis=1, inplace=True)\n","  \n","  #escalamos los valores de entrada\n","  cs = MinMaxScaler()\n","  Xtrain_Scaled = cs.fit_transform(train)\n","  Xval_Scaled = cs.transform(val)\n","  Xtest_Scaled = cs. transform(test)\n","\n","  \n","\n","  return (Xtrain_Scaled, Xval_Scaled, Xtest_Scaled, Ytrain, Yval, Ytest)\n","      "],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"fWLeux1ndb7l","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":118},"executionInfo":{"status":"ok","timestamp":1593341027555,"user_tz":-120,"elapsed":43379,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}},"outputId":"6f664d1a-7750-40e0-9d1f-01601cfdf602"},"source":["(Xtrain, Xval, Xtest, ytrain, yval, ytest) = preprocesado(train_with_imgs, val_with_imgs, test_with_imgs)\n","\n","print(f'Dimensiones del dataset de training: {train_imgs_loaded.shape}')\n","print(f'Dimensiones del dataset de validación: {val_imgs_loaded.shape}')\n","print(f'Dimensiones del dataset de test: {test_imgs_loaded.shape}')\n","\n","print(f'Dimensiones del dataset de training: {Xtrain.shape}')\n","print(f'Dimensiones del dataset de validación: {Xval.shape}')\n","print(f'Dimensiones del dataset de test: {Xtest.shape}')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Dimensiones del dataset de training: (7204, 224, 224, 3)\n","Dimensiones del dataset de validación: (1790, 224, 224, 3)\n","Dimensiones del dataset de test: (2277, 224, 224, 3)\n","Dimensiones del dataset de training: (7204, 47)\n","Dimensiones del dataset de validación: (1790, 47)\n","Dimensiones del dataset de test: (2277, 47)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5CGH2N4oH0vy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1593341028619,"user_tz":-120,"elapsed":41634,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}},"outputId":"c6de4d47-ad74-485f-fac7-874ecb51e546"},"source":["#Redimensionamos las imágenes de entrada. Estoy teniendo problemas de RAM y no puedo ejecutarlo\n","#con 224x224 no puedo escalar /255. Con 112x112 no puedo ejecutar el modelo\n","#es necesario asumir esta pérdida de información\n","train_imgs_loaded = np.resize(train_imgs_loaded, (train_imgs_loaded.shape[0],64, 64, train_imgs_loaded.shape[3]))\n","val_imgs_loaded = np.resize(val_imgs_loaded, (val_imgs_loaded.shape[0],64, 64, val_imgs_loaded.shape[3]))\n","test_imgs_loaded = np.resize(test_imgs_loaded, (test_imgs_loaded.shape[0],64, 64, test_imgs_loaded.shape[3]))\n","\n","print(f'Dimensiones del dataset de training: {train_imgs_loaded.shape}')\n","print(f'Dimensiones del dataset de training: {val_imgs_loaded.shape}')\n","print(f'Dimensiones del dataset de training: {test_imgs_loaded.shape}')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Dimensiones del dataset de training: (7204, 64, 64, 3)\n","Dimensiones del dataset de training: (1790, 64, 64, 3)\n","Dimensiones del dataset de training: (2277, 64, 64, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J7QHeDgeJzbC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593341028620,"user_tz":-120,"elapsed":40032,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}}},"source":["#escalamos los datos de entrada. Lo hago en celdas separadas ya que hay algún problema de RAM\n","#se trata de imágenes así que no hace falta centrar, solo dividimos por el máximo. \n","# nos aseguramos de hacerlo como float para no perder la info de los decimales\n","\n","train_imgs_loaded = train_imgs_loaded.astype('float32') / 255.\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"-lgn_PkHKiiV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593341028622,"user_tz":-120,"elapsed":38843,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}}},"source":["val_imgs_loaded = val_imgs_loaded.astype('float32') / 255.\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"La20DOHfLjYl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593341028623,"user_tz":-120,"elapsed":37813,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}}},"source":["test_imgs_loaded = test_imgs_loaded.astype('float32') / 255."],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yefHyTAEhshQ","colab_type":"text"},"source":["En este punto ya tenemos nuestros datos de entrada (imágenes por un lado y datos numéricos y categóricos por otro) preparados. Vamos a definir nuestros modelos de red neuronal para que traten cada uno de ese tipo de datos.\n","\n","Para ello nos basamos en los notebooks anteriores y elegimos directamente el modelo que mejor prestaciones nos dio.\n","\n","No obstante, eliminamos la última capa de cada uno de esos modelos. No queremos obtener el resultado final de la regresión por separado. Esas dos salidas las concatenamos, y ahora sí, las volvemos a introducir en un modelo que consiste simplemente en un clasificador que hace la regresión final."]},{"cell_type":"code","metadata":{"id":"TM90tSDZX4Ax","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593341107180,"user_tz":-120,"elapsed":836,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}}},"source":["from keras.models import Sequential, Model\n","from keras.layers import Dense, Dropout, Flatten, Activation, Input\n","from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, concatenate\n","from keras import backend as K\n","from keras.utils import to_categorical\n","from keras.optimizers import Adam\n","from keras.constraints import max_norm\n","\n","\n","# Creamos la rama de la red convolucional para tratar las imágenes\n","def miCNN(width, height, depth):\n","  model = Sequential()\n","\n","  # Definimos una capa convolucional\n","  model.add(Conv2D(64, kernel_size=(5,5), input_shape=(64, 64, 3)))\n","  model.add(BatchNormalization())\n","  model.add(Activation('relu'))\n","  model.add(MaxPooling2D(pool_size=(2, 2)))\n","  model.add(Dropout(0.09569))\n","\n","  # Definimos una segunda capa convolucional\n","  model.add(Conv2D(64, kernel_size=(5,5), activation='relu'))\n","  model.add(BatchNormalization())\n","  model.add(Activation('relu'))\n","  model.add(MaxPooling2D(pool_size=(2, 2)))\n","  model.add(Dropout(0.09569))\n","\n","  # Definimos una tercera capa convolucional\n","  model.add(Conv2D(64, kernel_size=(5,5), activation='relu'))\n","  model.add(BatchNormalization())\n","  model.add(Activation('relu'))\n","  model.add(MaxPooling2D(pool_size=(2, 2)))\n","  model.add(Dropout(0.09569))\n","\n","  # Añadimos nuestro clasificador\n","  model.add(Flatten())\n","  model.add(Dense(256, activation='relu', kernel_constraint=max_norm(3.)))\n","  model.add(Dropout(0.09569))\n","  model.add(Dense(4, activation='relu'))\n","\n","  return model\n","\n","#creamos otra rama con una red neuronal para tratar los datos numéricos/categóricos\n","def miRed(dim):\n","  model = Sequential()\n","  model.add(Dense(8, input_dim=dim, activation=\"relu\"))\n","  model.add(Dense(4, activation=\"relu\"))\n","  \n","  return model\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"XtXVqpBOYGWp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593341626970,"user_tz":-120,"elapsed":516181,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}},"outputId":"05152007-5237-4df6-e297-22a8fe5f0276"},"source":["#cogemos las salidas de las dos ramas por separado y las concatenamos\n","#esto es la entrada combinada de nuestro modelo final que da como resultado la regresión\n","\n","dataBranch = miRed(Xtrain.shape[1])\n","imageBranch = miCNN(64,64,3)\n","combinedInput = concatenate([dataBranch.output, imageBranch.output])\n","\n","x = Dense(4, activation=\"relu\")(combinedInput)\n","x = Dense(1, activation=\"linear\")(x)\n","model = Model(inputs=[dataBranch.input, imageBranch.input], outputs=x)\n","\n","# Compilamos el modelo\n","opt = Adam(lr=1e-3, decay=1e-3 / 200)\n","model.compile(loss='mse',\n","              optimizer=Adam(lr=0.0001, decay=1e-6),\n","              metrics=[tf.keras.metrics.RootMeanSquaredError()])\n","\n","# Entrenamos el modelo\n","model.fit([Xtrain,train_imgs_loaded], ytrain,\n","          batch_size=128,\n","          shuffle=True,\n","          epochs=100,\n","          validation_data=([Xval,val_imgs_loaded], yval))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 7204 samples, validate on 1790 samples\n","Epoch 1/100\n","7204/7204 [==============================] - 12s 2ms/step - loss: 1.5623 - root_mean_squared_error: 1.6119 - val_loss: 2.9297 - val_root_mean_squared_error: 1.3096\n","Epoch 2/100\n","7204/7204 [==============================] - 5s 704us/step - loss: 0.2248 - root_mean_squared_error: 1.1809 - val_loss: 2.9287 - val_root_mean_squared_error: 1.1030\n","Epoch 3/100\n","7204/7204 [==============================] - 5s 701us/step - loss: 0.1864 - root_mean_squared_error: 1.0563 - val_loss: 2.9090 - val_root_mean_squared_error: 1.0245\n","Epoch 4/100\n","7204/7204 [==============================] - 5s 702us/step - loss: 0.1634 - root_mean_squared_error: 0.9988 - val_loss: 2.8084 - val_root_mean_squared_error: 0.9799\n","Epoch 5/100\n","7204/7204 [==============================] - 5s 702us/step - loss: 0.1517 - root_mean_squared_error: 0.9622 - val_loss: 2.4215 - val_root_mean_squared_error: 0.9461\n","Epoch 6/100\n","7204/7204 [==============================] - 5s 698us/step - loss: 0.1438 - root_mean_squared_error: 0.9303 - val_loss: 1.8346 - val_root_mean_squared_error: 0.9134\n","Epoch 7/100\n","7204/7204 [==============================] - 5s 701us/step - loss: 0.1306 - root_mean_squared_error: 0.8969 - val_loss: 1.2082 - val_root_mean_squared_error: 0.8786\n","Epoch 8/100\n","7204/7204 [==============================] - 5s 705us/step - loss: 0.1310 - root_mean_squared_error: 0.8615 - val_loss: 0.9655 - val_root_mean_squared_error: 0.8453\n","Epoch 9/100\n","7204/7204 [==============================] - 5s 700us/step - loss: 0.1244 - root_mean_squared_error: 0.8300 - val_loss: 0.8516 - val_root_mean_squared_error: 0.8160\n","Epoch 10/100\n","7204/7204 [==============================] - 5s 698us/step - loss: 0.1240 - root_mean_squared_error: 0.8026 - val_loss: 0.7079 - val_root_mean_squared_error: 0.7900\n","Epoch 11/100\n","7204/7204 [==============================] - 5s 702us/step - loss: 0.1223 - root_mean_squared_error: 0.7780 - val_loss: 0.6640 - val_root_mean_squared_error: 0.7671\n","Epoch 12/100\n","7204/7204 [==============================] - 5s 705us/step - loss: 0.1162 - root_mean_squared_error: 0.7565 - val_loss: 0.6887 - val_root_mean_squared_error: 0.7471\n","Epoch 13/100\n","7204/7204 [==============================] - 5s 698us/step - loss: 0.1126 - root_mean_squared_error: 0.7379 - val_loss: 0.5462 - val_root_mean_squared_error: 0.7289\n","Epoch 14/100\n","7204/7204 [==============================] - 5s 696us/step - loss: 0.1126 - root_mean_squared_error: 0.7202 - val_loss: 0.5149 - val_root_mean_squared_error: 0.7122\n","Epoch 15/100\n","7204/7204 [==============================] - 5s 707us/step - loss: 0.1125 - root_mean_squared_error: 0.7043 - val_loss: 0.5320 - val_root_mean_squared_error: 0.6973\n","Epoch 16/100\n","7204/7204 [==============================] - 5s 699us/step - loss: 0.1112 - root_mean_squared_error: 0.6903 - val_loss: 0.5374 - val_root_mean_squared_error: 0.6841\n","Epoch 17/100\n","7204/7204 [==============================] - 5s 706us/step - loss: 0.1083 - root_mean_squared_error: 0.6778 - val_loss: 0.4805 - val_root_mean_squared_error: 0.6718\n","Epoch 18/100\n","7204/7204 [==============================] - 5s 703us/step - loss: 0.1056 - root_mean_squared_error: 0.6659 - val_loss: 0.5182 - val_root_mean_squared_error: 0.6606\n","Epoch 19/100\n","7204/7204 [==============================] - 5s 701us/step - loss: 0.1085 - root_mean_squared_error: 0.6554 - val_loss: 0.6402 - val_root_mean_squared_error: 0.6512\n","Epoch 20/100\n","7204/7204 [==============================] - 5s 700us/step - loss: 0.1033 - root_mean_squared_error: 0.6469 - val_loss: 0.4755 - val_root_mean_squared_error: 0.6422\n","Epoch 21/100\n","7204/7204 [==============================] - 5s 701us/step - loss: 0.1048 - root_mean_squared_error: 0.6377 - val_loss: 0.4509 - val_root_mean_squared_error: 0.6334\n","Epoch 22/100\n","7204/7204 [==============================] - 5s 700us/step - loss: 0.1047 - root_mean_squared_error: 0.6291 - val_loss: 0.4492 - val_root_mean_squared_error: 0.6251\n","Epoch 23/100\n","7204/7204 [==============================] - 5s 708us/step - loss: 0.1030 - root_mean_squared_error: 0.6211 - val_loss: 0.4919 - val_root_mean_squared_error: 0.6176\n","Epoch 24/100\n","7204/7204 [==============================] - 5s 709us/step - loss: 0.1013 - root_mean_squared_error: 0.6140 - val_loss: 0.5860 - val_root_mean_squared_error: 0.6110\n","Epoch 25/100\n","7204/7204 [==============================] - 5s 704us/step - loss: 0.1012 - root_mean_squared_error: 0.6080 - val_loss: 0.5183 - val_root_mean_squared_error: 0.6050\n","Epoch 26/100\n","7204/7204 [==============================] - 5s 699us/step - loss: 0.1030 - root_mean_squared_error: 0.6019 - val_loss: 0.6042 - val_root_mean_squared_error: 0.5995\n","Epoch 27/100\n","7204/7204 [==============================] - 5s 697us/step - loss: 0.0984 - root_mean_squared_error: 0.5968 - val_loss: 0.5020 - val_root_mean_squared_error: 0.5942\n","Epoch 28/100\n","7204/7204 [==============================] - 5s 707us/step - loss: 0.0975 - root_mean_squared_error: 0.5914 - val_loss: 0.4575 - val_root_mean_squared_error: 0.5887\n","Epoch 29/100\n","7204/7204 [==============================] - 5s 698us/step - loss: 0.0985 - root_mean_squared_error: 0.5860 - val_loss: 0.5028 - val_root_mean_squared_error: 0.5837\n","Epoch 30/100\n","7204/7204 [==============================] - 5s 698us/step - loss: 0.0975 - root_mean_squared_error: 0.5812 - val_loss: 0.5594 - val_root_mean_squared_error: 0.5792\n","Epoch 31/100\n","7204/7204 [==============================] - 5s 706us/step - loss: 0.0966 - root_mean_squared_error: 0.5770 - val_loss: 0.5053 - val_root_mean_squared_error: 0.5749\n","Epoch 32/100\n","7204/7204 [==============================] - 5s 701us/step - loss: 0.0957 - root_mean_squared_error: 0.5727 - val_loss: 0.4239 - val_root_mean_squared_error: 0.5705\n","Epoch 33/100\n","7204/7204 [==============================] - 5s 702us/step - loss: 0.0957 - root_mean_squared_error: 0.5681 - val_loss: 0.4092 - val_root_mean_squared_error: 0.5660\n","Epoch 34/100\n","7204/7204 [==============================] - 5s 705us/step - loss: 0.0931 - root_mean_squared_error: 0.5638 - val_loss: 0.3892 - val_root_mean_squared_error: 0.5617\n","Epoch 35/100\n","7204/7204 [==============================] - 5s 699us/step - loss: 0.0931 - root_mean_squared_error: 0.5595 - val_loss: 0.4396 - val_root_mean_squared_error: 0.5576\n","Epoch 36/100\n","7204/7204 [==============================] - 5s 702us/step - loss: 0.0919 - root_mean_squared_error: 0.5556 - val_loss: 0.4023 - val_root_mean_squared_error: 0.5538\n","Epoch 37/100\n","7204/7204 [==============================] - 5s 699us/step - loss: 0.0933 - root_mean_squared_error: 0.5518 - val_loss: 0.5805 - val_root_mean_squared_error: 0.5505\n","Epoch 38/100\n","7204/7204 [==============================] - 5s 700us/step - loss: 0.0922 - root_mean_squared_error: 0.5490 - val_loss: 0.5145 - val_root_mean_squared_error: 0.5476\n","Epoch 39/100\n","7204/7204 [==============================] - 5s 705us/step - loss: 0.0906 - root_mean_squared_error: 0.5460 - val_loss: 0.5055 - val_root_mean_squared_error: 0.5446\n","Epoch 40/100\n","7204/7204 [==============================] - 5s 704us/step - loss: 0.0915 - root_mean_squared_error: 0.5431 - val_loss: 0.4553 - val_root_mean_squared_error: 0.5417\n","Epoch 41/100\n","7204/7204 [==============================] - 5s 700us/step - loss: 0.0901 - root_mean_squared_error: 0.5401 - val_loss: 0.4602 - val_root_mean_squared_error: 0.5387\n","Epoch 42/100\n","7204/7204 [==============================] - 5s 704us/step - loss: 0.0884 - root_mean_squared_error: 0.5372 - val_loss: 0.5184 - val_root_mean_squared_error: 0.5360\n","Epoch 43/100\n","7204/7204 [==============================] - 5s 699us/step - loss: 0.0897 - root_mean_squared_error: 0.5347 - val_loss: 0.4226 - val_root_mean_squared_error: 0.5334\n","Epoch 44/100\n","7204/7204 [==============================] - 5s 700us/step - loss: 0.0865 - root_mean_squared_error: 0.5319 - val_loss: 0.4654 - val_root_mean_squared_error: 0.5307\n","Epoch 45/100\n","7204/7204 [==============================] - 5s 702us/step - loss: 0.0881 - root_mean_squared_error: 0.5293 - val_loss: 0.3835 - val_root_mean_squared_error: 0.5280\n","Epoch 46/100\n","7204/7204 [==============================] - 5s 702us/step - loss: 0.0874 - root_mean_squared_error: 0.5266 - val_loss: 0.5200 - val_root_mean_squared_error: 0.5255\n","Epoch 47/100\n","7204/7204 [==============================] - 5s 702us/step - loss: 0.0865 - root_mean_squared_error: 0.5244 - val_loss: 0.4295 - val_root_mean_squared_error: 0.5232\n","Epoch 48/100\n","7204/7204 [==============================] - 5s 699us/step - loss: 0.0864 - root_mean_squared_error: 0.5220 - val_loss: 0.4410 - val_root_mean_squared_error: 0.5209\n","Epoch 49/100\n","7204/7204 [==============================] - 5s 703us/step - loss: 0.0855 - root_mean_squared_error: 0.5197 - val_loss: 0.4867 - val_root_mean_squared_error: 0.5187\n","Epoch 50/100\n","7204/7204 [==============================] - 5s 704us/step - loss: 0.0863 - root_mean_squared_error: 0.5177 - val_loss: 0.4986 - val_root_mean_squared_error: 0.5167\n","Epoch 51/100\n","7204/7204 [==============================] - 5s 702us/step - loss: 0.0851 - root_mean_squared_error: 0.5158 - val_loss: 0.4559 - val_root_mean_squared_error: 0.5148\n","Epoch 52/100\n","7204/7204 [==============================] - 5s 706us/step - loss: 0.0851 - root_mean_squared_error: 0.5137 - val_loss: 0.4099 - val_root_mean_squared_error: 0.5127\n","Epoch 53/100\n","7204/7204 [==============================] - 5s 697us/step - loss: 0.0844 - root_mean_squared_error: 0.5116 - val_loss: 0.4560 - val_root_mean_squared_error: 0.5107\n","Epoch 54/100\n","7204/7204 [==============================] - 5s 698us/step - loss: 0.0827 - root_mean_squared_error: 0.5097 - val_loss: 0.4167 - val_root_mean_squared_error: 0.5087\n","Epoch 55/100\n","7204/7204 [==============================] - 5s 701us/step - loss: 0.0815 - root_mean_squared_error: 0.5077 - val_loss: 0.4724 - val_root_mean_squared_error: 0.5068\n","Epoch 56/100\n","7204/7204 [==============================] - 5s 702us/step - loss: 0.0811 - root_mean_squared_error: 0.5059 - val_loss: 0.4222 - val_root_mean_squared_error: 0.5050\n","Epoch 57/100\n","7204/7204 [==============================] - 5s 700us/step - loss: 0.0795 - root_mean_squared_error: 0.5040 - val_loss: 0.4251 - val_root_mean_squared_error: 0.5031\n","Epoch 58/100\n","7204/7204 [==============================] - 5s 702us/step - loss: 0.0774 - root_mean_squared_error: 0.5022 - val_loss: 0.4064 - val_root_mean_squared_error: 0.5013\n","Epoch 59/100\n","7204/7204 [==============================] - 5s 702us/step - loss: 0.0783 - root_mean_squared_error: 0.5003 - val_loss: 0.4760 - val_root_mean_squared_error: 0.4996\n","Epoch 60/100\n","7204/7204 [==============================] - 5s 702us/step - loss: 0.0770 - root_mean_squared_error: 0.4987 - val_loss: 0.3584 - val_root_mean_squared_error: 0.4978\n","Epoch 61/100\n","7204/7204 [==============================] - 5s 705us/step - loss: 0.0797 - root_mean_squared_error: 0.4968 - val_loss: 0.3806 - val_root_mean_squared_error: 0.4960\n","Epoch 62/100\n","7204/7204 [==============================] - 5s 701us/step - loss: 0.0786 - root_mean_squared_error: 0.4951 - val_loss: 0.3983 - val_root_mean_squared_error: 0.4943\n","Epoch 63/100\n","7204/7204 [==============================] - 5s 703us/step - loss: 0.0768 - root_mean_squared_error: 0.4934 - val_loss: 0.3396 - val_root_mean_squared_error: 0.4925\n","Epoch 64/100\n","7204/7204 [==============================] - 5s 702us/step - loss: 0.0770 - root_mean_squared_error: 0.4916 - val_loss: 0.4518 - val_root_mean_squared_error: 0.4909\n","Epoch 65/100\n","7204/7204 [==============================] - 5s 698us/step - loss: 0.0732 - root_mean_squared_error: 0.4901 - val_loss: 0.4298 - val_root_mean_squared_error: 0.4894\n","Epoch 66/100\n","7204/7204 [==============================] - 5s 704us/step - loss: 0.0740 - root_mean_squared_error: 0.4886 - val_loss: 0.3650 - val_root_mean_squared_error: 0.4878\n","Epoch 67/100\n","7204/7204 [==============================] - 5s 699us/step - loss: 0.0744 - root_mean_squared_error: 0.4870 - val_loss: 0.3584 - val_root_mean_squared_error: 0.4862\n","Epoch 68/100\n","7204/7204 [==============================] - 5s 700us/step - loss: 0.0734 - root_mean_squared_error: 0.4853 - val_loss: 0.4048 - val_root_mean_squared_error: 0.4846\n","Epoch 69/100\n","7204/7204 [==============================] - 5s 702us/step - loss: 0.0722 - root_mean_squared_error: 0.4839 - val_loss: 0.3204 - val_root_mean_squared_error: 0.4831\n","Epoch 70/100\n","7204/7204 [==============================] - 5s 699us/step - loss: 0.0712 - root_mean_squared_error: 0.4822 - val_loss: 0.3340 - val_root_mean_squared_error: 0.4814\n","Epoch 71/100\n","7204/7204 [==============================] - 5s 707us/step - loss: 0.0720 - root_mean_squared_error: 0.4806 - val_loss: 0.4769 - val_root_mean_squared_error: 0.4801\n","Epoch 72/100\n","7204/7204 [==============================] - 5s 704us/step - loss: 0.0703 - root_mean_squared_error: 0.4794 - val_loss: 0.3278 - val_root_mean_squared_error: 0.4787\n","Epoch 73/100\n","7204/7204 [==============================] - 5s 703us/step - loss: 0.0716 - root_mean_squared_error: 0.4779 - val_loss: 0.4251 - val_root_mean_squared_error: 0.4773\n","Epoch 74/100\n","7204/7204 [==============================] - 5s 705us/step - loss: 0.0685 - root_mean_squared_error: 0.4766 - val_loss: 0.3815 - val_root_mean_squared_error: 0.4760\n","Epoch 75/100\n","7204/7204 [==============================] - 5s 704us/step - loss: 0.0694 - root_mean_squared_error: 0.4753 - val_loss: 0.2642 - val_root_mean_squared_error: 0.4745\n","Epoch 76/100\n","7204/7204 [==============================] - 5s 703us/step - loss: 0.0683 - root_mean_squared_error: 0.4736 - val_loss: 0.4058 - val_root_mean_squared_error: 0.4730\n","Epoch 77/100\n","7204/7204 [==============================] - 5s 707us/step - loss: 0.0678 - root_mean_squared_error: 0.4724 - val_loss: 0.3625 - val_root_mean_squared_error: 0.4718\n","Epoch 78/100\n","7204/7204 [==============================] - 5s 706us/step - loss: 0.0684 - root_mean_squared_error: 0.4711 - val_loss: 0.3859 - val_root_mean_squared_error: 0.4705\n","Epoch 79/100\n","7204/7204 [==============================] - 5s 701us/step - loss: 0.0682 - root_mean_squared_error: 0.4699 - val_loss: 0.3351 - val_root_mean_squared_error: 0.4692\n","Epoch 80/100\n","7204/7204 [==============================] - 5s 706us/step - loss: 0.0674 - root_mean_squared_error: 0.4685 - val_loss: 0.2678 - val_root_mean_squared_error: 0.4678\n","Epoch 81/100\n","7204/7204 [==============================] - 5s 701us/step - loss: 0.0648 - root_mean_squared_error: 0.4670 - val_loss: 0.3629 - val_root_mean_squared_error: 0.4664\n","Epoch 82/100\n","7204/7204 [==============================] - 5s 705us/step - loss: 0.0656 - root_mean_squared_error: 0.4658 - val_loss: 0.3072 - val_root_mean_squared_error: 0.4651\n","Epoch 83/100\n","7204/7204 [==============================] - 5s 706us/step - loss: 0.0643 - root_mean_squared_error: 0.4644 - val_loss: 0.2376 - val_root_mean_squared_error: 0.4637\n","Epoch 84/100\n","7204/7204 [==============================] - 5s 707us/step - loss: 0.0629 - root_mean_squared_error: 0.4629 - val_loss: 0.2651 - val_root_mean_squared_error: 0.4622\n","Epoch 85/100\n","7204/7204 [==============================] - 5s 710us/step - loss: 0.0620 - root_mean_squared_error: 0.4615 - val_loss: 0.4125 - val_root_mean_squared_error: 0.4610\n","Epoch 86/100\n","7204/7204 [==============================] - 5s 705us/step - loss: 0.0629 - root_mean_squared_error: 0.4604 - val_loss: 0.3351 - val_root_mean_squared_error: 0.4599\n","Epoch 87/100\n","7204/7204 [==============================] - 5s 698us/step - loss: 0.0622 - root_mean_squared_error: 0.4592 - val_loss: 0.3190 - val_root_mean_squared_error: 0.4587\n","Epoch 88/100\n","7204/7204 [==============================] - 5s 701us/step - loss: 0.0593 - root_mean_squared_error: 0.4580 - val_loss: 0.3061 - val_root_mean_squared_error: 0.4574\n","Epoch 89/100\n","7204/7204 [==============================] - 5s 699us/step - loss: 0.0594 - root_mean_squared_error: 0.4568 - val_loss: 0.3184 - val_root_mean_squared_error: 0.4562\n","Epoch 90/100\n","7204/7204 [==============================] - 5s 704us/step - loss: 0.0590 - root_mean_squared_error: 0.4556 - val_loss: 0.3993 - val_root_mean_squared_error: 0.4551\n","Epoch 91/100\n","7204/7204 [==============================] - 5s 699us/step - loss: 0.0589 - root_mean_squared_error: 0.4546 - val_loss: 0.2964 - val_root_mean_squared_error: 0.4540\n","Epoch 92/100\n","7204/7204 [==============================] - 5s 699us/step - loss: 0.0576 - root_mean_squared_error: 0.4534 - val_loss: 0.3074 - val_root_mean_squared_error: 0.4528\n","Epoch 93/100\n","7204/7204 [==============================] - 5s 698us/step - loss: 0.0593 - root_mean_squared_error: 0.4522 - val_loss: 0.3201 - val_root_mean_squared_error: 0.4517\n","Epoch 94/100\n","7204/7204 [==============================] - 5s 703us/step - loss: 0.0579 - root_mean_squared_error: 0.4511 - val_loss: 0.2491 - val_root_mean_squared_error: 0.4505\n","Epoch 95/100\n","7204/7204 [==============================] - 5s 703us/step - loss: 0.0585 - root_mean_squared_error: 0.4498 - val_loss: 0.2464 - val_root_mean_squared_error: 0.4492\n","Epoch 96/100\n","7204/7204 [==============================] - 5s 697us/step - loss: 0.0562 - root_mean_squared_error: 0.4486 - val_loss: 0.2853 - val_root_mean_squared_error: 0.4480\n","Epoch 97/100\n","7204/7204 [==============================] - 5s 702us/step - loss: 0.0573 - root_mean_squared_error: 0.4474 - val_loss: 0.3164 - val_root_mean_squared_error: 0.4469\n","Epoch 98/100\n","7204/7204 [==============================] - 5s 702us/step - loss: 0.0561 - root_mean_squared_error: 0.4464 - val_loss: 0.2888 - val_root_mean_squared_error: 0.4458\n","Epoch 99/100\n","7204/7204 [==============================] - 5s 708us/step - loss: 0.0542 - root_mean_squared_error: 0.4453 - val_loss: 0.3101 - val_root_mean_squared_error: 0.4447\n","Epoch 100/100\n","7204/7204 [==============================] - 5s 706us/step - loss: 0.0544 - root_mean_squared_error: 0.4442 - val_loss: 0.3105 - val_root_mean_squared_error: 0.4437\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f107ee2ee10>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"ZW0hV8XMtNMm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1593341904974,"user_tz":-120,"elapsed":3523,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}},"outputId":"9ea0ebbf-5164-4c1e-b751-cf0539a6d032"},"source":["from sklearn.metrics import mean_squared_error\n","\n","predTrain = model.predict([Xtrain,train_imgs_loaded])\n","predVal = model.predict([Xval,val_imgs_loaded])\n","\n","#deshacemos la transformación logarítmica\n","predTrain_Eur = pd.DataFrame(predTrain).apply(lambda x: 10**(x))\n","predVal_Eur = pd.DataFrame(predVal).apply(lambda x: 10**(x))\n","Ytrain_Eur = pd.DataFrame(ytrain).apply(lambda x: 10**(x))\n","Yval_Eur = pd.DataFrame(yval).apply(lambda x: 10**(x))\n","\n","#calculamos el MSE y el RMSE para train y test\n","mseTrainModel = mean_squared_error(Ytrain_Eur,predTrain_Eur)\n","mseValModel = mean_squared_error(Yval_Eur,predVal_Eur)\n","\n","print('MSE (train): %0.3g' % mseTrainModel)\n","print('MSE (val) : %0.3g' % mseValModel)\n","\n","print('RMSE (train): %0.3g' % np.sqrt(mseTrainModel))\n","print('RMSE (val) : %0.3g' % np.sqrt(mseValModel))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["MSE (train): 5.14e+03\n","MSE (val) : 4.94e+03\n","RMSE (train): 71.7\n","RMSE (val) : 70.3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JkcaXobaqDGp","colab_type":"text"},"source":["Los resultados no son nada buenos, pero es debido a las limitaciones que hemos venido comentando en los notebooks anteriores.\n","\n","Por último evaluamos el modelo con el conjunto de test."]},{"cell_type":"code","metadata":{"id":"xnXJIhQWOKI8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1593343351764,"user_tz":-120,"elapsed":1387,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}},"outputId":"17d15b9f-0b3a-4d31-e1e3-5e6128286129"},"source":["# Evaluamos el modelo\n","scores = model.evaluate([Xtest,test_imgs_loaded], ytest)\n","\n","print('Loss: %.3f' % scores[0])\n","print('RMSE: %.3f' % scores[1])\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["2277/2277 [==============================] - 1s 403us/step\n","Loss: 0.310\n","RMSE: 0.444\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b0a_38ZRqhYb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1593343434542,"user_tz":-120,"elapsed":3490,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}},"outputId":"656555e2-fff5-4916-fc13-927081e7e297"},"source":["predTrain = model.predict([Xtrain,train_imgs_loaded])\n","predTest = model.predict([Xtest,test_imgs_loaded])\n","\n","#deshacemos la transformación logarítmica\n","predTrain_Eur = pd.DataFrame(predTrain).apply(lambda x: 10**(x))\n","predTest_Eur = pd.DataFrame(predTest).apply(lambda x: 10**(x))\n","Ytrain_Eur = pd.DataFrame(ytrain).apply(lambda x: 10**(x))\n","Ytest_Eur = pd.DataFrame(ytest).apply(lambda x: 10**(x))\n","\n","#calculamos el MSE y el RMSE para train y test\n","mseTrainModel = mean_squared_error(Ytrain_Eur,predTrain_Eur)\n","mseTestModel = mean_squared_error(Ytest_Eur,predTest_Eur)\n","\n","print('MSE (train): %0.3g' % mseTrainModel)\n","print('MSE (test) : %0.3g' % mseTestModel)\n","\n","print('RMSE (train): %0.3g' % np.sqrt(mseTrainModel))\n","print('RMSE (test) : %0.3g' % np.sqrt(mseTestModel))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["MSE (train): 5.14e+03\n","MSE (test) : 6.34e+03\n","RMSE (train): 71.7\n","RMSE (test) : 79.6\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kDYBJ06gq6RK","colab_type":"text"},"source":["**CONCLUSIÓN FINAL**\n","\n","A la vista de los resultados podríamos decir que ningún modelo tiene una precisión lo suficientemente alta como para poder darlo por bueno. Tiene mucho margen de mejora.\n","El mejor modelo sería el que considera simplemente los datos numéricos y categóricos. Allí para el conjunto de test obtuvimos un RMSE de 29€ frente a los más de 70€ que tenemos en los otros dos modelos donde entran en juego las imágenes.\n","\n","Hay que recordar la complejidad del dataset para obtener buenos resultados, y a eso podemos añadir los siguientes aspectos como posibles puntos de mejora:\n","\n","- las limitaciones de procesamiento que nos ha obligado a reducir el tamaño de las imágenes (de 224x224 a 64x64)\n","- el procesado de los datos se ha visto limitado ya que he centrado los esfuerzos en hacer funcionar los modelos y no he podido sacar tiempo para filtar outlier o quitar las entradas que no son de la ciudad de Madrid, por ejemplo.\n","- Haría falta técnicas de NLP para procesar mejor ciertas variables descriptivas y que aportaran más información sobre el precio. No es lo mismo contabilizar un número concreto de características que evaluarlas en función de su importancia."]},{"cell_type":"code","metadata":{"id":"3-jrcprIsrpw","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}