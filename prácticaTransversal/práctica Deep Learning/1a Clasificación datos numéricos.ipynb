{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1a Clasificación datos numéricos.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1cnLB4W0Xq_TSuQMdblVZOLF9Oae1G5-2","authorship_tag":"ABX9TyNjr0STCNMP8vEgrIN9yfV+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"CF3PrvWJ6X8t","colab_type":"text"},"source":["**CLASIFICACIÓN PARTIENDO DE DATOS NUMÉRICOS Y CATEGÓRICOS**\n","\n","En este notebook vamos a tratar de clasificar los apartamentos según su precio en baratos, medios o caros. Para ello estableceremos los límites en 50€ para los baratos y 150€ para los caros.\n","Dicha predicción se va a hacer a partir de los datos numéricos y categóricos que tenemos en el dataset de airbnb que venimos usando en las prácticas de este Bootcamp.\n","\n","En primer lugar nos descargamos el fichero de internet y lo copiamos en un directorio local de My Drive donde tenemos recogido todo el entorno de esta práctica.\n","También montamos el google collab con My Drive para tenerlo vinculado. \n","\n","Solo será necesario la primera vez, luego podemos bajar unas celdas más abajo para seguir con el ejercicio."]},{"cell_type":"code","metadata":{"id":"yGAWhUGP6nRG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":343},"executionInfo":{"status":"ok","timestamp":1593064923489,"user_tz":-120,"elapsed":62620,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}},"outputId":"a49fee41-1611-48e3-9bd8-5cb4329ec326"},"source":["# nos descargamos el dataset de OpenDataSoft\n","!wget -O \"airbnb-listings.csv\" \"https://public.opendatasoft.com/explore/dataset/airbnb-listings/download/?format=csv&disjunctive.host_verifications=true&disjunctive.amenities=true&disjunctive.features=true&refine.country=Spain&q=Madrid&timezone=Europe/London&use_labels_for_header=true&csv_separator=%3B\"\n","\n","!ls -lah"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-06-25 06:01:03--  https://public.opendatasoft.com/explore/dataset/airbnb-listings/download/?format=csv&disjunctive.host_verifications=true&disjunctive.amenities=true&disjunctive.features=true&refine.country=Spain&q=Madrid&timezone=Europe/London&use_labels_for_header=true&csv_separator=%3B\n","Resolving public.opendatasoft.com (public.opendatasoft.com)... 34.249.199.226, 34.248.20.69\n","Connecting to public.opendatasoft.com (public.opendatasoft.com)|34.249.199.226|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [application/csv]\n","Saving to: ‘airbnb-listings.csv’\n","\n","airbnb-listings.csv     [  <=>               ]  54.19M  2.77MB/s    in 50s     \n","\n","2020-06-25 06:02:01 (1.09 MB/s) - ‘airbnb-listings.csv’ saved [56826824]\n","\n","total 55M\n","drwxr-xr-x 1 root root 4.0K Jun 25 06:01 .\n","drwxr-xr-x 1 root root 4.0K Jun 25 05:59 ..\n","-rw-r--r-- 1 root root  55M Jun 25 06:02 airbnb-listings.csv\n","drwxr-xr-x 1 root root 4.0K Jun 19 16:15 .config\n","drwx------ 4 root root 4.0K Jun 25 06:00 drive\n","drwxr-xr-x 1 root root 4.0K Jun 17 16:18 sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-4dDxIX4wNAb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1593065528952,"user_tz":-120,"elapsed":3795,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}},"outputId":"9835d31b-f71d-4d09-fbbb-343c30456966"},"source":["!ls -lah"],"execution_count":null,"outputs":[{"output_type":"stream","text":["total 109M\n","drwxr-xr-x 1 root root 4.0K Jun 25 06:05 .\n","drwxr-xr-x 1 root root 4.0K Jun 25 05:59 ..\n","-rw-r--r-- 1 root root  55M Jun 25 06:02 airbnb-listings.csv\n","drwxr-xr-x 1 root root 4.0K Jun 19 16:15 .config\n","drwx------ 4 root root 4.0K Jun 25 06:00 drive\n","drwxr-xr-x 1 root root 4.0K Jun 17 16:18 sample_data\n","-rw-r--r-- 1 root root  11M Jun 25 06:05 test.csv\n","-rw-r--r-- 1 root root  35M Jun 25 06:05 train.csv\n","-rw-r--r-- 1 root root 8.9M Jun 25 06:05 val.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YLSxaq6U32t_","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"27R_6DOoEpEF","colab_type":"code","colab":{}},"source":["!cp airbnb-listings.csv \"drive/My Drive/BootcampBD&ML/práctica/prácticaDeepLearning\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hJu_2Fcm8qNz","colab_type":"text"},"source":["Esta parte de descarga, montado y copiado solo hace falta ejecutarla la primera vez. Una vez que lo tenemos almacenado en My Drive solo necesitamos cargarlo directamente.\n","\n","A partir de aquí empieza nuestro ejercicio de clasificación.\n","\n","Como hábito de buena costumbre, para no incurrir en errores involuntarios, en primer lugar se va a dividir el dataset original en train, validación y test.\n","\n","Se trabaja únicamente con el de train con el objetivo de elegir un modelo. Eso se verifica con el conjunto de validation y finalmente se aplica ese \"entrenamiento\" al bloque de test."]},{"cell_type":"code","metadata":{"id":"xGqFBaR0Tt4y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593241469617,"user_tz":-120,"elapsed":844,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}},"outputId":"b22779c9-8d31-4240-e4a5-df81c9b53023"},"source":["%tensorflow_version 1.x"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TKNlisDc8sQq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1593241497684,"user_tz":-120,"elapsed":19961,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}},"outputId":"70eb7de2-1c0e-4867-fb5b-0bd180a0039e"},"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","%matplotlib inline\n","cm = plt.cm.RdBu\n","cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","\n","\n","\n","full_df = pd.read_csv('drive/My Drive/BootcampBD&ML/práctica/prácticaDeepLearning/airbnb-listings.csv', sep=';', decimal='.')\n","full_train, test = train_test_split(full_df, test_size=0.2, shuffle=True, random_state=0)\n","train, val = train_test_split(full_train, test_size=0.2, shuffle=True, random_state=0)\n","\n","print(f'Dimensiones del dataset de training: {train.shape}')\n","print(f'Dimensiones del dataset de validación: {val.shape}')\n","print(f'Dimensiones del dataset de test: {test.shape}')\n","\n","# Guardamos\n","train.to_csv('./train.csv', sep=';', decimal='.', index=True)\n","val.to_csv('./val.csv', sep=';', decimal='.', index=True)\n","test.to_csv('./test.csv', sep=';', decimal='.', index=True)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Dimensiones del dataset de training: (8960, 89)\n","Dimensiones del dataset de validación: (2240, 89)\n","Dimensiones del dataset de test: (2801, 89)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Evo4RXBM_ClY","colab_type":"text"},"source":["En primer lugar vamos a procesar nuestros datos de entrada con la intención de darles el formato adecuado y que nuestro modelo pueda trabajar con ellos.\n","\n","Vemos que hay 89 columnas y necesitamos saber qué tipo de información disponemos. En este punto nos valemos del trabajo ya realizado en el módulo de ML. Queda explicado a continuación:\n","\n","1.- Filtramos por la ciudad de Madrid. Quiero asegurarme que solo trabajamos con apartamentos de dicha ciudad.\n","\n","2.- Analizamos nuestras features y decidimos si los vamos a usar en nuestro entrenamiento o si podemos prescindir de ellas. Para ello usamos los siguientes comandos: - df['xxxxx'].describe() - df['xxxxx'].value_counts()\n","\n","Podemos destacar las siguientes agrupaciones de columnas:\n","\n","- Columnas relacionadas con ID: considero que es información que identifica cada propiedad de forma singular y unívoca y no guarda ninguna relación con otras propiedades ni sus precios. Podemos eliminarlas de nuestro dataset. ['ID','Scrape ID','Last Scraped','Host ID','Calendar last Scraped']\n","- Columnas relacionas con URLs: son URLs que nos direccionan a otro sitio web e incluyen fotos. En este caso no vamos a hacer tratamiento de imagen, así que podemos eliminarlas. ['Listing Url','Thumbnail Url','Medium Url','Picture Url','XL Picture Url','Host URL','Host Thumbnail Url','Host Picture Url',]\n","- Columnas descriptivas: Son columnas de tipo objeto. Contienen mucha literatura y la información es redundante con otras más específicas. Son resúmenes detallando el tipo de propiedad y sus características (número de habitaciones, calle, barrio, etc). Se da el caso también que el número de entradas únicas para cada una de estas columnas es muy parecido al número total, por lo que además es muy complicado hacer agrupaciones o clústers. Por tanto podemos eliminarlas. ['Name','Summary','Space','Description','Neighborhood Overview','Notes','Transit','Access','Interaction','House Rules','Host Name','Host About','Street']\n","- Columnas que hacen referencia a Madrid, España: Ya hemos filtrado por la ciudad de Madrid, así que la información relacionada con País, Estado o similar no nos aporta nada. Añadimos también la columna Geolocation que está duplicada con Latitude y Longitude. Podemos eliminarlas del dataset. ['Host Location','State','Market','Smart Location','Country Code','Country','Geolocation']\n","- Columnas relacionadas con el precio: son columnas que nos hacen trampa a la hora de predecir el precio. Las eliminamos del dataset. ['Weekly Price','Monthly Price']\n","- Otras columnas que no aportan valor: aquí agrupamos columnas donde todos los valores son none, están vacías o solo tienen valores un número de entradas menor que el 5% del total del dataset. ['Host Acceptance Rate','Experiences Offered','Has Availability','License','Jurisdiction Names','Square Feet']\n","\n","3.- Analizamos la variable objetivo: Price. Vamos a ver su histograma y sus datos más relevantes:\n","<img src='https://docs.google.com/drawings/d/1JZwa8QDoZVXf7xI9etKMyambCuNas55_K8R7IwCvbnk/edit?usp=sharing' alt=\"data_blending\" border=\"0\" width=\"500\">\n","![](https://drive.google.com/uc?export=view&id=1JZwa8QDoZVXf7xI9etKMyambCuNas55_K8R7IwCvbnk)\n","![](img/Hist Price)\n","<figure>\n","<center>\n","<img src='https://docs.google.com/drawings/d/1JZwa8QDoZVXf7xI9etKMyambCuNas55_K8R7IwCvbnk/edit?usp=sharing' />\n","<figcaption>Image Caption</figcaption></center>\n","</figure>\n","\n","A la vista de los resultados consideramos que más de 400€ es outlier y hay 6 entradas en las que hay que imputar valores. Lo haremos usando la media. Además se aprecia que tiene una distribución logarítmica, por lo que vamos a aplicarle también dicha transformación\n","\n","4.- Trabajamos con las columnas que sabemos son de tipo fecha. En primer lugar le damos formato de año-mes-día y luego lo restamos a 2017, que lo tomamos como referencia de cuando se creó el dataset. De esta forma obtenemos columnas de tipo float cuyo valor mínimo será 0 (indica que es muy reciente) y el máximo será el número de años de diferencia entre 2017 y el evento concreto (Host since o First/Last Review).\n","\n","5.- Imputamos valores para completar nuestro dataset. Usamos la siguiente línea para ver donde hay campos vacíos: filtered_df.isnull().any(), y esta otra para ver el detalle de los valores: filtered_df['xxxx'].describe()\n","\n","6.- Analizamos variables descriptivas y contamos palabras. Este método es algo muy básico y no nos aporta una información precisa. Queda pendiente de mejora con técnicas NLP.\n","\n","7.- Analizamos las columnas que todavía no son numéricas. La idea es transformarlas o codificarlas con un MeanEncoder. Utilizamos el comando filtered_df.dtypes para comprobarlo.\n","\n","8.- Eliminimos la variable Price ya que está categorizada y si lo usamos como entrada nos falsearía el trabajo de predicción que pretendemos hacer.\n","\n","9.- Damos formato a nuestro dataset para devolver por un lado las variables de entrada X y la variable objetivo Y.\n","\n","10.- Escalamos los valores para usar valores entre 0 y 1 y así obtener mejor resultados con nuestros modelos.\n","\n","\n","Es importante destacar que todas esas transformaciones las hacemos en nuestros tres conjuntos de trabajo para ya tenerlos preparados. Tomamos siempre como referencia los valores obtenidos en nuestro conjuntos de train y los aplicamos a los valores de validation y test."]},{"cell_type":"code","metadata":{"id":"HfVX3OLS-koQ","colab_type":"code","colab":{}},"source":["# A partir de este momento cargamos el dataset de train y trabajamos ÚNICAMENTE con él. \n","df_train = pd.read_csv('./train.csv', sep=';', decimal='.')\n","df_val = pd.read_csv('./val.csv', sep=';', decimal='.')\n","df_test = pd.read_csv('./test.csv', sep=';', decimal='.')\n","\n","def preprocesado(train, val, test):\n","  #Nos quedamos solo con las filas que pertenecen a la ciudad de Madrid\n","  indexNames = train[ train['City'] != 'Madrid' ].index\n","  train.drop(indexNames , inplace=True)\n","  train.drop(['City'], axis=1, inplace=True)\n","\n","  indexNames = val[ val['City'] != 'Madrid' ].index\n","  val.drop(indexNames , inplace=True)\n","  val.drop(['City'], axis=1, inplace=True)\n","\n","  indexNames = test[ test['City'] != 'Madrid' ].index\n","  test.drop(indexNames , inplace=True)\n","  test.drop(['City'], axis=1, inplace=True)\n","\n","  #eliminamos las columnas que no aportan\n","  train.drop(['ID','Scrape ID','Last Scraped','Host ID','Calendar last Scraped','Listing Url','Thumbnail Url',\n","         'Medium Url','Picture Url','XL Picture Url','Host URL','Host Thumbnail Url','Host Picture Url',\n","        'Name','Summary','Space','Description','Neighborhood Overview','Notes','Transit','Access',\n","         'Interaction','House Rules','Host Name','Host About','Street','Host Location','State','Market',\n","         'Smart Location','Country Code','Country','Geolocation','Weekly Price','Monthly Price',\n","         'Host Acceptance Rate','Experiences Offered','Has Availability','License','Jurisdiction Names','Square Feet'], \n","        axis=1, inplace=True)\n","  val.drop(['ID','Scrape ID','Last Scraped','Host ID','Calendar last Scraped','Listing Url','Thumbnail Url',\n","         'Medium Url','Picture Url','XL Picture Url','Host URL','Host Thumbnail Url','Host Picture Url',\n","        'Name','Summary','Space','Description','Neighborhood Overview','Notes','Transit','Access',\n","         'Interaction','House Rules','Host Name','Host About','Street','Host Location','State','Market',\n","         'Smart Location','Country Code','Country','Geolocation','Weekly Price','Monthly Price',\n","         'Host Acceptance Rate','Experiences Offered','Has Availability','License','Jurisdiction Names','Square Feet'], \n","        axis=1, inplace=True)\n","  test.drop(['ID','Scrape ID','Last Scraped','Host ID','Calendar last Scraped','Listing Url','Thumbnail Url',\n","         'Medium Url','Picture Url','XL Picture Url','Host URL','Host Thumbnail Url','Host Picture Url',\n","        'Name','Summary','Space','Description','Neighborhood Overview','Notes','Transit','Access',\n","         'Interaction','House Rules','Host Name','Host About','Street','Host Location','State','Market',\n","         'Smart Location','Country Code','Country','Geolocation','Weekly Price','Monthly Price',\n","         'Host Acceptance Rate','Experiences Offered','Has Availability','License','Jurisdiction Names','Square Feet'], \n","        axis=1, inplace=True)\n","  \n","  #nueva variable --> en DL no lo uso (esta variable viene de ML) porque hemos visto que nos baja el accuracy\n","  #train['Bed_Bath_Rooms'] = train['Bedrooms']*train['Bathrooms']\n","  #val['Bed_Bath_Rooms'] = val['Bedrooms']*val['Bathrooms']\n","  #test['Bed_Bath_Rooms'] = test['Bedrooms']*test['Bathrooms']\n","  \n","  #PRICE\n","  #imputamos valores vacíos con la media de train\n","  MeanPriceTrain = train['Price'].mean()\n","  train['Price'].fillna(MeanPriceTrain, inplace=True)\n","  val['Price'].fillna(MeanPriceTrain, inplace=True)\n","  test['Price'].fillna(MeanPriceTrain, inplace=True)\n","  #definimos outlier >400€\n","  Price_filter = train['Price'] <= 400\n","  filtered_train = train[Price_filter]\n","  Price_filter = val['Price'] <= 400\n","  filtered_val = val[Price_filter]\n","  Price_filter = test['Price'] <= 400\n","  filtered_test = test[Price_filter]\n","  #transformamos variable Price a gausiana\n","  filtered_train['Price'] = filtered_train['Price'].apply(lambda x: np.log10(x))\n","  filtered_val['Price'] = filtered_val['Price'].apply(lambda x: np.log10(x))\n","  filtered_test['Price'] = filtered_test['Price'].apply(lambda x: np.log10(x))\n","  #categorizamos la variable precio en 3 tipos: barato (0), medio (1) y caro (2).\n","  filtered_train['Cat_Price'] = filtered_train['Price'].apply(lambda x: 0 if x < np.log10(50) else (1 if x < np.log10(150) else 2))\n","  filtered_val['Cat_Price'] = filtered_val['Price'].apply(lambda x: 0 if x < np.log10(50) else (1 if x < np.log10(150) else 2))\n","  filtered_test['Cat_Price'] = filtered_test['Price'].apply(lambda x: 0 if x < np.log10(50) else (1 if x < np.log10(150) else 2))\n","  \n","  \n","  #FECHAS\n","  filtered_train['Host Since'] = pd.to_datetime(filtered_train['Host Since'], format=\"%Y-%m-%d\")\n","  filtered_train['First Review'] = pd.to_datetime(filtered_train['First Review'], format=\"%Y-%m-%d\")\n","  filtered_train['Last Review'] = pd.to_datetime(filtered_train['Last Review'], format=\"%Y-%m-%d\")\n","  filtered_train['Host Since'] = filtered_train['Host Since'].apply(lambda x: 2017 - x.year)\n","  filtered_train['First Review'] = filtered_train['First Review'].apply(lambda x: 2017 - x.year)\n","  filtered_train['Last Review'] = filtered_train['Last Review'].apply(lambda x: 2017 - x.year)\n","\n","  filtered_val['Host Since'] = pd.to_datetime(filtered_val['Host Since'], format=\"%Y-%m-%d\")\n","  filtered_val['First Review'] = pd.to_datetime(filtered_val['First Review'], format=\"%Y-%m-%d\")\n","  filtered_val['Last Review'] = pd.to_datetime(filtered_val['Last Review'], format=\"%Y-%m-%d\")\n","  filtered_val['Host Since'] = filtered_val['Host Since'].apply(lambda x: 2017 - x.year)\n","  filtered_val['First Review'] = filtered_val['First Review'].apply(lambda x: 2017 - x.year)\n","  filtered_val['Last Review'] = filtered_val['Last Review'].apply(lambda x: 2017 - x.year)\n","\n","  filtered_test['Host Since'] = pd.to_datetime(filtered_test['Host Since'], format=\"%Y-%m-%d\")\n","  filtered_test['First Review'] = pd.to_datetime(filtered_test['First Review'], format=\"%Y-%m-%d\")\n","  filtered_test['Last Review'] = pd.to_datetime(filtered_test['Last Review'], format=\"%Y-%m-%d\")\n","  filtered_test['Host Since'] = filtered_test['Host Since'].apply(lambda x: 2017 - x.year)\n","  filtered_test['First Review'] = filtered_test['First Review'].apply(lambda x: 2017 - x.year)\n","  filtered_test['Last Review'] = filtered_test['Last Review'].apply(lambda x: 2017 - x.year)\n","\n","  #Imputamos valores en variables categóricas donde tomamos la moda para los valores que faltan.\n","  #Lo extraemos en una variable disinta para cada columna con la intención de aplicar el mismo valor en val y test\n","  ModeHSTrain = filtered_train['Host Since'].mode()[0]\n","  ModeHLCTrain = filtered_train['Host Listings Count'].mode()[0]\n","  ModeHTLCTrain = filtered_train['Host Total Listings Count'].mode()[0]\n","  ModeBathroomsTrain = filtered_train['Bathrooms'].mode()[0]\n","  ModeBedroomsTrain = filtered_train['Bedrooms'].mode()[0]\n","  ModeBedsTrain = filtered_train['Beds'].mode()[0]\n","\n","  filtered_train['Host Since'].fillna(ModeHSTrain, inplace=True)\n","  filtered_train['Host Listings Count'].fillna(ModeHLCTrain, inplace=True)\n","  filtered_train['Host Total Listings Count'].fillna(ModeHTLCTrain, inplace=True)\n","  filtered_train['Bathrooms'].fillna(ModeBathroomsTrain, inplace=True)\n","  filtered_train['Bedrooms'].fillna(ModeBedroomsTrain, inplace=True)\n","  filtered_train['Beds'].fillna(ModeBedsTrain, inplace=True)\n","\n","  filtered_val['Host Since'].fillna(ModeHSTrain, inplace=True)\n","  filtered_val['Host Listings Count'].fillna(ModeHLCTrain, inplace=True)\n","  filtered_val['Host Total Listings Count'].fillna(ModeHTLCTrain, inplace=True)\n","  filtered_val['Bathrooms'].fillna(ModeBathroomsTrain, inplace=True)\n","  filtered_val['Bedrooms'].fillna(ModeBedroomsTrain, inplace=True)\n","  filtered_val['Beds'].fillna(ModeBedsTrain, inplace=True)\n","  filtered_test['Host Since'].fillna(ModeHSTrain, inplace=True)\n","  filtered_test['Host Listings Count'].fillna(ModeHLCTrain, inplace=True)\n","  filtered_test['Host Total Listings Count'].fillna(ModeHTLCTrain, inplace=True)\n","  filtered_test['Bathrooms'].fillna(ModeBathroomsTrain, inplace=True)\n","  filtered_test['Bedrooms'].fillna(ModeBedroomsTrain, inplace=True)\n","  filtered_test['Beds'].fillna(ModeBedsTrain, inplace=True)\n","\n","  #Imputamos valores en variables lineales donde tomamos la media para los valores que faltan\n","  #Lo extraemos en una variable disinta para cada columna con la intención de aplicar el mismo valor en val y test\n","  MeanRSRatingTrain = filtered_train['Review Scores Rating'].mean()\n","  MeanRSAccuracyTrain = filtered_train['Review Scores Accuracy'].mean()\n","  MeanRSCleanlinessTrain = filtered_train['Review Scores Cleanliness'].mean()\n","  MeanRSCheckinTrain = filtered_train['Review Scores Checkin'].mean()\n","  MeanRSCommunicationTrain = filtered_train['Review Scores Communication'].mean()\n","  MeanRSLocationTrain = filtered_train['Review Scores Location'].mean()\n","  MeanRSValueTrain = filtered_train['Review Scores Value'].mean()\n","\n","  filtered_train['Review Scores Rating'].fillna(MeanRSRatingTrain, inplace=True)\n","  filtered_train['Review Scores Accuracy'].fillna(MeanRSAccuracyTrain, inplace=True)\n","  filtered_train['Review Scores Cleanliness'].fillna(MeanRSCleanlinessTrain, inplace=True)\n","  filtered_train['Review Scores Checkin'].fillna(MeanRSCheckinTrain, inplace=True)\n","  filtered_train['Review Scores Communication'].fillna(MeanRSCommunicationTrain, inplace=True)\n","  filtered_train['Review Scores Location'].fillna(MeanRSLocationTrain, inplace=True)\n","  filtered_train['Review Scores Value'].fillna(MeanRSValueTrain, inplace=True)\n","  filtered_val['Review Scores Rating'].fillna(MeanRSRatingTrain, inplace=True)\n","  filtered_val['Review Scores Accuracy'].fillna(MeanRSAccuracyTrain, inplace=True)\n","  filtered_val['Review Scores Cleanliness'].fillna(MeanRSCleanlinessTrain, inplace=True)\n","  filtered_val['Review Scores Checkin'].fillna(MeanRSCheckinTrain, inplace=True)\n","  filtered_val['Review Scores Communication'].fillna(MeanRSCommunicationTrain, inplace=True)\n","  filtered_val['Review Scores Location'].fillna(MeanRSLocationTrain, inplace=True)\n","  filtered_val['Review Scores Value'].fillna(MeanRSValueTrain, inplace=True)\n","  filtered_test['Review Scores Rating'].fillna(MeanRSRatingTrain, inplace=True)\n","  filtered_test['Review Scores Accuracy'].fillna(MeanRSAccuracyTrain, inplace=True)\n","  filtered_test['Review Scores Cleanliness'].fillna(MeanRSCleanlinessTrain, inplace=True)\n","  filtered_test['Review Scores Checkin'].fillna(MeanRSCheckinTrain, inplace=True)\n","  filtered_test['Review Scores Communication'].fillna(MeanRSCommunicationTrain, inplace=True)\n","  filtered_test['Review Scores Location'].fillna(MeanRSLocationTrain, inplace=True)\n","  filtered_test['Review Scores Value'].fillna(MeanRSValueTrain, inplace=True)\n","\n","  #los vacíos los consideramos como desconocidos\n","  filtered_train['Host Neighbourhood'].fillna('Unknown', inplace=True)\n","  filtered_train['Host Verifications'].fillna('Unknown', inplace=True)\n","  filtered_train['Neighbourhood'].fillna('Unknown', inplace=True)\n","  filtered_train['Zipcode'].fillna('Unknown', inplace=True)\n","  filtered_train['Amenities'].fillna('Unknown', inplace=True)\n","  filtered_train['First Review'].fillna('Unknown', inplace=True)\n","  filtered_train['Last Review'].fillna('Unknown', inplace=True)\n","  filtered_val['Host Neighbourhood'].fillna('Unknown', inplace=True)\n","  filtered_val['Host Verifications'].fillna('Unknown', inplace=True)\n","  filtered_val['Neighbourhood'].fillna('Unknown', inplace=True)\n","  filtered_val['Zipcode'].fillna('Unknown', inplace=True)\n","  filtered_val['Amenities'].fillna('Unknown', inplace=True)\n","  filtered_val['First Review'].fillna('Unknown', inplace=True)\n","  filtered_val['Last Review'].fillna('Unknown', inplace=True)\n","  filtered_test['Host Neighbourhood'].fillna('Unknown', inplace=True)\n","  filtered_test['Host Verifications'].fillna('Unknown', inplace=True)\n","  filtered_test['Neighbourhood'].fillna('Unknown', inplace=True)\n","  filtered_test['Zipcode'].fillna('Unknown', inplace=True)\n","  filtered_test['Amenities'].fillna('Unknown', inplace=True)\n","  filtered_test['First Review'].fillna('Unknown', inplace=True)\n","  filtered_test['Last Review'].fillna('Unknown', inplace=True)\n","\n","  #consideramos que donde falta un valor es porque no existe, es decir, no hay respuesta o la tasa es 0€\n","  filtered_train['Host Response Time'].fillna('No response', inplace=True)\n","  filtered_train['Host Response Rate'].fillna(0, inplace=True)\n","  filtered_train['Security Deposit'].fillna(0, inplace=True)\n","  filtered_train['Cleaning Fee'].fillna(0, inplace=True)\n","  filtered_train['Reviews per Month'].fillna(0, inplace=True)\n","  filtered_val['Host Response Time'].fillna('No response', inplace=True)\n","  filtered_val['Host Response Rate'].fillna(0, inplace=True)\n","  filtered_val['Security Deposit'].fillna(0, inplace=True)\n","  filtered_val['Cleaning Fee'].fillna(0, inplace=True)\n","  filtered_val['Reviews per Month'].fillna(0, inplace=True)\n","  filtered_test['Host Response Time'].fillna('No response', inplace=True)\n","  filtered_test['Host Response Rate'].fillna(0, inplace=True)\n","  filtered_test['Security Deposit'].fillna(0, inplace=True)\n","  filtered_test['Cleaning Fee'].fillna(0, inplace=True)\n","  filtered_test['Reviews per Month'].fillna(0, inplace=True)\n","\n","  #transformaciones contando palabras. es algo muy sencillo, queda pendiente mejorarlo con técnicas NLP en el futuro\n","  filtered_train['Amenities'] = filtered_train['Amenities'].apply(lambda x: len(str(x).split(',')))\n","  filtered_train['Host Verifications'] = filtered_train['Host Verifications'].apply(lambda x: len(str(x).split(',')))\n","  filtered_train['Features'] = filtered_train['Features'].apply(lambda x: len(str(x).split(',')))\n","  filtered_val['Amenities'] = filtered_val['Amenities'].apply(lambda x: len(str(x).split(',')))\n","  filtered_val['Host Verifications'] = filtered_val['Host Verifications'].apply(lambda x: len(str(x).split(',')))\n","  filtered_val['Features'] = filtered_val['Features'].apply(lambda x: len(str(x).split(',')))\n","  filtered_test['Amenities'] = filtered_test['Amenities'].apply(lambda x: len(str(x).split(',')))\n","  filtered_test['Host Verifications'] = filtered_test['Host Verifications'].apply(lambda x: len(str(x).split(',')))\n","  filtered_test['Features'] = filtered_test['Features'].apply(lambda x: len(str(x).split(',')))\n","\n","  #MeanEncoder\n","  categorical = ['Host Response Time', 'Host Neighbourhood', 'Neighbourhood','Neighbourhood Cleansed',\n","               'Neighbourhood Group Cleansed','Zipcode','Property Type','Room Type','Bed Type',\n","               'Calendar Updated','First Review','Last Review','Cancellation Policy']\n","  # En train creamos un dict para usarlo después en val y test\n","  mean_map = {}\n","  for c in categorical:\n","      mean = filtered_train.groupby(c)['Price'].mean()\n","      filtered_train[c] = filtered_train[c].map(mean)    \n","      mean_map[c] = mean\n","  for c in categorical:\n","    filtered_val[c] = filtered_val[c].map(mean_map[c])\n","  for c in categorical:\n","    filtered_test[c] = filtered_test[c].map(mean_map[c])\n"," #los valores vacíos de val y test los completo con la moda de train\n","  for c in categorical:\n","    filtered_val[c].fillna(filtered_train[c].mode()[0], inplace=True)\n","  for c in categorical:\n","    filtered_test[c].fillna(filtered_train[c].mode()[0], inplace=True)\n","\n","  #eliminamos la variable Price (ya está categorizada y ya se ha usado para el MeanEncoder)\n","  filtered_train.drop(['Price'],axis=1, inplace=True)\n","  filtered_val.drop(['Price'],axis=1, inplace=True)\n","  filtered_test.drop(['Price'],axis=1, inplace=True)\n","  \n","  #separamos las variables de entrada de la variable objetivo\n","  cols = filtered_train.columns.tolist()\n","  Xtrain = filtered_train[cols[0:-1]]\n","  Xval = filtered_val[cols[0:-1]]\n","  Xtest = filtered_test[cols[0:-1]]\n","\n","  #escalamos los valores de entrada\n","  cs = MinMaxScaler()\n","  Xtrain_Scaled = cs.fit_transform(Xtrain)\n","  Xval_Scaled = cs.transform(Xval)\n","  Xtest_Scaled = cs. transform(Xtest)\n","\n","  #extraemos la variable objetivo\n","  Ytrain = filtered_train[cols[-1]]\n","  Yval = filtered_val[cols[-1]]\n","  Ytest = filtered_test[cols[-1]]\n","\n","  return (Xtrain_Scaled, Xval_Scaled, Xtest_Scaled, Ytrain, Yval, Ytest)\n","      \n","  \n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3LQ2uXVK3oEm","colab_type":"text"},"source":["Usamos la función definida previamente para obtener nuestros conjuntos de datos y la variable objetivo."]},{"cell_type":"code","metadata":{"id":"qrQTDdPgC6ID","colab_type":"code","colab":{}},"source":["(Xtrain, Xval, Xtest, ytrain, yval, ytest) = preprocesado(df_train, df_val, df_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xl8okc5W4Elc","colab_type":"text"},"source":["Ahora vamos a definir los modelos con los que vamos a trabajar y que iremos comparando."]},{"cell_type":"code","metadata":{"id":"Ek6hFV5bEBVb","colab_type":"code","colab":{}},"source":["# import the necessary packages\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Activation, Dropout, Dense, Flatten, Input\n","\n","#creamos una primera red muy sencilla con una sola capa de entrada, otra oculta de 4 neuronas y otra de clasificación\n","def MiRed1(dim):\n","  model = Sequential()\n","  model.add(Dense(8, input_dim=dim, activation=\"relu\"))\n","  model.add(Dense(4, activation=\"relu\"))\n","  model.add(Dense(3, activation=\"softmax\"))\n","\n","  return model\n","\n","#creamos una red un poco más compleja con más capas ocultas\n","def MiRed2(dim):\n","  model = Sequential()\n","  model.add(Dense(64, input_dim=dim, activation=\"relu\"))\n","  model.add(Dense(32, activation=\"relu\"))\n","  model.add(Dense(16, activation=\"relu\"))\n","  model.add(Dense(8, activation=\"relu\"))\n","  model.add(Dense(4, activation=\"relu\"))\n","  model.add(Dense(3, activation=\"softmax\"))\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8lXWEi124xL3","colab_type":"text"},"source":["Empezamos usando el modelo 1:"]},{"cell_type":"code","metadata":{"id":"AbhtYGkxFcsS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593241875966,"user_tz":-120,"elapsed":323793,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}},"outputId":"e97a60f3-7230-42c3-aff7-77f97e7e6491"},"source":["from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras import backend as K\n","from keras.utils import to_categorical\n","from keras.optimizers import Adam\n","\n","#categorización one-hot\n","num_classes = 3\n","Ytrain = to_categorical(ytrain, num_classes)\n","Yval = to_categorical(yval, num_classes)\n","Ytest = to_categorical(ytest, num_classes)\n","\n","model = MiRed1(Xtrain.shape[1])\n","opt = Adam(lr=1e-3, decay=1e-3 / 200)\n","\n","#compilamos el modelo\n","model.compile(loss=\"categorical_crossentropy\", \n","              optimizer=opt,\n","\t\t\t\t\t\t\tmetrics=['accuracy'])\n","\n","# entrenamos el modelo\n","print(\"[INFO] training model...\")\n","model.fit(x=Xtrain, y=Ytrain, \n","\tvalidation_data=(Xval, Yval),\n","\tepochs=100, batch_size=8)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["[INFO] training model...\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 8412 samples, validate on 2100 samples\n","Epoch 1/100\n","8412/8412 [==============================] - 5s 575us/step - loss: 0.7049 - accuracy: 0.7184 - val_loss: 0.5904 - val_accuracy: 0.7952\n","Epoch 2/100\n","8412/8412 [==============================] - 3s 368us/step - loss: 0.5277 - accuracy: 0.8084 - val_loss: 0.5358 - val_accuracy: 0.7995\n","Epoch 3/100\n","8412/8412 [==============================] - 3s 378us/step - loss: 0.4911 - accuracy: 0.8113 - val_loss: 0.4981 - val_accuracy: 0.8029\n","Epoch 4/100\n","8412/8412 [==============================] - 3s 383us/step - loss: 0.4693 - accuracy: 0.8125 - val_loss: 0.4807 - val_accuracy: 0.8076\n","Epoch 5/100\n","8412/8412 [==============================] - 3s 381us/step - loss: 0.4534 - accuracy: 0.8181 - val_loss: 0.4780 - val_accuracy: 0.8114\n","Epoch 6/100\n","8412/8412 [==============================] - 3s 376us/step - loss: 0.4448 - accuracy: 0.8239 - val_loss: 0.4740 - val_accuracy: 0.8124\n","Epoch 7/100\n","8412/8412 [==============================] - 3s 375us/step - loss: 0.4380 - accuracy: 0.8267 - val_loss: 0.4695 - val_accuracy: 0.8157\n","Epoch 8/100\n","8412/8412 [==============================] - 3s 372us/step - loss: 0.4336 - accuracy: 0.8282 - val_loss: 0.4564 - val_accuracy: 0.8233\n","Epoch 9/100\n","8412/8412 [==============================] - 3s 374us/step - loss: 0.4309 - accuracy: 0.8291 - val_loss: 0.4548 - val_accuracy: 0.8257\n","Epoch 10/100\n","8412/8412 [==============================] - 3s 371us/step - loss: 0.4281 - accuracy: 0.8310 - val_loss: 0.4574 - val_accuracy: 0.8181\n","Epoch 11/100\n","8412/8412 [==============================] - 3s 372us/step - loss: 0.4264 - accuracy: 0.8293 - val_loss: 0.4557 - val_accuracy: 0.8219\n","Epoch 12/100\n","8412/8412 [==============================] - 3s 372us/step - loss: 0.4237 - accuracy: 0.8311 - val_loss: 0.4517 - val_accuracy: 0.8238\n","Epoch 13/100\n","8412/8412 [==============================] - 3s 371us/step - loss: 0.4216 - accuracy: 0.8338 - val_loss: 0.4454 - val_accuracy: 0.8229\n","Epoch 14/100\n","8412/8412 [==============================] - 3s 372us/step - loss: 0.4184 - accuracy: 0.8332 - val_loss: 0.4484 - val_accuracy: 0.8252\n","Epoch 15/100\n","8412/8412 [==============================] - 3s 368us/step - loss: 0.4190 - accuracy: 0.8344 - val_loss: 0.4504 - val_accuracy: 0.8238\n","Epoch 16/100\n","8412/8412 [==============================] - 3s 369us/step - loss: 0.4154 - accuracy: 0.8369 - val_loss: 0.4534 - val_accuracy: 0.8176\n","Epoch 17/100\n","8412/8412 [==============================] - 3s 374us/step - loss: 0.4178 - accuracy: 0.8330 - val_loss: 0.4611 - val_accuracy: 0.8205\n","Epoch 18/100\n","8412/8412 [==============================] - 3s 367us/step - loss: 0.4136 - accuracy: 0.8361 - val_loss: 0.4643 - val_accuracy: 0.8200\n","Epoch 19/100\n","8412/8412 [==============================] - 3s 370us/step - loss: 0.4139 - accuracy: 0.8362 - val_loss: 0.4471 - val_accuracy: 0.8224\n","Epoch 20/100\n","8412/8412 [==============================] - 3s 366us/step - loss: 0.4133 - accuracy: 0.8384 - val_loss: 0.4502 - val_accuracy: 0.8243\n","Epoch 21/100\n","8412/8412 [==============================] - 3s 368us/step - loss: 0.4121 - accuracy: 0.8369 - val_loss: 0.4461 - val_accuracy: 0.8224\n","Epoch 22/100\n","8412/8412 [==============================] - 3s 364us/step - loss: 0.4100 - accuracy: 0.8396 - val_loss: 0.4399 - val_accuracy: 0.8267\n","Epoch 23/100\n","8412/8412 [==============================] - 3s 366us/step - loss: 0.4097 - accuracy: 0.8361 - val_loss: 0.4694 - val_accuracy: 0.8190\n","Epoch 24/100\n","8412/8412 [==============================] - 3s 369us/step - loss: 0.4101 - accuracy: 0.8396 - val_loss: 0.4503 - val_accuracy: 0.8210\n","Epoch 25/100\n","8412/8412 [==============================] - 3s 372us/step - loss: 0.4088 - accuracy: 0.8382 - val_loss: 0.4546 - val_accuracy: 0.8210\n","Epoch 26/100\n","8412/8412 [==============================] - 3s 370us/step - loss: 0.4087 - accuracy: 0.8379 - val_loss: 0.4508 - val_accuracy: 0.8238\n","Epoch 27/100\n","8412/8412 [==============================] - 3s 371us/step - loss: 0.4084 - accuracy: 0.8392 - val_loss: 0.4462 - val_accuracy: 0.8233\n","Epoch 28/100\n","8412/8412 [==============================] - 3s 374us/step - loss: 0.4065 - accuracy: 0.8365 - val_loss: 0.4418 - val_accuracy: 0.8257\n","Epoch 29/100\n","8412/8412 [==============================] - 3s 379us/step - loss: 0.4077 - accuracy: 0.8403 - val_loss: 0.4723 - val_accuracy: 0.8157\n","Epoch 30/100\n","8412/8412 [==============================] - 3s 380us/step - loss: 0.4082 - accuracy: 0.8398 - val_loss: 0.4537 - val_accuracy: 0.8224\n","Epoch 31/100\n","8412/8412 [==============================] - 3s 381us/step - loss: 0.4058 - accuracy: 0.8412 - val_loss: 0.4638 - val_accuracy: 0.8129\n","Epoch 32/100\n","8412/8412 [==============================] - 3s 374us/step - loss: 0.4047 - accuracy: 0.8394 - val_loss: 0.4490 - val_accuracy: 0.8243\n","Epoch 33/100\n","8412/8412 [==============================] - 3s 368us/step - loss: 0.4046 - accuracy: 0.8415 - val_loss: 0.4657 - val_accuracy: 0.8148\n","Epoch 34/100\n","8412/8412 [==============================] - 3s 368us/step - loss: 0.4044 - accuracy: 0.8412 - val_loss: 0.4607 - val_accuracy: 0.8181\n","Epoch 35/100\n","8412/8412 [==============================] - 3s 370us/step - loss: 0.4050 - accuracy: 0.8418 - val_loss: 0.4373 - val_accuracy: 0.8262\n","Epoch 36/100\n","8412/8412 [==============================] - 3s 365us/step - loss: 0.4048 - accuracy: 0.8401 - val_loss: 0.4457 - val_accuracy: 0.8219\n","Epoch 37/100\n","8412/8412 [==============================] - 3s 373us/step - loss: 0.4051 - accuracy: 0.8417 - val_loss: 0.4401 - val_accuracy: 0.8238\n","Epoch 38/100\n","8412/8412 [==============================] - 3s 368us/step - loss: 0.4045 - accuracy: 0.8407 - val_loss: 0.4373 - val_accuracy: 0.8281\n","Epoch 39/100\n","8412/8412 [==============================] - 3s 368us/step - loss: 0.4034 - accuracy: 0.8415 - val_loss: 0.4763 - val_accuracy: 0.8086\n","Epoch 40/100\n","8412/8412 [==============================] - 3s 370us/step - loss: 0.4015 - accuracy: 0.8414 - val_loss: 0.4479 - val_accuracy: 0.8262\n","Epoch 41/100\n","8412/8412 [==============================] - 3s 371us/step - loss: 0.4029 - accuracy: 0.8400 - val_loss: 0.4444 - val_accuracy: 0.8219\n","Epoch 42/100\n","8412/8412 [==============================] - 3s 367us/step - loss: 0.4032 - accuracy: 0.8403 - val_loss: 0.4397 - val_accuracy: 0.8229\n","Epoch 43/100\n","8412/8412 [==============================] - 3s 368us/step - loss: 0.4027 - accuracy: 0.8405 - val_loss: 0.4401 - val_accuracy: 0.8290\n","Epoch 44/100\n","8412/8412 [==============================] - 3s 372us/step - loss: 0.4018 - accuracy: 0.8427 - val_loss: 0.4430 - val_accuracy: 0.8286\n","Epoch 45/100\n","8412/8412 [==============================] - 3s 369us/step - loss: 0.4013 - accuracy: 0.8408 - val_loss: 0.4519 - val_accuracy: 0.8186\n","Epoch 46/100\n","8412/8412 [==============================] - 3s 371us/step - loss: 0.4016 - accuracy: 0.8425 - val_loss: 0.4411 - val_accuracy: 0.8271\n","Epoch 47/100\n","8412/8412 [==============================] - 3s 372us/step - loss: 0.4006 - accuracy: 0.8411 - val_loss: 0.4534 - val_accuracy: 0.8257\n","Epoch 48/100\n","8412/8412 [==============================] - 3s 371us/step - loss: 0.4024 - accuracy: 0.8407 - val_loss: 0.4369 - val_accuracy: 0.8276\n","Epoch 49/100\n","8412/8412 [==============================] - 3s 369us/step - loss: 0.4015 - accuracy: 0.8428 - val_loss: 0.4419 - val_accuracy: 0.8200\n","Epoch 50/100\n","8412/8412 [==============================] - 3s 365us/step - loss: 0.4000 - accuracy: 0.8379 - val_loss: 0.4362 - val_accuracy: 0.8252\n","Epoch 51/100\n","8412/8412 [==============================] - 3s 386us/step - loss: 0.3998 - accuracy: 0.8430 - val_loss: 0.4355 - val_accuracy: 0.8238\n","Epoch 52/100\n","8412/8412 [==============================] - 3s 385us/step - loss: 0.4025 - accuracy: 0.8409 - val_loss: 0.4537 - val_accuracy: 0.8214\n","Epoch 53/100\n","8412/8412 [==============================] - 3s 367us/step - loss: 0.4010 - accuracy: 0.8412 - val_loss: 0.4397 - val_accuracy: 0.8243\n","Epoch 54/100\n","8412/8412 [==============================] - 3s 370us/step - loss: 0.3995 - accuracy: 0.8433 - val_loss: 0.4367 - val_accuracy: 0.8286\n","Epoch 55/100\n","8412/8412 [==============================] - 3s 377us/step - loss: 0.3978 - accuracy: 0.8425 - val_loss: 0.4366 - val_accuracy: 0.8281\n","Epoch 56/100\n","8412/8412 [==============================] - 3s 381us/step - loss: 0.3986 - accuracy: 0.8450 - val_loss: 0.4387 - val_accuracy: 0.8281\n","Epoch 57/100\n","8412/8412 [==============================] - 3s 380us/step - loss: 0.4007 - accuracy: 0.8431 - val_loss: 0.4375 - val_accuracy: 0.8252\n","Epoch 58/100\n","8412/8412 [==============================] - 3s 366us/step - loss: 0.3989 - accuracy: 0.8409 - val_loss: 0.4398 - val_accuracy: 0.8252\n","Epoch 59/100\n","8412/8412 [==============================] - 3s 368us/step - loss: 0.3993 - accuracy: 0.8422 - val_loss: 0.4345 - val_accuracy: 0.8257\n","Epoch 60/100\n","8412/8412 [==============================] - 3s 368us/step - loss: 0.3985 - accuracy: 0.8401 - val_loss: 0.4387 - val_accuracy: 0.8257\n","Epoch 61/100\n","8412/8412 [==============================] - 3s 373us/step - loss: 0.3986 - accuracy: 0.8421 - val_loss: 0.4419 - val_accuracy: 0.8243\n","Epoch 62/100\n","8412/8412 [==============================] - 3s 364us/step - loss: 0.3980 - accuracy: 0.8428 - val_loss: 0.4373 - val_accuracy: 0.8248\n","Epoch 63/100\n","8412/8412 [==============================] - 3s 372us/step - loss: 0.3977 - accuracy: 0.8431 - val_loss: 0.4549 - val_accuracy: 0.8190\n","Epoch 64/100\n","8412/8412 [==============================] - 3s 370us/step - loss: 0.3987 - accuracy: 0.8424 - val_loss: 0.4538 - val_accuracy: 0.8171\n","Epoch 65/100\n","8412/8412 [==============================] - 3s 369us/step - loss: 0.3992 - accuracy: 0.8432 - val_loss: 0.4365 - val_accuracy: 0.8276\n","Epoch 66/100\n","8412/8412 [==============================] - 3s 371us/step - loss: 0.3974 - accuracy: 0.8445 - val_loss: 0.4450 - val_accuracy: 0.8243\n","Epoch 67/100\n","8412/8412 [==============================] - 3s 371us/step - loss: 0.3986 - accuracy: 0.8414 - val_loss: 0.4374 - val_accuracy: 0.8276\n","Epoch 68/100\n","8412/8412 [==============================] - 3s 362us/step - loss: 0.3969 - accuracy: 0.8427 - val_loss: 0.4531 - val_accuracy: 0.8181\n","Epoch 69/100\n","8412/8412 [==============================] - 3s 371us/step - loss: 0.3970 - accuracy: 0.8456 - val_loss: 0.4450 - val_accuracy: 0.8210\n","Epoch 70/100\n","8412/8412 [==============================] - 3s 383us/step - loss: 0.3969 - accuracy: 0.8450 - val_loss: 0.4413 - val_accuracy: 0.8243\n","Epoch 71/100\n","8412/8412 [==============================] - 3s 401us/step - loss: 0.3964 - accuracy: 0.8445 - val_loss: 0.4357 - val_accuracy: 0.8262\n","Epoch 72/100\n","8412/8412 [==============================] - 3s 395us/step - loss: 0.3978 - accuracy: 0.8444 - val_loss: 0.4365 - val_accuracy: 0.8262\n","Epoch 73/100\n","8412/8412 [==============================] - 3s 396us/step - loss: 0.3959 - accuracy: 0.8424 - val_loss: 0.4533 - val_accuracy: 0.8176\n","Epoch 74/100\n","8412/8412 [==============================] - 3s 370us/step - loss: 0.3972 - accuracy: 0.8413 - val_loss: 0.4401 - val_accuracy: 0.8238\n","Epoch 75/100\n","8412/8412 [==============================] - 3s 366us/step - loss: 0.3961 - accuracy: 0.8451 - val_loss: 0.4539 - val_accuracy: 0.8167\n","Epoch 76/100\n","8412/8412 [==============================] - 3s 367us/step - loss: 0.3971 - accuracy: 0.8427 - val_loss: 0.4360 - val_accuracy: 0.8257\n","Epoch 77/100\n","8412/8412 [==============================] - 3s 369us/step - loss: 0.3951 - accuracy: 0.8455 - val_loss: 0.4376 - val_accuracy: 0.8333\n","Epoch 78/100\n","8412/8412 [==============================] - 3s 368us/step - loss: 0.3957 - accuracy: 0.8444 - val_loss: 0.4404 - val_accuracy: 0.8262\n","Epoch 79/100\n","8412/8412 [==============================] - 3s 369us/step - loss: 0.3944 - accuracy: 0.8468 - val_loss: 0.4428 - val_accuracy: 0.8229\n","Epoch 80/100\n","8412/8412 [==============================] - 3s 374us/step - loss: 0.3952 - accuracy: 0.8459 - val_loss: 0.4378 - val_accuracy: 0.8252\n","Epoch 81/100\n","8412/8412 [==============================] - 3s 378us/step - loss: 0.3947 - accuracy: 0.8457 - val_loss: 0.4487 - val_accuracy: 0.8210\n","Epoch 82/100\n","8412/8412 [==============================] - 3s 381us/step - loss: 0.3955 - accuracy: 0.8450 - val_loss: 0.4331 - val_accuracy: 0.8262\n","Epoch 83/100\n","8412/8412 [==============================] - 3s 373us/step - loss: 0.3957 - accuracy: 0.8434 - val_loss: 0.4386 - val_accuracy: 0.8243\n","Epoch 84/100\n","8412/8412 [==============================] - 3s 370us/step - loss: 0.3957 - accuracy: 0.8464 - val_loss: 0.4405 - val_accuracy: 0.8257\n","Epoch 85/100\n","8412/8412 [==============================] - 3s 367us/step - loss: 0.3951 - accuracy: 0.8449 - val_loss: 0.4659 - val_accuracy: 0.8190\n","Epoch 86/100\n","8412/8412 [==============================] - 3s 371us/step - loss: 0.3957 - accuracy: 0.8456 - val_loss: 0.4368 - val_accuracy: 0.8286\n","Epoch 87/100\n","8412/8412 [==============================] - 3s 373us/step - loss: 0.3945 - accuracy: 0.8451 - val_loss: 0.4340 - val_accuracy: 0.8262\n","Epoch 88/100\n","8412/8412 [==============================] - 3s 368us/step - loss: 0.3945 - accuracy: 0.8466 - val_loss: 0.4381 - val_accuracy: 0.8271\n","Epoch 89/100\n","8412/8412 [==============================] - 3s 374us/step - loss: 0.3944 - accuracy: 0.8446 - val_loss: 0.4358 - val_accuracy: 0.8267\n","Epoch 90/100\n","8412/8412 [==============================] - 3s 377us/step - loss: 0.3950 - accuracy: 0.8438 - val_loss: 0.4384 - val_accuracy: 0.8257\n","Epoch 91/100\n","8412/8412 [==============================] - 3s 371us/step - loss: 0.3945 - accuracy: 0.8420 - val_loss: 0.4546 - val_accuracy: 0.8190\n","Epoch 92/100\n","8412/8412 [==============================] - 3s 368us/step - loss: 0.3937 - accuracy: 0.8468 - val_loss: 0.4402 - val_accuracy: 0.8248\n","Epoch 93/100\n","8412/8412 [==============================] - 3s 365us/step - loss: 0.3951 - accuracy: 0.8461 - val_loss: 0.4328 - val_accuracy: 0.8305\n","Epoch 94/100\n","8412/8412 [==============================] - 3s 368us/step - loss: 0.3930 - accuracy: 0.8439 - val_loss: 0.4416 - val_accuracy: 0.8238\n","Epoch 95/100\n","8412/8412 [==============================] - 3s 371us/step - loss: 0.3939 - accuracy: 0.8449 - val_loss: 0.4520 - val_accuracy: 0.8181\n","Epoch 96/100\n","8412/8412 [==============================] - 3s 368us/step - loss: 0.3923 - accuracy: 0.8447 - val_loss: 0.4380 - val_accuracy: 0.8229\n","Epoch 97/100\n","8412/8412 [==============================] - 3s 369us/step - loss: 0.3943 - accuracy: 0.8471 - val_loss: 0.4399 - val_accuracy: 0.8224\n","Epoch 98/100\n","8412/8412 [==============================] - 3s 368us/step - loss: 0.3927 - accuracy: 0.8468 - val_loss: 0.4642 - val_accuracy: 0.8210\n","Epoch 99/100\n","8412/8412 [==============================] - 3s 371us/step - loss: 0.3925 - accuracy: 0.8489 - val_loss: 0.4386 - val_accuracy: 0.8267\n","Epoch 100/100\n","8412/8412 [==============================] - 3s 369us/step - loss: 0.3927 - accuracy: 0.8462 - val_loss: 0.4344 - val_accuracy: 0.8324\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f7bd7f134a8>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"9AiQBGCz43ud","colab_type":"text"},"source":["Ahora usamos el modelo 2:"]},{"cell_type":"code","metadata":{"id":"zXg4YybaFiNK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593098805323,"user_tz":-120,"elapsed":431108,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}},"outputId":"59739557-7d35-4ae0-9313-848af5fa2ce7"},"source":["model2 = MiRed2(Xtrain.shape[1])\n","opt = Adam(lr=1e-3, decay=1e-3 / 200)\n","\n","#compilamos el modelo\n","model2.compile(loss=\"categorical_crossentropy\",\n","                optimizer=opt,\n","\t\t\t\t\t\t\t\tmetrics=['accuracy'])\n","\n","# entrenamos el modelo\n","print(\"[INFO] training model...\")\n","model2.fit(x=Xtrain, y=Ytrain, \n","\tvalidation_data=(Xval, Yval),\n","\tepochs=100, batch_size=8)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[INFO] training model...\n","Train on 8412 samples, validate on 2100 samples\n","Epoch 1/100\n","8412/8412 [==============================] - 5s 541us/step - loss: 0.7000 - accuracy: 0.7688 - val_loss: 0.5665 - val_accuracy: 0.8067\n","Epoch 2/100\n","8412/8412 [==============================] - 4s 514us/step - loss: 0.5172 - accuracy: 0.8142 - val_loss: 0.4999 - val_accuracy: 0.8148\n","Epoch 3/100\n","8412/8412 [==============================] - 4s 524us/step - loss: 0.4702 - accuracy: 0.8201 - val_loss: 0.4788 - val_accuracy: 0.8048\n","Epoch 4/100\n","8412/8412 [==============================] - 4s 488us/step - loss: 0.4545 - accuracy: 0.8258 - val_loss: 0.4754 - val_accuracy: 0.8190\n","Epoch 5/100\n","8412/8412 [==============================] - 4s 523us/step - loss: 0.4444 - accuracy: 0.8267 - val_loss: 0.4740 - val_accuracy: 0.8186\n","Epoch 6/100\n","8412/8412 [==============================] - 4s 496us/step - loss: 0.4365 - accuracy: 0.8338 - val_loss: 0.4601 - val_accuracy: 0.8195\n","Epoch 7/100\n","8412/8412 [==============================] - 4s 488us/step - loss: 0.4342 - accuracy: 0.8299 - val_loss: 0.4640 - val_accuracy: 0.8219\n","Epoch 8/100\n","8412/8412 [==============================] - 4s 523us/step - loss: 0.4256 - accuracy: 0.8332 - val_loss: 0.4748 - val_accuracy: 0.8152\n","Epoch 9/100\n","8412/8412 [==============================] - 5s 552us/step - loss: 0.4236 - accuracy: 0.8352 - val_loss: 0.4566 - val_accuracy: 0.8229\n","Epoch 10/100\n","8412/8412 [==============================] - 5s 570us/step - loss: 0.4195 - accuracy: 0.8359 - val_loss: 0.4576 - val_accuracy: 0.8210\n","Epoch 11/100\n","8412/8412 [==============================] - 5s 582us/step - loss: 0.4123 - accuracy: 0.8401 - val_loss: 0.4433 - val_accuracy: 0.8262\n","Epoch 12/100\n","8412/8412 [==============================] - 4s 496us/step - loss: 0.4107 - accuracy: 0.8383 - val_loss: 0.4520 - val_accuracy: 0.8276\n","Epoch 13/100\n","8412/8412 [==============================] - 4s 498us/step - loss: 0.4095 - accuracy: 0.8406 - val_loss: 0.4552 - val_accuracy: 0.8214\n","Epoch 14/100\n","8412/8412 [==============================] - 4s 480us/step - loss: 0.4052 - accuracy: 0.8424 - val_loss: 0.4715 - val_accuracy: 0.8229\n","Epoch 15/100\n","8412/8412 [==============================] - 4s 514us/step - loss: 0.4047 - accuracy: 0.8424 - val_loss: 0.4421 - val_accuracy: 0.8276\n","Epoch 16/100\n","8412/8412 [==============================] - 4s 474us/step - loss: 0.4002 - accuracy: 0.8431 - val_loss: 0.4318 - val_accuracy: 0.8295\n","Epoch 17/100\n","8412/8412 [==============================] - 4s 499us/step - loss: 0.3995 - accuracy: 0.8414 - val_loss: 0.4482 - val_accuracy: 0.8190\n","Epoch 18/100\n","8412/8412 [==============================] - 4s 499us/step - loss: 0.3976 - accuracy: 0.8418 - val_loss: 0.4640 - val_accuracy: 0.8062\n","Epoch 19/100\n","8412/8412 [==============================] - 5s 535us/step - loss: 0.3956 - accuracy: 0.8470 - val_loss: 0.4515 - val_accuracy: 0.8248\n","Epoch 20/100\n","8412/8412 [==============================] - 4s 512us/step - loss: 0.3902 - accuracy: 0.8437 - val_loss: 0.4190 - val_accuracy: 0.8329\n","Epoch 21/100\n","8412/8412 [==============================] - 4s 522us/step - loss: 0.3907 - accuracy: 0.8478 - val_loss: 0.4401 - val_accuracy: 0.8233\n","Epoch 22/100\n","8412/8412 [==============================] - 4s 500us/step - loss: 0.3863 - accuracy: 0.8499 - val_loss: 0.4303 - val_accuracy: 0.8276\n","Epoch 23/100\n","8412/8412 [==============================] - 4s 478us/step - loss: 0.3857 - accuracy: 0.8499 - val_loss: 0.4334 - val_accuracy: 0.8305\n","Epoch 24/100\n","8412/8412 [==============================] - 4s 505us/step - loss: 0.3785 - accuracy: 0.8539 - val_loss: 0.4214 - val_accuracy: 0.8338\n","Epoch 25/100\n","8412/8412 [==============================] - 4s 479us/step - loss: 0.3782 - accuracy: 0.8496 - val_loss: 0.4231 - val_accuracy: 0.8314\n","Epoch 26/100\n","8412/8412 [==============================] - 4s 501us/step - loss: 0.3767 - accuracy: 0.8499 - val_loss: 0.4328 - val_accuracy: 0.8290\n","Epoch 27/100\n","8412/8412 [==============================] - 4s 494us/step - loss: 0.3772 - accuracy: 0.8516 - val_loss: 0.4241 - val_accuracy: 0.8333\n","Epoch 28/100\n","8412/8412 [==============================] - 4s 486us/step - loss: 0.3753 - accuracy: 0.8497 - val_loss: 0.4308 - val_accuracy: 0.8276\n","Epoch 29/100\n","8412/8412 [==============================] - 4s 524us/step - loss: 0.3722 - accuracy: 0.8541 - val_loss: 0.4241 - val_accuracy: 0.8405\n","Epoch 30/100\n","8412/8412 [==============================] - 4s 527us/step - loss: 0.3696 - accuracy: 0.8579 - val_loss: 0.4190 - val_accuracy: 0.8357\n","Epoch 31/100\n","8412/8412 [==============================] - 5s 537us/step - loss: 0.3694 - accuracy: 0.8526 - val_loss: 0.4227 - val_accuracy: 0.8314\n","Epoch 32/100\n","8412/8412 [==============================] - 4s 519us/step - loss: 0.3657 - accuracy: 0.8550 - val_loss: 0.4284 - val_accuracy: 0.8257\n","Epoch 33/100\n","8412/8412 [==============================] - 4s 512us/step - loss: 0.3638 - accuracy: 0.8541 - val_loss: 0.4216 - val_accuracy: 0.8338\n","Epoch 34/100\n","8412/8412 [==============================] - 4s 494us/step - loss: 0.3615 - accuracy: 0.8576 - val_loss: 0.4230 - val_accuracy: 0.8314\n","Epoch 35/100\n","8412/8412 [==============================] - 4s 472us/step - loss: 0.3619 - accuracy: 0.8560 - val_loss: 0.4378 - val_accuracy: 0.8295\n","Epoch 36/100\n","8412/8412 [==============================] - 4s 496us/step - loss: 0.3583 - accuracy: 0.8578 - val_loss: 0.4481 - val_accuracy: 0.8210\n","Epoch 37/100\n","8412/8412 [==============================] - 4s 491us/step - loss: 0.3598 - accuracy: 0.8534 - val_loss: 0.4196 - val_accuracy: 0.8295\n","Epoch 38/100\n","8412/8412 [==============================] - 4s 487us/step - loss: 0.3531 - accuracy: 0.8591 - val_loss: 0.4242 - val_accuracy: 0.8319\n","Epoch 39/100\n","8412/8412 [==============================] - 5s 555us/step - loss: 0.3551 - accuracy: 0.8591 - val_loss: 0.4166 - val_accuracy: 0.8348\n","Epoch 40/100\n","8412/8412 [==============================] - 4s 531us/step - loss: 0.3512 - accuracy: 0.8590 - val_loss: 0.4236 - val_accuracy: 0.8357\n","Epoch 41/100\n","8412/8412 [==============================] - 4s 502us/step - loss: 0.3497 - accuracy: 0.8598 - val_loss: 0.4230 - val_accuracy: 0.8476\n","Epoch 42/100\n","8412/8412 [==============================] - 4s 470us/step - loss: 0.3452 - accuracy: 0.8629 - val_loss: 0.4487 - val_accuracy: 0.8290\n","Epoch 43/100\n","8412/8412 [==============================] - 4s 501us/step - loss: 0.3469 - accuracy: 0.8613 - val_loss: 0.4355 - val_accuracy: 0.8362\n","Epoch 44/100\n","8412/8412 [==============================] - 4s 494us/step - loss: 0.3455 - accuracy: 0.8620 - val_loss: 0.4210 - val_accuracy: 0.8310\n","Epoch 45/100\n","8412/8412 [==============================] - 4s 511us/step - loss: 0.3420 - accuracy: 0.8610 - val_loss: 0.4484 - val_accuracy: 0.8286\n","Epoch 46/100\n","8412/8412 [==============================] - 4s 528us/step - loss: 0.3445 - accuracy: 0.8603 - val_loss: 0.4393 - val_accuracy: 0.8333\n","Epoch 47/100\n","8412/8412 [==============================] - 4s 493us/step - loss: 0.3401 - accuracy: 0.8613 - val_loss: 0.4388 - val_accuracy: 0.8300\n","Epoch 48/100\n","8412/8412 [==============================] - 4s 521us/step - loss: 0.3358 - accuracy: 0.8654 - val_loss: 0.4734 - val_accuracy: 0.8124\n","Epoch 49/100\n","8412/8412 [==============================] - 4s 513us/step - loss: 0.3351 - accuracy: 0.8654 - val_loss: 0.4290 - val_accuracy: 0.8300\n","Epoch 50/100\n","8412/8412 [==============================] - 4s 525us/step - loss: 0.3343 - accuracy: 0.8653 - val_loss: 0.4494 - val_accuracy: 0.8257\n","Epoch 51/100\n","8412/8412 [==============================] - 4s 524us/step - loss: 0.3279 - accuracy: 0.8640 - val_loss: 0.4440 - val_accuracy: 0.8319\n","Epoch 52/100\n","8412/8412 [==============================] - 5s 542us/step - loss: 0.3289 - accuracy: 0.8657 - val_loss: 0.4210 - val_accuracy: 0.8324\n","Epoch 53/100\n","8412/8412 [==============================] - 4s 487us/step - loss: 0.3283 - accuracy: 0.8669 - val_loss: 0.4517 - val_accuracy: 0.8329\n","Epoch 54/100\n","8412/8412 [==============================] - 4s 497us/step - loss: 0.3257 - accuracy: 0.8673 - val_loss: 0.4480 - val_accuracy: 0.8310\n","Epoch 55/100\n","8412/8412 [==============================] - 4s 509us/step - loss: 0.3235 - accuracy: 0.8665 - val_loss: 0.4465 - val_accuracy: 0.8352\n","Epoch 56/100\n","8412/8412 [==============================] - 4s 490us/step - loss: 0.3220 - accuracy: 0.8726 - val_loss: 0.4411 - val_accuracy: 0.8338\n","Epoch 57/100\n","8412/8412 [==============================] - 4s 525us/step - loss: 0.3217 - accuracy: 0.8666 - val_loss: 0.4740 - val_accuracy: 0.8300\n","Epoch 58/100\n","8412/8412 [==============================] - 4s 517us/step - loss: 0.3179 - accuracy: 0.8671 - val_loss: 0.4374 - val_accuracy: 0.8352\n","Epoch 59/100\n","8412/8412 [==============================] - 4s 501us/step - loss: 0.3184 - accuracy: 0.8692 - val_loss: 0.4638 - val_accuracy: 0.8238\n","Epoch 60/100\n","8412/8412 [==============================] - 4s 505us/step - loss: 0.3176 - accuracy: 0.8727 - val_loss: 0.4488 - val_accuracy: 0.8333\n","Epoch 61/100\n","8412/8412 [==============================] - 4s 514us/step - loss: 0.3147 - accuracy: 0.8720 - val_loss: 0.4435 - val_accuracy: 0.8229\n","Epoch 62/100\n","8412/8412 [==============================] - 4s 523us/step - loss: 0.3097 - accuracy: 0.8721 - val_loss: 0.4457 - val_accuracy: 0.8314\n","Epoch 63/100\n","8412/8412 [==============================] - 4s 483us/step - loss: 0.3114 - accuracy: 0.8740 - val_loss: 0.4422 - val_accuracy: 0.8276\n","Epoch 64/100\n","8412/8412 [==============================] - 4s 514us/step - loss: 0.3090 - accuracy: 0.8748 - val_loss: 0.4679 - val_accuracy: 0.8219\n","Epoch 65/100\n","8412/8412 [==============================] - 4s 482us/step - loss: 0.3061 - accuracy: 0.8767 - val_loss: 0.4443 - val_accuracy: 0.8281\n","Epoch 66/100\n","8412/8412 [==============================] - 4s 497us/step - loss: 0.3082 - accuracy: 0.8734 - val_loss: 0.4447 - val_accuracy: 0.8367\n","Epoch 67/100\n","8412/8412 [==============================] - 4s 490us/step - loss: 0.3039 - accuracy: 0.8782 - val_loss: 0.4462 - val_accuracy: 0.8310\n","Epoch 68/100\n","8412/8412 [==============================] - 4s 493us/step - loss: 0.2987 - accuracy: 0.8789 - val_loss: 0.4697 - val_accuracy: 0.8276\n","Epoch 69/100\n","8412/8412 [==============================] - 4s 481us/step - loss: 0.2994 - accuracy: 0.8768 - val_loss: 0.4744 - val_accuracy: 0.8229\n","Epoch 70/100\n","8412/8412 [==============================] - 4s 499us/step - loss: 0.2987 - accuracy: 0.8821 - val_loss: 0.4591 - val_accuracy: 0.8271\n","Epoch 71/100\n","8412/8412 [==============================] - 4s 496us/step - loss: 0.2949 - accuracy: 0.8796 - val_loss: 0.4493 - val_accuracy: 0.8338\n","Epoch 72/100\n","8412/8412 [==============================] - 5s 545us/step - loss: 0.2941 - accuracy: 0.8802 - val_loss: 0.4517 - val_accuracy: 0.8329\n","Epoch 73/100\n","8412/8412 [==============================] - 4s 497us/step - loss: 0.2937 - accuracy: 0.8809 - val_loss: 0.4663 - val_accuracy: 0.8276\n","Epoch 74/100\n","8412/8412 [==============================] - 4s 482us/step - loss: 0.2890 - accuracy: 0.8828 - val_loss: 0.4866 - val_accuracy: 0.8281\n","Epoch 75/100\n","8412/8412 [==============================] - 4s 480us/step - loss: 0.2904 - accuracy: 0.8834 - val_loss: 0.4652 - val_accuracy: 0.8300\n","Epoch 76/100\n","8412/8412 [==============================] - 4s 495us/step - loss: 0.2869 - accuracy: 0.8829 - val_loss: 0.4606 - val_accuracy: 0.8357\n","Epoch 77/100\n","8412/8412 [==============================] - 4s 493us/step - loss: 0.2842 - accuracy: 0.8841 - val_loss: 0.4762 - val_accuracy: 0.8324\n","Epoch 78/100\n","8412/8412 [==============================] - 4s 492us/step - loss: 0.2823 - accuracy: 0.8852 - val_loss: 0.4971 - val_accuracy: 0.8262\n","Epoch 79/100\n","8412/8412 [==============================] - 4s 475us/step - loss: 0.2799 - accuracy: 0.8886 - val_loss: 0.4798 - val_accuracy: 0.8210\n","Epoch 80/100\n","8412/8412 [==============================] - 4s 532us/step - loss: 0.2809 - accuracy: 0.8861 - val_loss: 0.5163 - val_accuracy: 0.8186\n","Epoch 81/100\n","8412/8412 [==============================] - 5s 550us/step - loss: 0.2786 - accuracy: 0.8878 - val_loss: 0.4979 - val_accuracy: 0.8238\n","Epoch 82/100\n","8412/8412 [==============================] - 4s 523us/step - loss: 0.2756 - accuracy: 0.8871 - val_loss: 0.4836 - val_accuracy: 0.8343\n","Epoch 83/100\n","8412/8412 [==============================] - 5s 585us/step - loss: 0.2726 - accuracy: 0.8864 - val_loss: 0.4840 - val_accuracy: 0.8276\n","Epoch 84/100\n","8412/8412 [==============================] - 5s 569us/step - loss: 0.2711 - accuracy: 0.8904 - val_loss: 0.4943 - val_accuracy: 0.8310\n","Epoch 85/100\n","8412/8412 [==============================] - 4s 491us/step - loss: 0.2712 - accuracy: 0.8897 - val_loss: 0.4990 - val_accuracy: 0.8329\n","Epoch 86/100\n","8412/8412 [==============================] - 4s 497us/step - loss: 0.2701 - accuracy: 0.8906 - val_loss: 0.4940 - val_accuracy: 0.8248\n","Epoch 87/100\n","8412/8412 [==============================] - 5s 540us/step - loss: 0.2700 - accuracy: 0.8931 - val_loss: 0.4938 - val_accuracy: 0.8271\n","Epoch 88/100\n","8412/8412 [==============================] - 4s 493us/step - loss: 0.2676 - accuracy: 0.8928 - val_loss: 0.4693 - val_accuracy: 0.8352\n","Epoch 89/100\n","8412/8412 [==============================] - 4s 505us/step - loss: 0.2693 - accuracy: 0.8913 - val_loss: 0.5122 - val_accuracy: 0.8267\n","Epoch 90/100\n","8412/8412 [==============================] - 4s 516us/step - loss: 0.2667 - accuracy: 0.8912 - val_loss: 0.4866 - val_accuracy: 0.8271\n","Epoch 91/100\n","8412/8412 [==============================] - 4s 472us/step - loss: 0.2578 - accuracy: 0.8986 - val_loss: 0.5296 - val_accuracy: 0.8329\n","Epoch 92/100\n","8412/8412 [==============================] - 4s 520us/step - loss: 0.2607 - accuracy: 0.8937 - val_loss: 0.5077 - val_accuracy: 0.8338\n","Epoch 93/100\n","8412/8412 [==============================] - 4s 515us/step - loss: 0.2616 - accuracy: 0.8956 - val_loss: 0.5199 - val_accuracy: 0.8324\n","Epoch 94/100\n","8412/8412 [==============================] - 5s 549us/step - loss: 0.2581 - accuracy: 0.8987 - val_loss: 0.5098 - val_accuracy: 0.8290\n","Epoch 95/100\n","8412/8412 [==============================] - 5s 541us/step - loss: 0.2560 - accuracy: 0.9003 - val_loss: 0.5480 - val_accuracy: 0.8329\n","Epoch 96/100\n","8412/8412 [==============================] - 4s 516us/step - loss: 0.2542 - accuracy: 0.8959 - val_loss: 0.5514 - val_accuracy: 0.8229\n","Epoch 97/100\n","8412/8412 [==============================] - 4s 487us/step - loss: 0.2495 - accuracy: 0.9003 - val_loss: 0.5263 - val_accuracy: 0.8319\n","Epoch 98/100\n","8412/8412 [==============================] - 4s 495us/step - loss: 0.2514 - accuracy: 0.9017 - val_loss: 0.5342 - val_accuracy: 0.8281\n","Epoch 99/100\n","8412/8412 [==============================] - 4s 482us/step - loss: 0.2478 - accuracy: 0.8991 - val_loss: 0.5354 - val_accuracy: 0.8233\n","Epoch 100/100\n","8412/8412 [==============================] - 4s 493us/step - loss: 0.2479 - accuracy: 0.9035 - val_loss: 0.5323 - val_accuracy: 0.8319\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7fcb5cddedd8>"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"d4zPFVuMDBT4","colab_type":"text"},"source":["Como podemos ver en los resultados de las ejecuciones anteriores tenemos dos modelos:\n","\n","- Modelo 1: Se trata de una red sencilla con una sola capa de entrada de 8 neuronas, otra oculta de 4 y una de clasificación de salida con 3 neuronas (nuestras 3 posibles salidas).\n","- Modelo 2: Es una red algo más compleja con más capas ocultas. Empezamos con una de 64 neuronas y vamos bajando en potencias de 2 hasta llegar a 4. La capa de clasificación de salida es igual que el caso anterior.\n","\n","Ambos modelos los comparamos en igualdad de condiciones, es decir, con el mismo learning rate, batch_size, igual número de épocas... y vemos que el modelo1 tiene mejores prestaciones:\n","- Accuracy: El modelo 1 tiene un 84% en train y un 83% en val. Mientras que el modelo 2 tiene un 90% en train y un 83% en val. Eso nos indica overfitting en el modelo 2 (se aprende muy bien el conjunto de train y luego no es capaz de generalizarlo tan bien en el modelo de validación) y puede venir dado por la complejidad de esta segunda red.\n","- Tiempo de ejecución: En el modelo 1 cada época tarda 3 segundos, mientras que en el segundo modelo tarda 4 ó 5. Es decir, es más rápido el primero.\n","\n","Por tanto, nos quedamos con el modelo 1."]},{"cell_type":"code","metadata":{"id":"-HAqv72EFdQt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593099298817,"user_tz":-120,"elapsed":1671,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}},"outputId":"39e9423b-22bd-49e2-96e9-96174794c369"},"source":["Xtrain.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8412, 47)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"oF1CtgsdFXxn","colab_type":"text"},"source":["Quiero comentar un caso curioso que me ha pasado entrenando estos modelos. En una primera instancia el conjunto de datos de entrada tenía 48 columnas (finalmente se ha quedado en 47). Los resultados obtenidos eran mucho peores y un tanto desconcertantes. \n","\n","El modelo parecía que a partir de la segunda época ya había convergido y se quedaba con unos valores de accuracy de 50% en train y 47% en val. \n","Realmente era como si el modelo no aprendiera, así que después de verificar que las etiquetas estaban bien comencé a entrenar el modelo solo con unas cuantas variables de entrada y los resultados fueron mejorando. El accuracy empezó a subir según iba incrementando el número de variables de entrada. Hay que tener en cuenta que para este proceso no se tenía en cuenta qué varibales de entrada se usaban, pero sí se observaba que el comportamiento de los modelos ya era más coherente. \n","\n","Llegué a la conclusión que la variable que estropeaba el funcionamiento era la última ya que con 47 variables de entrada obtenemos los resultados que hemos comentado antes superiores al 80% y con 48 bajábamos al 50%.\n","Esa variable en cuestión es una que yo creaba manualmente (viene heredado del módulo de ML) donde multiplicaba el número de baños por el número de habitaciones."]},{"cell_type":"markdown","metadata":{"id":"_5yEPZFEbdN8","colab_type":"text"},"source":["Para terminar evaluamos el modelo elegido con el conjunto de test:"]},{"cell_type":"code","metadata":{"id":"HvLWGedYbAcZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1593241877005,"user_tz":-120,"elapsed":1024,"user":{"displayName":"Marcos Gutiérrez","photoUrl":"","userId":"15097821019630428284"}},"outputId":"28c3bb21-b956-4636-e785-71f934482727"},"source":["# Evaluamos el modelo\n","scores = model.evaluate(Xtest, Ytest)\n","\n","print('Test Loss: %.3f' % scores[0])\n","print('Test Accuracy: %.3f' % scores[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2642/2642 [==============================] - 0s 45us/step\n","Test Loss: 0.393\n","Test Accuracy: 0.846\n"],"name":"stdout"}]}]}