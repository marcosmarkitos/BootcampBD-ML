{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1 Introducción al Deep Learning.ipynb","provenance":[],"collapsed_sections":["OFDhMkz78NoB","oLJb8m8c8TSH","i82s0YnP8XPH"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"jJQZDOSRlvjY","colab_type":"text"},"source":["# 1. Deep Learning\n","\n","Bienvenidos al módulo de Deep Learning. En esta sesión vamos a ver una breve introducción con las diferencias entre Inteligencia Artificial, Machine Learning y Deep Learning. También hablaremos un poco de cuanto tiempo lleva este mundillo en marcha, e introduciremos el gradient descent, el pilar fundamental de las redes neuronales.\n","\n","En la segunda parte empezaremos a trabajar con TensorFlow, y al terminar, habréis implementado vuestra **primera red neuronal**!\n","\n","Aquí tenéis el temario que cubriremos hoy:\n","\n","**Introducción**\n","* Del Machine Learning al Deep Learning\n","* Contexto histórico\n","* Herramienta: Google Colab\n","* Descenso del gradiente\n","\n","**Introducción a TensorFlow**\n","* Grafos, variables, operaciones\n","* Resolución de problemas con TensorFlow\n","* Mi primera red neuronal en TensorFlow\n","\n","¿Qué os parece? ¿Tenéis ganas?\n","\n","**¡Vamos allá!**"]},{"cell_type":"markdown","metadata":{"id":"-0dQrH-TDD1z","colab_type":"text"},"source":["## 1.1. Introducción. Del Machine Learning al Deep Learning.\n","\n","¿Qué es el Deep Learning? ¿En qué se diferencia del Machine Learning? ¿Y de la Inteligencia Artificial?\n","\n","<a href=\"https://ibb.co/hWqjG7\"><img src=\"https://preview.ibb.co/cETFOn/AI_ML_DL.png\" alt=\"IA engloba ML, que a su vez engloba DL\" border=\"0\"></a>\n","\n","**Inteligencia artificial:** \n","\n","La IA consiste en conseguir que las máquinas realicen tareas que requieren de la inteligencia humana. Se puede dividir en dos campos:\n","\n","*   *General AI*: consiste en dotar a las máquinas de todas nuestras capacidades y sentidos. Por ejemplo, C-3PO o Terminator. Tranquilos, todavía queda muuuucho para ver algo parecido a Skynet por aquí.\n","*   *Narrow AI*: consiste en dotar a las máquinas de la capacidad de desarrollar una determinada tarea, como por ejemplo, reconocer caras, señales de tráfico, el habla, etc. Es en este campo donde actualmente se están observando grandes avances.\n","\n","**Machine Learning:**\n","\n","El Machine Learning o aprendizaje máquina es un **subcampo dentro de la Inteligencia Artificial**. Básicamente, consiste en **utilizar una gran cantidad de datos para extraer información útil para las personas**. Por ejemplo, imaginaos que disponemos de los últimos resultados de La Liga y queremos ser capaces de predecir el resultado del próximo Clásico. Primero, necesitariamos *parsear* los datos, limpiarlos, eliminar las entradas incompletas, estudiar la distribución de las variables y elegir las características o atributos (*feature engineering*) que nos permitieran predecir este resultado con la mayor precisión posible. Una vez tuviésemos claro cuales son las mejores características a utilizar, necesitaríamos encontrar el mejor algoritmo posible para nuestro dataset.\n","\n","La **elección de las características**, que a priori puede llegar a parecer sencillo, es el paso **más complicado y costoso** y, además, requiere de un alto grado de conocimientos sobre el problema en cuestión y sobre técnicas de extracción de características.\n","\n","**Deep Learning:**\n","\n","El aprendizaje profundo o Deep Learning es un subcampo del **Machine Learning**, y soluciona el problema anterior de la elección de características. También llamado aprendizaje jerárquico, ***aprende*** distintas **representaciones de los datos** que son introducidas a un clasificador final.\n","\n","La magia está en que ya no necesitamos volvernos locos buscando las mejores características o atributos para cada problema, si no que esto lo hace **automáticamente** nuestro algoritmo.\n","\n","\n","Por último, cabe destacar la importancia de tener una gran cantidad de datos para poder utilizar técnicas de ML o DL. Además, cuanta más calidad tengan esos datos, mejor se comportaran nuestros modelos.\n","\n","*“I think AI is akin to building a rocket ship. You need a huge engine and a lot of fuel. If you have a large engine and a tiny amount of fuel, you won’t make it to orbit. If you have a tiny engine and a ton of fuel, you can’t even lift off. To build a rocket you need a huge engine and a lot of fuel.”*\n","\n","– Andrew Ng (source: Wired)\n","\n","Que traducido quiere decir:\n","\n","*Creo que la IA es parecido a construir un cohete espacial. Necesitas un motor enorme y mucho combustible. Si tienes un motor enorme pero poco combustible, no conseguirás poner el cohete en órbita. Si tienes un pequeño motor y un montón de combustible, no podrás ni despegar. Para construir un cohete espacial necesitas un motor enorme y un monton de combustible.*\n","\n","Así que ya sabéis, no solo es importante el algoritmo que utilicemos, sino los datos de los que dispongamos.\n","\n","¿Y por qué **deep** learning?\n","\n","<img src=\"https://www.tensorflow.org/images/wide_n_deep.svg\" border=\"0\" height=\"300\">\n","\n","Porque realizamos muchas transformaciones a los datos que tenemos, una detrás de la otra, de una forma secuencial, hasta que llegamos a la representación de esos datos en la que somos capaces de diferenciar los datos conforme nosotros queremos.\n","\n","Aquí tenéis un muy buen ejercicio que podéis hacer cuando tengáis un rato: https://www.tensorflow.org/tutorials/wide_and_deep"]},{"cell_type":"markdown","metadata":{"id":"OFDhMkz78NoB","colab_type":"text"},"source":["### 1.1.1. Contexto histórico\n","\n","Probablemente muchos de vosotros penséis que esto del Deep Learning y las redes neuronales es una novedad, pues nada más lejos de la realidad! De hecho, la primera red neuronal data de 1958!! Lo que pasa es que no había potencia de cálculo suficiente para poder progresar hasta hace relativamente poco, con la popularización de las GPUs de altas prestaciones. Así que... gracias gamers!!\n","\n","Por si tenéis curiosidad, estas son las cosas más importantes que han ido pasando dentro del campo de la IA:\n","\n","<img src=\"https://image.ibb.co/mEVbA8/timeline_deep_learning.png\" alt=\"timeline_deep_learning\" border=\"0\">\n","\n","*   **1950**: Alan Turing crea el **Test de Turing**\n","*   **1952**: Arthur Samuel crea el primer programa que **aprende** partida tras partida a jugar a las Damas\n","*   **1956**: Martin Minsky acuña el término **\"Artificial Intelligence\"** para referirse a este nuevo campo\n","*   **1958**: Frank Rosenblatt diseña el Perceptrón, **la primera red neuronal artificial**. HACE **60 AÑOS!!!**\n","\n","Como podéis ver, la Inteligencia Artificial no es ni mucho menos nueva, lleva mucho tiempo entre nosotros, sufriendo altibajos debidos a las altas expectativas depositadas y los \"pocos\" avances conseguidos.\n","\n","Desde 1974 hasta nuestros días, se han producido varios \"inviernos\" y \"primaveras\".\n","\n","<a href=\"https://imgbb.com/\"><img src=\"https://image.ibb.co/b3ih3n/AI_winter.jpg\" alt=\"Winter is coming\" border=\"0\"></a>\n","\n","Algunos de los hechos más relevantes hasta 2006 son estos:\n","\n","*   **1967**: Nace el campo del reconocimiento de patrones con la aparición del algoritmo **\"Nearest Neighbor\"**\n","*   **1979**: Crean el Stanford Cart, un **robot capaz de navegar automáticamente por una habitación evitando obstáculos**\n","*   **1981**: Gerald Dejong introduce el \"Explanation Based Learning\", el precursor del Machine Learning. El ordenador **analizaba datos** de entrenamiento y creaba reglas **para descartar los datos menos importantes**\n","*   **1985**: Terry Sejnowski inventa NetTalk, un algoritmo capaz de **aprender a pronunciar palabras** como lo haría un niño\n","*   **1990s**: **Cambia el paradigma del Machine Learning**: de un enfoque orientado al conocimiento, a uno **orientado al dato**. Empiezan a extraer conclusiones de grandes cantidades de datos.\n","*   **1997**: **DeepBlue derrota a Kaspárov** por primera vez.\n","\n","Tras esta época de luces y sombras, y gracias, entre otras cosas, a la disponibilidad de mucha más potencia de cálculo y de datos, desde 2006 hasta la fecha ha habido una explosión del Machine Learning.\n","\n","*   **2006**: Aparecen las **arquitecturas profundas**, acuñadas como Deep Learning por Geoffrey Hinton\n","*   **2011**: **Watson IBM vence** a sus competidores **humanos** en el concurso Jeopardy\n","*   **2012**: Geoffrey Hinton gana por goleada el concurso de **ImageNet** con una red neuronal profunda\n","*   **2012**: En Google X crean GoogleBrain, capaz de **detectar gatos en videos**\n","*   **2014**: Facebook desarrolla DeepFace, capaz de **reconocer caras de humanos con una precisión de 97.25%**, solo un 0.28% por debajo de un ser humano\n","*   **2014**: Google compra DeepMind, una stertup inglesa que había creado un algoritmo capaz de **aprender a jugar con juegos Atari simplemente viendo el video**\n","*   **2014**: Aparecen las **GANs (Generative Adversarial Networks)**, capaces de generar contenido falso que no lo parece, cambiando para siempre la percepción de \"real\" (deep fakes).\n","*   **2015**: Elon Musk y Sam Altman crean OpenAI para **promover el bueno uso de la IA**\n","*   **2016**: **Google DeepMind vence** por primera vez en el **juego Go, consiguiendo movimientos creativos**"]},{"cell_type":"markdown","metadata":{"id":"oLJb8m8c8TSH","colab_type":"text"},"source":["### 1.1.2. Google Colab\n","\n","La plataforma en la que os encontráis se llama **Google Colab**. Va a ser a la vez nuestro *notebook* y nuestra IDE, ya que nos permite aprovechar que por el momento Google ofrece GPUs **NVIDIA K80** de forma **gratuita** (maravilloso, no?), que es donde ejecutaremos nuestros desarrollos.\n","\n","Cualquiera con una cuenta de Google puede crear un nuevo notebook y empezar a disfrutarlo! A lo largo del curso iremos viendo lo necesario para que aprendáis a manejarlo con soltura, así que no tenéis por qué preocuparos si es la primera vez que lo véis. Y si habéis trabajado antes con Jupyter, esto es lo mismo!\n","\n","Lo único que tenéis que hacer todos para aprovechar la GPU es ir a **Edit**, en la barra de herramientas, y luego a **Notebook settings**. Os aparecerá esta pantalla, la cual tiene que quedar igual que en la imagen. Debéis seleccionar Python 3 y GPU, y luego darle a **Save**.\n","\n","<a href=\"https://ibb.co/ceoX3n\"><img src=\"https://preview.ibb.co/mQEi9S/notebook_config.png\" alt=\"Notebook configuration\" border=\"0\"></a>"]},{"cell_type":"markdown","metadata":{"id":"i82s0YnP8XPH","colab_type":"text"},"source":["### 1.1.3. El descenso del gradiente: el culpable de que existan las redes neuronales\n","\n","El mecanismo que hace que una red neuronal aprenda es el descenso del gradiente. Como posiblemente ya sabréis los más curiosos, las redes neuronales se entrenan actualizando una serie de pesos, y conforme más se entrenan, más se acercan a una buena solución. ¿Os suena esto de algo?\n","\n","\n","¿No?\n","\n","\n","¡Estamos optimizando funciones! En efecto, siento desilusionaros, pero las redes neuronales no son otra cosa que un método, muy ingenioso y potente, eso sí, de **optimizar funciones**. Y nuestro mejor amigo se llama **Descenso del gradiente**, que es lo que en gran medida ha permitido que podamos entrenar redes con millones de parámetros y vivir para verlo!\n","\n","**¿Pero qué es el descenso del gradiente?**\n","\n","Vamos a imaginarnos que estamos en lo alto de una montaña y que hay una niebla tremenda, con lo cual no somos capaces de ver más allá de nuestras narices, literalmente. Lo que queremos lógicamente es llegar abajo del todo, donde hay un bar estupendo con una cervecita bien fría esperándonos. Aunque más de uno puede que haya saltado ya y no le importe bajar rodando, para aquellos más cautos, os voy a explicar cómo lo vamos a hacer. Poneos en situación. Estáis en el punto más alto y no veis nada, ¿cómo lo hacéis para bajar la montaña?\n","\n","<img src=\"https://image.ibb.co/jhnVbJ/mountain.png\" alt=\"mountain\" border=\"0\" height=\"300\">\n","\n","¿Ningún valiente? Ya he dicho que rodando no nos vale.\n","\n","¿Y si damos un pequeño paso en cada una de las 4 direcciones (este, oeste, norte y sur) y elegimos aquella en la que más bajamos para dar un paso? ¿Y si volvemos a realizar esta operación una y otra vez? Podríamos hacer esto hasta que no consiguieramos bajar en ninguna de las 4 posibles orientaciones. Entonces, en teoría, deberíamos haber llegado abajo.\n","\n","¿Qué? ¿No os termina de convencer verdad? Eso de dar 4 pasos a ver cual es mejor... no pareece muy eficiente ¿verdad? ¿Se os ocurre alguna forma de mejorar esto? Ojalá hubiese alguna forma de saber qué pendiente hay en cada punto, no? eso nos permitiría avanzar siempre hacia donde más pendiente hubiera.\n","\n","¿Os suena esto de algo? ¿Cómo podemos averiguar la pendiente de una función?\n","\n","¡Eso es! ¡Calculando la **derivada**!\n","\n","¿Os acordáis de qué es lo que indica la derivada de una función? ¿Os acordáis de cómo se calculan?\n","\n","$f'(x) = \\frac{f(x+h)-f(x-h)}{2}$, cuando $h\\to 0$.\n","\n","La primera derivada de una función mide la rapidez con que cambia una función, es decir cuanto crece o decrece. Así que lo que podemos hacer es **calcular la pendiente para cada punto al que llegamos seguir bajando esa pendiente hasta un punto mínimo**.\n","\n","<img src=\"https://image.ibb.co/cXGCqd/mountain_gd.png\" alt=\"mountain_gd\" border=\"0\" height=\"300\"> <img src=\"https://image.ibb.co/ganZLd/gradient_descent_2.png\" alt=\"gradient_descent_2\" border=\"0\" height=\"300\">\n","\n","Pues si amigos, esto taaaan sofisticado es el algoritmo del descenso del gradiente, y os puedo decir que es **el corazón de las redes neuronales**.\n","\n","Para aquellos de vosotros que os gusten más las matemáticas que las montañas, podéis ver el descenso del gradiente como un algoritmo de optimización que permite **minimizar cualquier función** (siempre que sea **diferenciable**, es decir, que podamos calcular sus derivadas). De hecho, la idea es muy similar a aquellos problemas de optimización a los que muy posiblemente os hayáis enfrentado en alguna clase de matemáticas a lo largo de vuestras vidas. Y para muestra, un botón:\n","\n","<center><img src=\"http://www.cs.us.es/~fsancho/images/2017-02/gradient_descent.gif\" border=\"0\"></center>\n","\n","Este algoritmo tiene variaciones (vanilla gradient descent, batch gradient descent, stochastic gradient descent, etc), pero todos parten de la misma idea base, la que os acabo de explicar."]},{"cell_type":"markdown","metadata":{"id":"TcokI_bpc4Ui","colab_type":"text"},"source":["## 1.2. Introducción a TensorFlow\n","\n","Como muchos de vosotros ya sabréis, TensorFlow es un framework desarrollado y mantenido por Google que permite la ejecución de operaciones matemáticas de una forma optimizada en una CPU o GPU. En nuestro caso estamos más interesados en la GPU, ya que es la única forma que tenemos de entrenar una red neuronal profunda y no morir de viejos esperando ;)\n","\n","¿Por qué tensorflow?\n","\n","* Por su **flexibilidad y escalabilidad**\n","\n","* Por su **popularidad**\n","\n","<img src=\"https://image.ibb.co/mCJNqd/tf_pop.png\" alt=\"tf_pop\" border=\"0\" height=\"300\"> <img src=\"https://image.ibb.co/bBDYwJ/tf_users.png\" alt=\"tf_users\" border=\"0\" height=\"300\">\n","\n","\n","Más adelante comprenderemos por qué es tan importante disponer de un buen framework que nos permita realizar operaciones de la forma más rápida posible. De momento, vamos a trabajar un poco con TensorFlow hasta que nos familiaricemos con su modo de funcionar. Pero antes, algunas de sus características más importantes:\n","\n","*    TensorFlow utiliza **tensores** para realizar las operaciones.\n","*    En TensorFlow, primero se definen las operaciones a realizar (construimos el **grafo**), y luego se ejecutan (se ejecuta el grafo)\n","*    Permite ejecutar el código implementado **paralelamente** o en una o varias GPUs, a elección del usuario\n","\n","Vale, pero **¿qué es un tensor?**\n","\n","Aunque los tensores los inventaron los físicos para ser capaces de describir interacciones, en el ámbito de la IA se pueden entender simplemente como **contenedores de números**.\n","\n","<a href=\"https://ibb.co/bBCyb7\"><img src=\"https://image.ibb.co/fnFvOn/tensores.png\" alt=\"tensores\" border=\"0\"></a>"]},{"cell_type":"markdown","metadata":{"id":"LOzjXJZsRv4T","colab_type":"text"},"source":["Vamos a ver algunos ejemplos con tensores!"]},{"cell_type":"code","metadata":{"id":"aUbV0zbtRzOT","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rRuBIyw7A9D5","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z91sW_BFAwlC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SCeepOKaBWrb","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8dYP5ZfnBaTE","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eoLA0id5Bmoe","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZStAX6KvBpqC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CkInQL5pB42t","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bYU1IwoWCBaD","colab_type":"text"},"source":["Y así podríamos seguir hasta el infinito añadiendo dimensiones a nuestros tensores para ser capaces de guardar más datos. Para que os hagáis una idea de cómo se suelen utilizar en el mundo del Deep Learning, los tipos más comunes de tensores son:\n","\n","*    **Tensores 3D**: utilizados en **series temporales**\n","*    **Tensores 4D**: utilizados con **imágenes**\n","*    **Tensores 5D**: utilizados con **videos**\n","\n","Normalmente, siempre habrá una de las dimensiones que se utilizará para almacenar las muestras de cada tipo de datos. Por ejemplo, con las imágenes:\n","\n","Si queremos almacenar 64 imágenes RGB de 224x224 píxels, necesitaremos un vector de matrices 3D, o lo que es lo mismo, un tensor 4D. ¿Quién sabría decirme las dimensiones que tendría nuestro vector de matrices 3D?\n","\n","Tenemos 64 imágenes de 224 pixels x 224 pixels x 3 canales (R, G y B). \n","\n","Por tanto: (64, 224, 224, 3)\n","\n","De acuerdo, pues ya sabemos qué es un tensor y para que sirve: ¡para mantener las notas de vuestros exámenes bien guardadas! ;D\n","\n","Si queréis profundizar en los tensores o más ejemplos, aquí tenéis un recurso muy bueno para ello (en inglés): [Tensors ilustrated with cats](https://hackernoon.com/learning-ai-if-you-suck-at-math-p4-tensors-illustrated-with-cats-27f0002c9b32)"]},{"cell_type":"markdown","metadata":{"id":"VCoGMApGPiXd","colab_type":"text"},"source":["### Ejemplo de carga de dataset externo\n","\n","¿Y por qué son importantes los tensores? Porque van a ser las estructuras de datos que utilizaremos para entrenar nuestras redes.\n","\n","Vamos a ver un ejemplo de cómo podríamos cargar un dataset de imágenes junto con sus etiquetas.\n","\n","Para este ejemplo vamos a utilizar imágenes provenientes de escáneres de pulmón para tratar de predecir el Covid-19. Los datos son públicos y están disponibles en el siguiente enlace:\n","\n","https://github.com/UCSD-AI4H/COVID-CT\n","\n","Este dataset consta de imágenes de pacientes patológicos y sanos. Para hacer el ejemplo más sencillo, vamos a tratar con las imágenes correspondientes a Covid19 únicamente."]},{"cell_type":"code","metadata":{"id":"Tv-yXA4_QuXI","colab_type":"code","colab":{}},"source":["# Para ello, lo primero es decargarnos el dataset\n","!wget -O CT_Covid.zip https://github.com/UCSD-AI4H/COVID-CT/blob/master/Images-processed/CT_COVID.zip?raw=true"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UoBobtNrRPAl","colab_type":"code","colab":{}},"source":["# comprobamos que tenemos el dataset descargado\n","!ls -lah"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eqgap56DRoH7","colab_type":"code","colab":{}},"source":["# lo descomprimimos\n","!unzip CT_Covid.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8LBB4v_wRuzn","colab_type":"code","colab":{}},"source":["# ahora que ya lo tenemos descomprimido, tenemos que listar la carpeta donde se \n","# encuentran todas las imágenes para después poder cargarlas. Existen varias\n","# formas de hacer esto, y algunas son más eficientes que otras. Por ejemplo:\n","\n","# images = []\n","# for img in list_imgs:\n","#     images.append(load_image(img))\n","\n","# Esté método es el más lento que podemos utilizar, ya que cada vez que añadamos \n","# una nueva imagen, Python creará una nueva lista y copiará el contenido de la\n","# anterior, así que no es el método más adecuado.\n","\n","# Por el contrario, este es mucho mejor, ya que no se crean nuevas listas,\n","# simplemente se accede a posiciones determinadas y se insertan los datos:\n","\n","# n_images = len(list_imgs)\n","# images = np.zeros((n_images, height, width, channels), dtype=np.uint8)\n","# for i, img in enumerate(list_imgs):\n","#     images[i] = load_image(img)\n","\n","# Sin embargo, éste segundo método tiene un inconveniente: neceistamos que\n","# todas las imágenes tengan el mismo tamaño, algo que no siempre pasa en\n","# los datasets reales: tendremos que redimensionarlas.\n","\n","# Vamos a cargarlas siguiendo los dos métodos para que veais las diferencias.\n","# Para ver el tiempo que tarda cada una utilizaremos la librería TQDM, que \n","# crea una barra de progreso y nos informa de los tiempos."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dSgRIAP_SvI7","colab_type":"code","colab":{}},"source":["# listamos el directorio\n","import glob\n","list_imgs = ## Aquí tu código ##\n","n_images = len(list_imgs)\n","print(n_images, 'images were loaded!')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4cxJbqEtTwrT","colab_type":"code","colab":{}},"source":["# Perfecto, tenemos las 349 CTs que hay disponibles en el dataset. \n","# Ahora, vamos a cargarlas, pero primero necesitamos saber las dimensiones\n","# de las imágenes. Para ello, vamos a utilizar OpenCV.\n","\n","import cv2\n","\n","for img_path in list_imgs:\n","    img = ## Aquí tu código ##\n","    print(## Aquí tu código ##)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DDsQRwsMVFko","colab_type":"code","colab":{}},"source":["# Fijaos que las imágenes tienen tamaños diferentes. Ahora, tenemos dos opciones:\n","#\n","# - Redimensionar las imágenes al mismo tamaño, sin mantener el ASPECT RATIO.\n","#   Es el método más sencillo, pero distosionará las imágenes, por lo que puede\n","#   hacer que nuestro modelo no sea todo lo bueno que podría ser.\n","#\n","# - Redimensionar las imágenes al mismo tamaño, manteniendo el ASPECT RATIO.\n","#   Para ello, podemos redimensionar las imágenes al tamaño deseado y luego \n","#   rellenar \"los huecos\" con algún valor constante, normalmente, 0.\n","#\n","# En este caso, por simplicidad, vamos a hacer la primera opción.\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aa2g67B_TI9o","colab_type":"code","colab":{}},"source":["from tqdm import tqdm\n","\n","# creamos la estructura de datos donde almacenaremos las imágenes cargadas\n","images = []\n","\n","# implementamos el bucle que recorrerá la lista e irá cargando las imágenes,\n","# redimensionándolas y añadiéndolas a nuestra estructura de datos\n","for i, img_path in enumerate(tqdm(list_imgs)):\n","    img = ## Aquí tu código ##\n","    # opencv carga por defecto las imágenes en modo BGR\n","    # esto lo tenemos que tener en cuenta, ya que si entrenamos\n","    # el modelo con imágenes BGR, luego tendremos que alimentarlo\n","    # con imágenes del mismo tipo para que el modelo funcione \n","    # correctamente.\n","    img = ## Aquí tu código ##\n","    # la redimensionamos a 96x96 (este tamaño es arbitrario porque es un ejemplo,\n","    # en un caso real, estudiaríamos el tamaño que menos distorsiona la mayoría\n","    # de las imágenes)\n","    img = ## Aquí tu código ##\n","    # aquí incluiríamos los pasos de preprocesamiento que quisiésemos, por ejemplo:\n","    # img = img / 255.  # normalizamos la imagen entre 0 y 1\n","    # img = mi_funcion_random_crop(img)  # cortamos un trozo aleatoriamente\n","    # añadimos la imagen a nuestra estructura de datos\n","    images.append(img)\n","\n","print('Loading completed!')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OdblTec648Wu","colab_type":"code","colab":{}},"source":["type(images)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ffga2ExT5FGM","colab_type":"code","colab":{}},"source":["type(images[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gz8o67Jm5C4Q","colab_type":"code","colab":{}},"source":["images[0].shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qq56FJ_45AYN","colab_type":"code","colab":{}},"source":["# En el caso de cargar las imágenes así, tenemos que convertirlas a un TENSOR 4D\n","# de N_Imágenes x Alto x Ancho x Canales. Ahora mismo es una lista de TENSORES 3D,\n","# para convertirlo a Tensor 4D simplemente tenemos que hacer uso de la función\n","# np.stack:\n","\n","images = ## Aquí tu código ##"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a2VZAh0P5I1m","colab_type":"code","colab":{}},"source":["type(images)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1QDIU3FP5KSq","colab_type":"code","colab":{}},"source":["images.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y-RcPEpFZKw9","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","# creamos la estructura de datos donde almacenaremos las imágenes cargadas\n","images = ## Aquí tu código ##\n","\n","# implementamos el bucle que recorrerá la lista e irá cargando las imágenes,\n","# redimensionándolas y añadiéndolas a nuestra estructura de datos\n","for i, img_path in enumerate(tqdm(list_imgs)):\n","    img = ## Aquí tu código ##\n","    # opencv carga por defecto las imágenes en modo BGR\n","    # esto lo tenemos que tener en cuenta, ya que si entrenamos\n","    # el modelo con imágenes BGR, luego tendremos que alimentarlo\n","    # con imágenes del mismo tipo para que el modelo funcione \n","    # correctamente.\n","    img = ## Aquí tu código ##\n","    # la redimensionamos a 96x96 (este tamaño es arbitrario porque es un ejemplo,\n","    # en un caso real, estudiaríamos el tamaño que menos distorsiona la mayoría\n","    # de las imágenes)\n","    img = ## Aquí tu código ##\n","    # añadimos la imagen a nuestra estructura de datios\n","    images[i] = ## Aquí tu código ##\n","\n","print('Loading completed!')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UoMkZSKXd31g","colab_type":"code","colab":{}},"source":["# En este caso no se nota la diferencia porque son pocas imágenes, pero cuando\n","# trabajéis con grandes cantidades de datos podréis ver la diferencia.\n","\n","# Ahora que ya los tenemos cargados, vamos a estudiar un poco la estructura de datos\n","images.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nh2oOhOJ2DH5","colab_type":"code","colab":{}},"source":["images.min()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uo15GJPo2FwR","colab_type":"code","colab":{}},"source":["images.max()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y9tVMzhM2MQI","colab_type":"code","colab":{}},"source":["images.dtype"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zFrUyGqO2JWG","colab_type":"code","colab":{}},"source":["# Si os fijáis, nuestros datos son de tipo float64, y van de 0 a 255. \n","# Normalmente, cuando trabajamos con imágenes, solemos trabajar con datos de \n","# tipo uint8 que van de 0 a 255, o float que van de 0 a 1.\n","# Vamos a convertir nuestra imagen a de 0 a 1.\n","images = ## Aquí tu código ##"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V-_s9qah4U1z","colab_type":"code","colab":{}},"source":["images.min()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uyicQVLh4Wi0","colab_type":"code","colab":{}},"source":["images.max()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ui3hpRPX5yqa","colab_type":"text"},"source":["Pues así de fácil es como podemos preparar los datos para alimentar nuestra red neuronal y entrenarla :)\n","\n","Más adelante veremos cómo definir nuestra red neuronal y cómo entrenarla."]},{"cell_type":"markdown","metadata":{"id":"4HNcdMWSRH5z","colab_type":"text"},"source":["\n","\n","Si a alguien le interesa el tema del Covid19, este enlace es un buen recurso para obtener más datos y conocer el estado del arte: https://aimi.stanford.edu/resources/covid19."]},{"cell_type":"markdown","metadata":{"id":"E2-EEjlWDYgt","colab_type":"text"},"source":["##¿Qué es un grafo?\n","\n","Antes os he comentado que en TensorFlow, primero se definen las operaciones a realizar y luego se ejecutan. Para ello, se usa un grafo.\n","\n","\n","Un ejemplo sencillo de una suma de a + b.\n","\n","<img src=\"https://image.ibb.co/nkwp3y/tf_graph_2.png\" alt=\"tf_graph_2\" border=\"0\" height=\"200\">\n","\n","Y aquí tenéis un ejemplo un poco más complicado, para los valientes:\n","\n","![alt text](https://www.tensorflow.org/images/tensors_flowing.gif)\n","\n","Es un ejemplo de un grafo que representa la clasificación de una imagen de un número en su correspondiente clase. No es necesario que entendáis lo que está ocurriendo, simplemente que tensorflow funciona así: primero tu defines las operaciones que quieres que se realicen, junto a las variables necearias (creas el grafo) y luego lo ejecutas (con una sesión). Pero basta de cháchara, ¡vamos a ponernos manos a la obra!\n"]},{"cell_type":"code","metadata":{"id":"SflQtngNSSbJ","colab_type":"code","colab":{}},"source":["# Ejemplos con TensorFlow"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-jDZ2OWAEW0b","colab_type":"code","colab":{}},"source":["# Lo primero que necesitamos hacer es asegurarnos de que vamos a ejecutar la \n","# versión 1.x de TensorFlow. Hace aproximadamente un año salió la versión\n","# 2.0, que establece por defecto el \"EagerMode\" para hacer más sencilla la \n","# implementación y depuración de código. \n","\n","# No obstante, al igual que pasó en su día con Python 2 y Python 3, con tensorflow\n","# ha pasado algo similar: la versión 1.x se sigue utilizando mucho. Algunas de \n","# las razones son la retro-compatibilidad y la rapidez de ejecución. En este \n","# curso veremos ejemplos de ambos casos.\n","\n","# Vamos a ver qué versión es la que tenemos:\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VvxTaG1p2Cro","colab_type":"code","colab":{}},"source":["# Desde el 27 de marzo de 2020, Google Colab tiene activada por defecto la versión\n","# 2.x. Para poder usar la 1.x debemos utilizar el siguiente comando mágico: \n","\n","%tensorflow_version 1.x\n","\n","# Al haber cargado tensorflow ya, lo más probable es que os pida reiniciar el \n","# runtime para poder cambiar la versión, si es así, lo reiniciáis y volvéis a \n","# ejecutar el comando. Este es el mensaje que suele aparecer cuando esto sucede:\n","# \"TensorFlow is already loaded. Please restart the runtime to change versions.\"\n","\n","# Si todo va bien, esto es lo que deberíais ver:\n","# \"TensorFlow 1.x selected.\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pixwOhZQ2Fkp","colab_type":"code","colab":{}},"source":["# Vamos a comprobar qué versión tenemos ahora:\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lTDtVd_k2xu-","colab_type":"code","colab":{}},"source":["# Ya estamos preparados para empezar!\n","\n","# Lo primero que debemos hacer es importar el paquete de Tensorflow\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt # importamos también pyplot para gráficas\n","%matplotlib inline\n","\n","# Es muy importante que conozcamos 3 conceptos básicos de TF:\n","# tf.Graph: representa un conjunto de tf.Operations\n","# tf.Operation: son las operaciones indicadas por las ecuaciones que escribimos\n","# tf.Tensor: los resultados de las tf.Operations\n","\n","# En un principio, el tf.Graph es transparente a nosotros, ya que por defecto\n","# existe uno donde se van añadiendo todas las operaciones que definimos:\n","# tf.get_default_graph()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"77CwESJT2xnb","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s-oDrVgC2xfa","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cUYw_5NN2xZN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aIXQtwffEWQ5","colab_type":"code","colab":{}},"source":["# Para poder visualizar el grafo ERA necesario definir un par de funciones que \n","# lo permitan. Para que veáis a que nivel TF puede llegar a ser un incordio,\n","# las he dejado aquí.\n","\n","from IPython.display import clear_output, Image, display, HTML\n","\n","def strip_consts(graph_def, max_const_size=32):\n","    \"\"\"Strip large constant values from graph_def.\"\"\"\n","    strip_def = tf.GraphDef()\n","    for n0 in graph_def.node:\n","        n = strip_def.node.add() \n","        n.MergeFrom(n0)\n","        if n.op == 'Const':\n","            tensor = n.attr['value'].tensor\n","            size = len(tensor.tensor_content)\n","            if size > max_const_size:\n","                tensor.tensor_content = \"<stripped %d bytes>\"%size\n","    return strip_def\n","\n","def show_graph(graph_def, max_const_size=32):\n","    \"\"\"Visualize TensorFlow graph.\"\"\"\n","    if hasattr(graph_def, 'as_graph_def'):\n","        graph_def = graph_def.as_graph_def()\n","    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n","    code = \"\"\"\n","        <script>\n","          function load() {{\n","            document.getElementById(\"{id}\").pbtxt = {data};\n","          }}\n","        </script>\n","        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n","        <div style=\"height:600px\">\n","          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n","        </div>\n","    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n","\n","    iframe = \"\"\"\n","        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n","    \"\"\".format(code.replace('\"', '&quot;'))\n","    display(HTML(iframe))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8hOe1xLS5WWY","colab_type":"code","colab":{}},"source":["# Ahora, desde TF 1.13, podemos hacer uso del comando mágico: %tensorboard\n","# Pero primero, tenemos que guardar el grafo:\n","writer = tf.summary.FileWriter(\"output\", tf.get_default_graph())\n","writer.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gDuu7pVNS7EO","colab_type":"code","colab":{}},"source":["# ahora sí, visualizamos el grafo recien construido:\n","%load_ext tensorboard\n","%tensorboard --logdir output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"46aWoafg5cyF","colab_type":"code","colab":{}},"source":["# También podemos ver la definición del grafo\n","print(tf.get_default_graph().as_graph_def())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QGRgotcEKOF2","colab_type":"text"},"source":["Para los que no la recordéis, la fórmula de la distribución de probabilidad de Gauss es así:\n","\n","<img src=\"https://image.ibb.co/hTyQbJ/normal_fdp.png\" alt=\"normal_fdp\" border=\"0\">\n","\n","La gráfica la vamos a poder ver enseguida."]},{"cell_type":"code","metadata":{"id":"zq_Pc2dAKHfW","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DiSVY0t5K1xT","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CUCd6MKXK_hH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zxP5-GeYLiVn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MgsgV0a1MQdK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OmPCeyYOMY0j","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XE2XILJtKHPe","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n32o51VzNQ5C","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tqRrLKmbNi_L","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JBZcIUO9OAUA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KThab6BuOZnZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rm0JbUvJOtJC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PccKSQvNPCrQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LD50umw-PLOU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eyBlGRHzPvTA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tgUfBc9A6lsL","colab_type":"text"},"source":["Como os he comentado antes, una red neuronal no es otra cosa que un optimizador de funciones. ¿Y para qué podríamos utilizar este optimizador de funciones? Vamos a ver un ejemplo."]},{"cell_type":"markdown","metadata":{"id":"3-J6OIdyESot","colab_type":"text"},"source":["### Problema\n","\n","Netflix ha decidido colocar otro de sus famosos carteles publicitarios en un edificio.\n","\n","<img src=\"https://image.ibb.co/c199mJ/cartel_netflix.jpg\" alt=\"cartel_netflix\" border=\"0\" width=\"300\">\n","\n","Han decidido que el cartel publicitario tiene que cubrir una superficie de 600 metros cuadrados, debjando un margen de 2 metros arriba y abajo y de 4 metros a izquierda y derecha para publicidad. Sin embargo, no les han comunicado las dimensiones de la fachada del edificio. Podríamos mandar un email al propietario y preguntarle, pero como sabemos matemáticas podemos ahorrárnoslo. ¿Cómo podemos averiguar las dimensiones del edificio?\n","\n","<img src=\"https://image.ibb.co/iq5qRJ/opt_problem.png\" alt=\"opt_problem\" border=\"0\" width=\"400\">"]},{"cell_type":"code","metadata":{"id":"0BwXpvBMYA_S","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cp0yrwFJclpR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lzok3yGjew0q","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hb6t9EyHe4NU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sDTMyKfffJA6","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L9ugLkGgSjeG","colab_type":"text"},"source":["### Problema\n","\n","En este caro, queremos encontrar el mínimo de la función y=log²(x)"]},{"cell_type":"code","metadata":{"id":"JDMg7mZs0Lxr","colab_type":"code","colab":{}},"source":["# Hallar el mínimo de la función y=log(x)^2\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M_do4TbMh34J","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5mcxneho21S_","colab_type":"text"},"source":["### Problema\n","\n","Veamos como ajustar una recta a un conjunto de datos que representan la inteligencia de cada uno de los personajes de Los Simpsons, desde Ralph Wiggum hasta el Doctor Frink.\n","\n","<img src=\"https://image.ibb.co/kXFbyn/ralph.gif\" alt=\"ralph\" border=\"0\" height=200>&nbsp;\n","<img src=\"https://image.ibb.co/nMK1yJ/frink.gif\" alt=\"frink\" border=\"0\" height=200>"]},{"cell_type":"code","metadata":{"id":"a90crsticHKd","colab_type":"code","colab":{}},"source":["# Problema inteligencias\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q-gfFP1AjAsl","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0rjtlGVXGyoi","colab_type":"text"},"source":["### Problema\n","\n","Veamos ahora cómo clasificar imágenes de dígitos con una regresión logística.\n","\n","Vamos a utilizar el archiconocido dataset MNIST, que es como el \"Hola mundo\" de los datasets:\n","\n","<img src=\"https://image.ibb.co/gkZAD8/mnist.jpg\" alt=\"mnist\" border=\"0\" height=\"300\">\n","<img src=\"https://image.ibb.co/kgLyOT/mnist_image.png\" alt=\"mnist_image\" border=\"0\" height=\"300\">"]},{"cell_type":"code","metadata":{"id":"mggjd17oVIB6","colab_type":"code","colab":{}},"source":["# Problema MNIST\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JCvgGdDuoztM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x9qLtOQopbte","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6I_4dK09pmo0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9u-29RRbpoyf","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ISVsdDW_ps_c","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kYbqt0UftWhf","colab_type":"text"},"source":["<img src=\"https://image.ibb.co/kzdu17/perceptron_schematic.png\" alt=\"perceptron_schematic\" border=\"0\">\n"]}]}